## الوحدة 3. هندسات المحول للصوت

في هذه الدورة، سننظر بشكل أساسي في نماذج المحول وكيف يمكن تطبيقها على مهام الصوت. في حين أنك لست بحاجة إلى معرفة التفاصيل الداخلية لهذه النماذج، من المفيد فهم المفاهيم الرئيسية التي تجعلها تعمل، لذا إليك مراجعة سريعة. للحصول على نظرة متعمقة حول المحولات، تحقق من [دورة NLP](https://huggingface.co/course/chapter1/1).

## كيف يعمل المحول؟

تم تصميم نموذج المحول الأصلي لترجمة النص المكتوب من لغة إلى أخرى. بدا تصميمه على النحو التالي:

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers.svg" alt="تصميم المحول الأصلي">
</div>

على اليسار يوجد **المشفر** وعلى اليمين يوجد **فك التشفير**.

- يستقبل المشفر إدخالاً، في هذه الحالة تسلسل رموز النص، ويبني تمثيلًا له (ميزاته). يتم تدريب هذا الجزء من النموذج لاكتساب الفهم من الإدخال.

- يستخدم فك التشفير تمثيل المشفر (الميزات) إلى جانب إدخالات أخرى (الرموز التي تم التنبؤ بها سابقًا) لتوليد تسلسل مستهدف. يتم تدريب هذا الجزء من النموذج لإنتاج الإخراج. في التصميم الأصلي، يتكون تسلسل الإخراج من رموز النص.

هناك أيضًا نماذج قائمة على المحول التي تستخدم فقط جزء المشفر (جيد لمهام تتطلب فهم الإدخال، مثل التصنيف)، أو جزء فك التشفير فقط (جيد لمهام مثل توليد النص). يعد BERT مثالاً على نموذج المشفر فقط؛ يعد GPT2 مثالاً على نموذج فك التشفير فقط.

تتمثل إحدى الميزات الرئيسية لنماذج المحول في أنها مبنية باستخدام طبقات خاصة تسمى **طبقات الاهتمام**. تخبر هذه الطبقات النموذج بإيلاء اهتمام محدد لعناصر معينة في تسلسل الإدخال وتجاهل الآخرين عند حساب تمثيلات الميزات.

## استخدام المحولات للصوت

تتميز نماذج الصوت التي سنغطيها في هذه الدورة عادةً بهندسة محول قياسية كما هو موضح أعلاه، ولكن مع تعديل طفيف على جانب الإدخال أو الإخراج للسماح ببيانات الصوت بدلاً من النص. نظرًا لأن جميع هذه النماذج عبارة عن محولات في جوهرها، فستكون معظم هندستها مشتركة والاختلافات الرئيسية هي في كيفية تدريبها واستخدامها.

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/audio-course-images/resolve/main/transformers_blocks.png" alt="المحول مع إدخال الصوت والإخراج">
</div>

بالنسبة لمهام الصوت، قد يكون تسلسل الإدخال و/أو الإخراج صوتيًا بدلاً من النص:

- التعرف التلقائي على الكلام (ASR): الإدخال هو الكلام، والإخراج هو النص.

- تركيب الكلام (TTS): الإدخال هو النص، والإخراج هو الكلام.

- تصنيف الصوت: الإدخال هو الصوت، والإخراج هو احتمال فئة - واحد لكل عنصر في التسلسل أو احتمال فئة واحدة للتسلسل بأكمله.

- تحويل الصوت أو تعزيز الكلام: كل من الإدخال والإخراج عبارة عن صوت.

هناك بضع طرق مختلفة للتعامل مع الصوت بحيث يمكن استخدامه مع المحول. الاعتبار الرئيسي هو ما إذا كان سيتم استخدام الصوت بشكله الخام - كموجة - أو معالجته كمخطط طيفي بدلاً من ذلك.

## إدخالات النموذج

يمكن أن يكون إدخال نموذج الصوت إما نصًا أو صوتًا. الهدف هو تحويل هذا الإدخال إلى متجه مضمن يمكن معالجته بواسطة هندسة المحول.

### إدخال النص

يأخذ نموذج تحويل النص إلى كلام النص كإدخال. يعمل هذا تمامًا مثل المحول الأصلي أو أي نموذج NLP آخر: يتم توكين النص أولاً، مما يعطي تسلسل رموز النص. يتم إرسال هذا التسلسل عبر طبقة تضمين الإدخال لتحويل الرموز إلى متجهات أبعاد 512. ثم يتم تمرير متجهات التضمين هذه إلى مشفر المحول.

### إدخال الموجة

يأخذ نموذج التعرف التلقائي على الكلام الصوت كإدخال. لكي نتمكن من استخدام محول لـ ASR، يجب علينا أولاً تحويل الصوت إلى تسلسل من متجهات التضمين بطريقة ما.

تستخدم النماذج مثل **Wav2Vec2** و **HuBERT** موجة الصوت مباشرة كإدخال للنموذج. كما رأيت في [الفصل الخاص ببيانات الصوت](../chapter1/introduction)، فإن الموجة عبارة عن تسلسل أحادي البعد من الأرقام العشرية، حيث يمثل كل رقم السعة المعينة في وقت معين. يتم أولاً تطبيع هذه الموجة الأولية إلى متوسط صفري وانحراف معياري الوحدة، مما يساعد على توحيد عينات الصوت عبر أحجام مختلفة (السعات).

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/audio-course-images/resolve/main/wav2vec2-input.png" alt="يستخدم Wav2Vec2 CNN لإنشاء تضمينات من موجة الإدخال">
</div>

بعد التطبيع، يتم تحويل تسلسل عينات الصوت إلى تضمين باستخدام شبكة عصبية صغيرة للتعرّف على الميزات، والمعروفة باسم المشفر الميزات. تقوم كل طبقة من الطبقات التلافيفية في هذه الشبكة بمعالجة تسلسل الإدخال، وتفرز الصوت لتقليل طول التسلسل، حتى تقوم الطبقة التلافيفية النهائية بإخراج متجه 512 بُعد مع التضمين لكل 25 مللي ثانية من الصوت. بمجرد تحويل تسلسل الإدخال إلى تسلسل من هذه التضمينات، سيقوم المحول بمعالجة البيانات كما هو معتاد.

### إدخال المخطط الطيفي

من عيوب استخدام الموجة الأولية كإدخال أنها تميل إلى أن يكون لها أطوال تسلسل طويلة. على سبيل المثال، يعطي ثلاثون ثانية من الصوت بمعدل أخذ العينات 16 كيلو هرتز إدخالاً بطول `30 * 16000 = 480000`. تتطلب أطوال التسلسل الأطول حسابات أكثر في نموذج المحول، وبالتالي زيادة استخدام الذاكرة.

بسبب هذا، لا تكون الموجات الصوتية الأولية عادةً أكثر أشكال تمثيل إدخال الصوت كفاءة. من خلال استخدام مخطط طيفي، نحصل على نفس الكمية من المعلومات ولكن في شكل مضغوط أكثر.

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/audio-course-images/resolve/main/whisper-input.png" alt="يستخدم Whisper CNN لإنشاء تضمينات من مخطط طيفي للإدخال">
</div>

تقوم النماذج مثل **Whisper** أولاً بتحويل الموجة إلى مخطط طيفي لوغاريتمي. دائمًا ما يقسم Whisper الصوت إلى مقاطع مدتها 30 ثانية، ويكون للمخطط الطيفي لوغاريتم الشكل `(80، 3000)` حيث 80 هو عدد صناديق mel و 3000 هو طول التسلسل. من خلال التحويل إلى مخطط طيفي لوغاريتمي، قللنا من كمية بيانات الإدخال، ولكن الأهم من ذلك، أن هذا التسلسل أقصر بكثير من الموجة الأولية. ثم تتم معالجة المخطط الطيفي لوغاريتم بواسطة شبكة CNN صغيرة في تسلسل من التضمينات، والتي تدخل المحول كالمعتاد.

في كلتا الحالتين، سواء كان الإدخال موجة أو مخطط طيفي، توجد شبكة صغيرة أمام المحول تقوم بتحويل الإدخال إلى تضمينات، ثم يتولى المحول القيام بمهمته.

## مخرجات النموذج

تخرج هندسة المحول تسلسلًا من متجهات الحالة المخفية، والمعروفة أيضًا باسم التضمينات الإخراجية. هدفنا هو تحويل هذه المتجهات إلى إخراج نصي أو صوتي.

### إخراج النص

يتمثل هدف نموذج التعرف التلقائي على الكلام في التنبؤ بتسلسل رموز النص. يتم ذلك عن طريق إضافة رأس نمذجة اللغة - عادةً ما تكون طبقة خطية واحدة - تليها softmax أعلى إخراج المحول. يتنبأ هذا بالاحتمالات عبر رموز النص في المفردات.

### إخراج المخطط الطيفي

بالنسبة للنماذج التي تولد الصوت، مثل نموذج تحويل النص إلى كلام (TTS)، سيتعين علينا إضافة طبقات يمكنها إنتاج تسلسل صوتي. من الشائع جدًا إنشاء مخطط طيفي ثم استخدام شبكة عصبية إضافية، تُعرف باسم vocoder، لتحويل هذا المخطط الطيفي إلى موجة.

في نموذج **SpeechT5** TTS، على سبيل المثال، يكون الإخراج من شبكة المحول عبارة عن تسلسل من متجهات العناصر 768. تقوم الطبقة الخطية بمشروع هذا التسلسل في مخطط طيفي لوغاريتمي. ما يسمى post-net، يتكون من طبقات خطية وتلافيفية إضافية، ويصقل المخطط الطيفي عن طريق تقليل الضوضاء. ثم يقوم vocoder بإنشاء موجة الصوت النهائية.

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/audio-course-images/resolve/main/speecht5.png" alt="SpeechT5 يخرج مخططًا طيفيًا ويستخدم vocoder لإنشاء الموجة">
</div>

<Tip>
💡 إذا كنت تأخذ موجة موجودة وتطبق تحويل فورييه قصير المدى أو STFT، فيمكنك إجراء العملية العكسية، أي ISTFT، للحصول على الموجة الأصلية مرة أخرى. يعمل هذا لأن المخطط الطيفي الذي تم إنشاؤه بواسطة STFT يحتوي على كل من معلومات السعة والطور، وكلاهما مطلوب لإعادة بناء الموجة. ومع ذلك، فإن نماذج الصوت التي تولد إخراجها كمخطط طيفي تتنبأ عادةً بمعلومات السعة فقط، وليس الطور. لتحويل مثل هذا المخطط الطيفي إلى موجة، يجب علينا بطريقة ما تقدير معلومات الطور. هذا ما يفعله vocoder.
</Tip>

### إخراج الموجة

من الممكن أيضًا أن تقوم النماذج بإخراج الموجة مباشرة بدلاً من المخطط الطيفي كخطوة وسيطة، ولكن لا توجد حاليًا أي نماذج في 🤗 المحولات التي تقوم بذلك.

## الخلاصة

ملخص: معظم نماذج المحول الصوتي متشابهة أكثر من الاختلاف - فهي جميعها مبنية على نفس هندسة المحول وطبقات الاهتمام، على الرغم من أن بعض النماذج ستستخدم فقط جزء المشفر من المحول بينما يستخدم البعض الآخر كل من المشفر وفك التشفير.

لقد رأيت أيضًا كيفية إدخال بيانات الصوت وإخراجها من نماذج المحول. لأداء مهام الصوت المختلفة لـ ASR وTTS، وما إلى ذلك، يمكننا ببساطة استبدال الطبقات التي تقوم بمعالجة الإدخالات إلى التضمينات، واستبدال الطبقات التي تقوم بمعالجة التضمينات المتوقعة إلى الإخراج، في حين أن العمود الفقري للمحول يبقى كما هو.

بعد ذلك، دعنا نلقي نظرة على بعض الطرق المختلفة التي يمكن بها تدريب هذه النماذج على التعرف على الكلام التلقائي.