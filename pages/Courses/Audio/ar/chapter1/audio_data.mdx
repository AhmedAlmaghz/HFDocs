# مقدمة في بيانات الصوت

في الطبيعة، الموجة الصوتية هي إشارة مستمرة، وهذا يعني أنها تحتوي على عدد لا نهائي من قيم الإشارة في وقت معين.
ويسبب هذا مشكلات للأجهزة الرقمية التي تتوقع مصفوفات محدودة. ولكي تتم معالجة الموجة الصوتية المستمرة وتخزينها ونقلها بواسطة الأجهزة الرقمية، يجب تحويلها إلى سلسلة من القيم المنفصلة، تعرف بالتمثيل الرقمي.

إذا نظرت إلى أي مجموعة بيانات صوتية، فستجد ملفات رقمية بمقتطفات صوتية، مثل السرد النصي أو الموسيقى.
وقد تصادف تنسيقات ملفات مختلفة مثل `.wav` (ملف صوتي موجي)، `.flac` (ترميز الصوت غير المضغوط المجاني)
و`.mp3` (طبقة الصوت MPEG-1 رقم 3). تختلف هذه التنسيقات بشكل رئيسي في كيفية ضغطها للتمثيل الرقمي للإشارة الصوتية.

دعونا نلقي نظرة على كيفية وصولنا من إشارة مستمرة إلى هذا التمثيل. أولاً، يتم التقاط الإشارة التناظرية
بواسطة ميكروفون، والذي يحول الموجات الصوتية إلى إشارة كهربائية. ثم يتم تحويل الإشارة الكهربائية إلى إشارة رقمية بواسطة
محول تناظري رقمي للحصول على التمثيل الرقمي من خلال المعاينة.

## المعاينة ومعدل المعاينة

المعاينة هي عملية قياس قيمة إشارة مستمرة في خطوات زمنية ثابتة. الموجة المعاينة _منفصلة_،
بما أنه يحتوي على عدد محدود من قيم الإشارة بفترات متساوية.

*توضيح من مقال ويكيبيديا: [المعاينة (معالجة الإشارات)](<https://en.wikipedia.org/wiki/Sampling_(signal_processing)>)*

**معدل المعاينة** (يسمى أيضًا تردد المعاينة) هو عدد العينات المأخوذة في الثانية الواحدة ويقاس
بالهرتز (Hz). لإعطائك نقطة مرجعية، فإن الصوت بجودة الأقراص المدمجة له معدل معاينة يبلغ 44100 هرتز، مما يعني أن العينات تؤخذ
44100 مرة في الثانية. للمقارنة، الصوت عالي الدقة له معدل معاينة يبلغ 192000 هرتز أو 192 كيلو هرتز. معدل المعاينة الشائع
المستخدم في تدريب نماذج الكلام هو 16000 هرتز أو 16 كيلو هرتز.

يحدد اختيار معدل المعاينة بشكل أساسي أعلى تردد يمكن التقاطه من الإشارة. وهذا يعرف أيضًا
بحد نايكويست وهو نصف معدل المعاينة بالضبط. الترددات المسموعة في الكلام البشري أقل من 8 كيلو هرتز
لذلك فإن معاينة الكلام عند 16 كيلو هرتز كافية. ولن يؤدي استخدام معدل معاينة أعلى إلى التقاط المزيد من المعلومات
ويؤدي ببساطة إلى زيادة التكلفة الحسابية لمعالجة مثل هذه الملفات. من ناحية أخرى، فإن معاينة الصوت بمعدل معاينة منخفض جدًا
سيسفر عن فقدان المعلومات. وسيبدو الكلام الذي تمت معاينته عند 8 كيلو هرتز مكتومًا، حيث لا يمكن التقاط الترددات الأعلى
بهذا المعدل.

من المهم التأكد من أن جميع الأمثلة الصوتية في مجموعة البيانات الخاصة بك لها نفس معدل المعاينة عند العمل في أي مهمة صوتية.
إذا كنت تخطط لاستخدام بيانات صوتية مخصصة لتدقيق نموذج مسبق التدريب، فيجب أن يتطابق معدل معاينة بياناتك
مع معدل معاينة البيانات التي تم تدريب النموذج عليها مسبقًا. يحدد معدل المعاينة الفاصل الزمني بين عينات الصوت المتتالية
والذي يؤثر على الدقة الزمنية لبيانات الصوت. ضع في اعتبارك مثالاً: صوت لمدة 5 ثوانٍ بمعدل معاينة يبلغ 16000 هرتز
سيتم تمثيله على أنه سلسلة من 80000 قيمة، في حين أن نفس الصوت الذي يبلغ مدته 5 ثوانٍ بمعدل معاينة يبلغ
8000 هرتز سيتم تمثيله على أنه سلسلة من 40000 قيمة. تعامل نماذج المحول التي تحل المهام الصوتية الأمثلة على أنها
تسلسلات وتعتمد على آليات الاهتمام لتعلم التمثيل الصوتي أو متعدد الوسائط. نظرًا لأن التسلسلات تختلف بالنسبة
لأمثلة الصوت عند معدلات معاينة مختلفة، فسيكون من الصعب على النماذج تعميمها بين معدلات المعاينة.

**إعادة المعاينة** هي عملية مطابقة معدلات المعاينة، وهي جزء من [معالجة](<preprocessing#resampling-the-audio-data>) بيانات الصوت.

## السعة وعمق البت

في حين أن معدل المعاينة يخبرك بمدى تكرار أخذ العينات، فما هي القيم الموجودة في كل عينة على وجه التحديد؟

يتم إنشاء الصوت عن طريق التغييرات في ضغط الهواء بترددات يمكن للإنسان سماعها. **سعة** الصوت تصف
مستوى ضغط الصوت في أي لحظة معينة ويقاس بالديسيبل (dB). ندرك السعة على أنها شدة الصوت.
لإعطائك مثالاً، يكون صوت التحدث العادي أقل من 60 ديسيبل، ويمكن أن تصل حفل موسيقى الروك إلى حوالي 125 ديسيبل، مما يدفع
حدود السمع البشري.

في الصوت الرقمي، يسجل كل عينة صوتية سعة موجة الصوت في لحظة معينة. **عمق البت** للعينة
يحدد دقة وصف هذه القيمة السعة. وكلما زاد عمق البت، زادت دقة التمثيل الرقمي في تقريب الموجة الصوتية المستمرة الأصلية.

تبلغ أعماق البت الصوتية الأكثر شيوعًا 16 بت و24 بت. كل منهما مصطلح ثنائي، يمثل عدد الخطوات الممكنة
التي يمكن بها تحويل قيمة السعة عند تحويلها من مستمر إلى منفصل: 65536 خطوة للصوت 16 بت،
و16777216 خطوة للصوت 24 بت. نظرًا لأن التكميم ينطوي على تقريب القيمة المستمرة إلى قيمة منفصلة، فإن عملية المعاينة
تقدم ضوضاء. وكلما زاد عمق البت، قل ضجيج التكميم هذا. في الممارسة العملية، يكون ضجيج التكميم في الصوت 16 بت
صغيرًا بدرجة كافية بحيث لا يمكن سماعه، وعادةً لا تكون هناك حاجة لاستخدام أعماق بت أعلى.

قد تصادف أيضًا صوت 32 بت. يقوم هذا بتخزين العينات كقيم ذات نقطة عائمة، في حين أن الصوت 16 بت و24 بت
استخدم عينات صحيحة. تبلغ دقة القيمة ذات النقطة العائمة 32 بت 24 بت، مما يمنحها نفس عمق البت مثل الصوت 24 بت.
من المتوقع أن تكون عينات الصوت ذات النقطة العائمة ضمن النطاق [-1.0، 1.0]. نظرًا لأن نماذج التعلم الآلي تعمل بشكل طبيعي
على بيانات ذات نقطة عائمة، يجب أولاً تحويل الصوت إلى تنسيق ذي نقطة عائمة قبل استخدامه لتدريب
النموذج. سنرى كيفية القيام بذلك في القسم التالي حول [معالجة](<preprocessing>)البيانات.

كما هو الحال مع الإشارات الصوتية المستمرة، يتم التعبير عن سعة الصوت الرقمي عادةً بالديسيبل (dB). نظرًا لأن
السمع البشري له طبيعة لوغاريتمية - حيث تكون آذاننا أكثر حساسية للتقلبات الصغيرة في الأصوات الهادئة أكثر من الأصوات العالية
من الأسهل تفسير شدة الصوت إذا كانت السعات بالديسيبل، والتي تكون لوغاريتمية أيضًا.
يبدأ مقياس الديسيبل للصوت في العالم الحقيقي عند 0 ديسيبل، والذي يمثل أكثر الأصوات هدوءًا التي يمكن للإنسان سماعها،
وتكون الأصوات الأعلى لها قيم أكبر. ومع ذلك، بالنسبة لإشارات الصوت الرقمية، فإن 0 ديسيبل هو أعلى سعة ممكنة، في حين أن جميع
السعات الأخرى سلبية. كقاعدة عامة: كل -6 ديسيبل هو نصف السعة، وأي شيء أقل من -60 ديسيبل
غير مسموع بشكل عام ما لم تقم بتشغيل الصوت فعليًا.

## الصوت كموجة

قد تكون شاهدت أصواتًا مرئية كـ**موجة**، والتي ترسم قيم العينات بمرور الوقت وتوضح التغييرات
في سعة الصوت. وهذا ما يسمى أيضًا تمثيل *النطاق الزمني* للصوت.

هذا النوع من التصور مفيد لتحديد ميزات محددة للإشارة الصوتية مثل توقيت أحداث الصوت الفردية،
وشدة الإشارة بشكل عام، وأي مخالفات أو ضوضاء موجودة في الصوت.

لرسم الموجة لإشارة صوتية، يمكننا استخدام مكتبة بايثون تسمى `ليبروسا`:

```bash
pip install librosa
```

دعونا نأخذ مثالًا على صوت يسمى "trumpet" يأتي مع المكتبة:

```py
import librosa

array, sampling_rate = librosa.load(librosa.ex("trumpet"))
```

يتم تحميل المثال كزوج مرتب من سلسلة الوقت (هنا نسميه `array`)، ومعدل المعاينة (`sampling_rate`).
دعونا نلقي نظرة على موجة هذا الصوت باستخدام دالة `waveshow()` في ليبروسا:

```py
import matplotlib.pyplot as plt
import librosa.display

plt.figure().set_figwidth(12)
librosa.display.waveshow(array, sr=sampling_rate)
```

يرسم هذا مخططًا لسعة الإشارة على المحور y والوقت على طول المحور x. وبعبارة أخرى، تتوافق كل نقطة مع
قيمة عينة واحدة تم أخذها عند معاينة هذا الصوت. لاحظ أيضًا أن ليبروسا تعيد الصوت كقيم ذات نقطة عائمة بالفعل،
وأن قيم السعة تقع بالفعل ضمن النطاق [-1.0، 1.0].

يمكن أن يكون تصور الصوت إلى جانب الاستماع إليه أداة مفيدة لفهم البيانات التي تعمل بها.
يمكنك رؤية شكل الإشارة، ومراقبة الأنماط، وتعلم اكتشاف الضوضاء أو التشويه. إذا قمت بمعالجة البيانات ببعض الطرق
مثل التطبيع أو إعادة المعاينة أو التصفية، فيمكنك التأكد بصريًا من تطبيق خطوات المعالجة المتوقعة.
بعد تدريب نموذج، يمكنك أيضًا تصور العينات التي تحدث فيها الأخطاء (على سبيل المثال، في مهمة تصنيف الصوت) لتصحيح
المشكلة.

## الطيف الترددي

هناك طريقة أخرى لتصور بيانات الصوت وهي رسم **الطيف الترددي** لإشارة صوتية، والمعروف أيضًا باسم التمثيل *النطاق الترددي*.
يتم حساب الطيف باستخدام التحويل المتقطع فورييه أو DFT. فهو يصف الترددات الفردية
التي تشكل الإشارة وقوتها.

دعونا نرسم الطيف الترددي لنفس صوت البوق عن طريق أخذ DFT باستخدام دالة `rfft()` في نومبي. في حين أنه
من الممكن رسم طيف الصوت بالكامل، من المفيد أكثر النظر في منطقة صغيرة بدلاً من ذلك. هنا سنأخذ
DFT على مدى أول 4096 عينة، وهو ما يقرب من طول الملاحظة الأولى التي يتم تشغيلها:

```py
import numpy as np

dft_input = array[:4096]

# احسب DFT
النافذة = np.hanning(len(dft_input))
windowed_input = dft_input * window
dft = np.fft.rfft(windowed_input)

# احصل على الطيف السعة بالديسيبل
السعة = np.abs(dft)
السعة_db = librosa.amplitude_to_db(amplitude، ref=np.max)

# احصل على صناديق التردد
التردد = librosa.fft_frequencies(sr=sampling_rate, n_fft=len(dft_input))

plt.figure().set_figwidth(12)
plt.plot(frequency, amplitude_db)
plt.xlabel("Frequency (Hz)")
plt.ylabel("Amplitude (dB)")
plt.xscale("log")
```

يرسم هذا مخططًا لقوة مكونات التردد المختلفة الموجودة في هذا الجزء الصوتي. تكون قيم التردد على
المحور x، وعادة ما يتم رسمها على مقياس لوغاريتمي، في حين تكون السعات على المحور y.

يظهر الطيف الترددي الذي قمنا برسمه عدة قمم. تتوافق هذه القمم مع توافقيات الملاحظة التي يتم تشغيلها،
مع كون التوافقيات الأعلى أكثر هدوءًا. نظرًا لأن القمة الأولى تبلغ حوالي 620 هرتز، فإن هذا هو الطيف الترددي لملاحظة E♭.

الناتج من DFT هو مصفوفة من الأعداد المركبة، تتكون من مكونات حقيقية وخيالية. أخذ
القيمة المطلقة مع `np.abs(dft)` يستخرج معلومات السعة من المخطط الطيفي. توفر الزاوية بين المكونات الحقيقية
والخيالية ما يسمى الطيف الطوري، ولكن يتم تجاهله غالبًا في تطبيقات التعلم الآلي.

لقد استخدمت `librosa.amplitude_to_db()` لتحويل قيم السعة إلى مقياس الديسيبل، مما يسهل رؤية
التفاصيل الدقيقة في الطيف. يستخدم بعض الأشخاص **مخطط الطاقة**، والذي يقيس الطاقة بدلاً من السعة؛
هذا هو ببساطة طيف بقيم السعة تربيع.

💡 في الممارسة العملية، يستخدم الأشخاص مصطلح FFT بشكل متبادل مع DFT، حيث أن FFT أو التحويل فورييه السريع هو الطريقة الوحيدة الفعالة
لحساب DFT على جهاز كمبيوتر.

يحتوي الطيف الترددي لإشارة صوتية على نفس المعلومات تمامًا مثل موجتها - فهي ببساطة طريقتان مختلفتان للنظر إلى نفس البيانات (هنا،
أول 4096 عينة من صوت البوق). في حين أن الموجة ترسم سعة إشارة الصوت بمرور الوقت، فإن الطيف يرسم سعات الترددات الفردية
في نقطة ثابتة في الوقت المناسب.
## المخطط الطيفي

ماذا لو أردنا أن نرى كيف تتغير الترددات في إشارة صوتية؟ إن البوق يعزف عدة نوتات موسيقية وكل منها له تردد مختلف. المشكلة هي أن الطيف لا يظهر سوى لقطة ثابتة للترددات في لحظة معينة. والحل هو أخذ عدة تحولات فورييه منفصلة، حيث يغطي كل منها شريحة زمنية صغيرة فقط، وتكديس الطيف الناتج معًا في ما يسمى **"مخطط طيفي"**.

يرسم المخطط الطيفي المحتوى الترددي لإشارة صوتية أثناء تغيرها بمرور الوقت. فهو يسمح برؤية الوقت والتردد والشدة على رسم بياني واحد. والخوارزمية التي تقوم بهذا الحساب هي تحويل فورييه قصير الوقت (STFT).

يعد المخطط الطيفي أحد أكثر الأدوات الصوتية إفادة المتاحة لك. على سبيل المثال، عند العمل مع تسجيل موسيقي، يمكنك رؤية مختلف الآلات الموسيقية والمسارات الصوتية وكيف تساهم في الصوت العام. وفي الكلام، يمكنك التعرف على أصوات حروف العلة المختلفة لأن كل حرف علة يتميز بترددات معينة.

دعونا نرسم مخططًا طيفيًا لنفس صوت البوق، باستخدام دالتَي `stft()` و`specshow()` في مكتبة ليبروسا:

```py
import numpy as np

D = librosa.stft(array)
S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)

plt.figure().set_figwidth(12)
librosa.display.specshow(S_db, x_axis="time", y_axis="hz")
plt.colorbar()
```

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/audio-course-images/resolve/main/spectrogram_plot.png" alt="مخطط طيفي" />
</div>

في هذا الرسم، يمثل المحور x الوقت كما هو الحال في تخيل الشكل الموجي، لكن الآن يمثل المحور y التردد بالهرتز. ويشير شدة اللون إلى شدة أو قدرة المكون الترددي في كل نقطة زمنية، مقاسة بالديسيبل (dB).

يتم إنشاء المخطط الطيفي عن طريق أخذ مقاطع قصيرة من الإشارة الصوتية، عادة ما تستمر بضع مللي ثانية، وحساب تحويل فورييه المتقطع لكل مقطع للحصول على طيف التردد الخاص به. ثم يتم تكديس الأطياف الناتجة معًا على محور الوقت لإنشاء المخطط الطيفي. ويمثل كل شريحة رأسية في هذه الصورة طيف تردد واحد، كما هو موضح من الأعلى. وبشكل افتراضي، تقسم دالة `librosa.stft()` الإشارة الصوتية إلى مقاطع يبلغ طولها 2048 عينة، مما يوفر حل وسط جيدًا بين دقة التردد ودقة الوقت.

نظرًا لأن المخطط الطيفي والشكل الموجي هما وجهان مختلفان لنفس البيانات، فمن الممكن إعادة تحويل المخطط الطيفي إلى الشكل الموجي الأصلي باستخدام عكس STFT. ومع ذلك، يتطلب ذلك معلومات الطور بالإضافة إلى معلومات الشدة. إذا تم إنشاء المخطط الطيفي بواسطة نموذج تعلم آلي، فإنه عادةً ما يقوم بإخراج الشدات فقط. في هذه الحالة، يمكننا استخدام خوارزمية إعادة بناء الطور، مثل خوارزمية غريفيث-ليم الكلاسيكية، أو استخدام شبكة عصبية تسمى محول ترميز النبضات، لإعادة بناء شكل موجي من المخطط الطيفي.

لا تستخدم المخططات الطيفية للتصوير فقط. حيث يتخذ العديد من نماذج التعلم الآلي المخططات الطيفية كمدخلات - على عكس الأشكال الموجية - وتنتج مخططات طيفية كإخراج.

الآن بعد أن عرفنا ما هو المخطط الطيفي وكيف يتم صنعه، دعونا نلقي نظرة على أحد أشكاله المستخدمة على نطاق واسع في معالجة الكلام: المخطط الطيفي الميل.

## المخطط الطيفي الميل

المخطط الطيفي الميل هو تنويع للمخطط الطيفي يستخدم عادة في معالجة الكلام ومهام التعلم الآلي. وهو يشبه المخطط الطيفي في أنه يظهر المحتوى الترددي لإشارة صوتية بمرور الوقت، ولكن على محور تردد مختلف.

في المخطط الطيفي القياسي، يكون محور التردد خطيًا ويقاس بالهرتز (Hz). ومع ذلك، فإن الجهاز السمعي البشري أكثر حساسية للتغيرات في الترددات المنخفضة منه في الترددات العالية، وتقل هذه الحساسية بشكل لوغاريتمي مع زيادة التردد. والمقياس الميل هو مقياس إدراكي يقارب استجابة التردد غير الخطية للأذن البشرية.

لإنشاء مخطط طيفي ميل، يتم استخدام تحويل فورييه قصير الوقت (STFT) كما هو موضح سابقًا، عن طريق تقسيم الصوت إلى مقاطع قصيرة للحصول على تسلسل من أطياف الترددات. بالإضافة إلى ذلك، يتم تمرير كل طيف عبر مجموعة من المرشحات، ما يسمى بنك مرشحات الميل، لتحويل الترددات إلى المقياس الميل.

دعونا نرى كيف يمكننا رسم مخطط طيفي ميل باستخدام دالة `melspectrogram()` في مكتبة ليبروسا، والتي تقوم بجميع هذه الخطوات نيابة عنا:

```py
S = librosa.feature.melspectrogram(y=array, sr=sampling_rate, n_mels=128, fmax=8000)
S_dB = librosa.power_to_db(S, ref=np.max)

plt.figure().set_figwidth(12)
librosa.display.specshow(S_dB, x_axis="time", y_axis="mel", sr=sampling_rate, fmax=8000)
plt.colorbar()
```

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/huggingface-course/audio-course-images/resolve/main/mel-spectrogram.png" alt="رسم بياني لمخطط طيفي ميل" />
</div>

في المثال أعلاه، تمثل `n_mels` عدد نطاقات الميل المراد إنشاؤها. وتحدد نطاقات الميل مجموعة من نطاقات التردد التي تقسم الطيف إلى مكونات ذات معنى إدراكي، باستخدام مجموعة من المرشحات التي يتم اختيار شكلها ومسافتها لمحاكاة استجابة الأذن البشرية لمختلف الترددات. والقيم الشائعة لـ `n_mels` هي 40 أو 80. ويشير `fmax` إلى أعلى تردد (بالهرتز) نهتم به.

وكما هو الحال مع المخطط الطيفي العادي، من الشائع التعبير عن قوة مكونات التردد الميل بالديسيبل. ويشار إلى هذا عادة باسم **"مخطط طيفي لوغاريتمي ميل"**، لأن التحويل إلى الديسيبل ينطوي على عملية لوغاريتمية. وقد استخدم المثال أعلاه دالة `librosa.power_to_db()` لأن دالة `librosa.feature.melspectrogram()` تقوم بإنشاء مخطط طيفي للقوة.

<Tip>
💡 ليست جميع المخططات الطيفية الميل متشابهة! هناك مقياسان ميليان مختلفان شائعان ("htk" و"slaney")، وبدلاً من مخطط طيفي للقوة، قد يتم استخدام مخطط طيفي للشدة. ولا يحسب التحويل إلى مخطط طيفي لوغاريتمي ميل دائمًا الديسيبل الحقيقي، ولكنه قد يأخذ ببساطة اللوغاريتم. لذلك، إذا كان نموذج التعلم الآلي يتوقع مخططًا طيفيًا ميل كمدخل، فتأكد من حسابه بنفس الطريقة.
</Tip>

إن إنشاء مخطط طيفي ميل هو عملية فقد للبيانات لأنه ينطوي على تصفية الإشارة. وتحويل مخطط طيفي ميل مرة أخرى إلى شكل موجي أكثر صعوبة من القيام بذلك لمخطط طيفي عادي، لأنه يتطلب تقدير الترددات التي تم التخلص منها. وهذا هو السبب في الحاجة إلى نماذج التعلم الآلي مثل محول ترميز النبضات HiFiGAN لإنتاج شكل موجي من مخطط طيفي ميل.

مقارنة بالمخطط الطيفي القياسي، يمكن للمخطط الطيفي الميل التقاط المزيد من الميزات ذات المعنى للإشارة الصوتية بالنسبة للإدراك البشري، مما يجعله خيارًا شائعًا في مهام مثل التعرف على الكلام، وتحديد المتحدث، وتصنيف نوع الموسيقى.

والآن بعد أن عرفت كيفية تصور أمثلة البيانات الصوتية، جرّب أن ترى كيف تبدو أصواتك المفضلة. :)