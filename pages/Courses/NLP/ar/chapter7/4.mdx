لم يتم ترجمة الأجزاء التي تحتوي على أكواد برمجية أو روابط أو رموز HTML و CSS، كما هو مطلوب. فيما يلي ترجمة بقية النص:

# الترجمة

دعونا الآن نغوص في الترجمة. هذه هي مهمة أخرى [تسلسل إلى تسلسل](/course/chapter1/7)، وهذا يعني أنها مشكلة يمكن صياغتها على أنها الانتقال من تسلسل إلى آخر. بهذا المعنى، فإن المشكلة قريبة جدًا من [التلخيص](/course/chapter7/6)، ويمكنك تكييف ما سنراه هنا مع مشكلات أخرى تتعلق بالتسلسل إلى تسلسل مثل:

- **نقل الأسلوب**: إنشاء نموذج *يترجم* النصوص المكتوبة بأسلوب معين إلى آخر (على سبيل المثال، من الأسلوب الرسمي إلى غير الرسمي أو من اللغة الإنجليزية الشكسبيرية إلى اللغة الإنجليزية الحديثة)
- **الاستجابة للأسئلة التوليدية**: إنشاء نموذج يولد إجابات للأسئلة، بالنظر إلى سياق معين

إذا كان لديك مجموعة بيانات كبيرة بما يكفي من النصوص بلغتين (أو أكثر)، فيمكنك تدريب نموذج ترجمة جديد من الصفر كما سنفعل في القسم الخاص [بنمذجة اللغة السببية](/course/chapter7/6). ومع ذلك، سيكون من الأسرع ضبط نموذج ترجمة موجود، سواء كان نموذجًا متعدد اللغات مثل mT5 أو mBART الذي تريد ضبطه لزوج لغوي محدد، أو حتى نموذج متخصص للترجمة من لغة إلى أخرى وتريد ضبطه لمجموعة البيانات الخاصة بك.

في هذا القسم، سنقوم بضبط نموذج ماريان المعلم مسبقًا للترجمة من الإنجليزية إلى الفرنسية (حيث يتحدث العديد من موظفي Hugging Face كلتا اللغتين) على مجموعة بيانات [KDE4](https://huggingface.co/datasets/kde4)، والتي هي مجموعة بيانات للملفات الموضعية لتطبيقات [KDE](https://apps.kde.org/). تم تعليم النموذج الذي سنستخدمه مسبقًا على مجموعة كبيرة من النصوص الفرنسية والإنجليزية المأخوذة من مجموعة بيانات [Opus](https://opus.nlpl.eu/)، والتي تحتوي بالفعل على مجموعة بيانات KDE4. ولكن حتى إذا رأى النموذج المعلم مسبقًا هذه البيانات أثناء تعلمه المسبق، فسوف نرى أنه يمكننا الحصول على نسخة أفضل منه بعد الضبط الدقيق.

بمجرد الانتهاء، سنحصل على نموذج قادر على تقديم تنبؤات مثل هذا:

بمجرد الانتهاء، سنتمكن من استخدام النموذج لتقديم تنبؤات مثل تلك الموجودة في الصورة أدناه:

![صورة لتنبؤات النموذج](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/modeleval-marian-finetuned-kde4-en-to-fr.png)

كما هو الحال في الأقسام السابقة، يمكنك العثور على النموذج الفعلي الذي سنقوم بتدريبه وتحميله إلى Hub باستخدام الكود أدناه والتحقق المزدوج من تنبؤاته [هنا](https://huggingface.co/huggingface-course/marian-finetuned-kde4-en-to-fr?text=This+plugin+allows+you+to+automatically+translate+web+pages+between+several+languages.)

## إعداد البيانات

لضبط أو تدريب نموذج ترجمة من الصفر، سنحتاج إلى مجموعة بيانات مناسبة للمهمة. كما ذكرنا سابقًا، سنستخدم مجموعة بيانات [KDE4](https://huggingface.co/datasets/kde4) في هذا القسم، ولكن يمكنك تكييف الكود لاستخدام بياناتك الخاصة بسهولة، طالما أن لديك أزواج من الجمل بلغتين تريد الترجمة منهما وإليهما. راجع [الفصل 5](/course/chapter5) إذا كنت بحاجة إلى تذكير بكيفية تحميل بياناتك المخصصة في `مجموعة بيانات`.

### مجموعة بيانات KDE4

كما هو معتاد، نقوم بتنزيل مجموعة البيانات الخاصة بنا باستخدام دالة `load_dataset()` :

```py
from datasets import load_dataset

raw_datasets = load_dataset("kde4", lang1="en", lang2="fr")
```

إذا كنت تريد العمل مع زوج مختلف من اللغات، فيمكنك تحديدها بواسطة رموزها. هناك ما مجموعه 92 لغة متاحة لمجموعة البيانات هذه؛ يمكنك رؤيتها جميعًا عن طريق توسيع علامات اللغة على [بطاقة مجموعة البيانات](https://huggingface.co/datasets/kde4) الخاصة بها.

![اللغات المتاحة لمجموعة بيانات KDE4](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/language_tags.png)

دعونا نلقي نظرة على مجموعة البيانات:

```py
raw_datasets
```

```python out
DatasetDict({
train: Dataset({
features: ['id', 'translation'],
num_rows: 210173
})
})
```

لدينا 210,173 زوجًا من الجمل، ولكن في قسم واحد، لذلك سيتعين علينا إنشاء مجموعة التحقق الخاصة بنا. كما رأينا في [الفصل 5](/course/chapter5)، تحتوي `مجموعة البيانات` على طريقة `train_test_split()` التي يمكن أن تساعدنا. سنقدم بذرة للتكرار:

```py
split_datasets = raw_datasets["train"].train_test_split(train_size=0.9, seed=20)
split_datasets
```

```python out
DatasetDict({
train: Dataset({
features: ['id', 'translation'],
num_rows: 189155
})
test: Dataset({
features: ['id', 'translation'],
num_rows: 21018
})
})
```

يمكننا إعادة تسمية مفتاح `"test"` إلى `"validation"` بهذه الطريقة:

```py
split_datasets["validation"] = split_datasets.pop("test")
```

الآن دعونا نلقي نظرة على أحد عناصر مجموعة البيانات:

```py
split_datasets["train"][1]["translation"]
```

```python out
{'en': 'Default to expanded threads',
'fr': 'Par défaut, développer les fils de discussion'}
```

نحصل على قاموس بجملتين في زوج اللغات الذي طلبناه. إحدى مميزات هذه المجموعة من البيانات المليئة بمصطلحات علوم الكمبيوتر الفنية هي أنها مترجمة بالكامل إلى الفرنسية. ومع ذلك، يترك المهندسون الفرنسيون معظم الكلمات الخاصة بعلوم الكمبيوتر باللغة الإنجليزية عندما يتحدثون. هنا، على سبيل المثال، قد تظهر كلمة "threads" في جملة فرنسية، خاصة في محادثة فنية؛ ولكن في هذه المجموعة من البيانات، تمت ترجمتها إلى "fils de discussion" الأكثر صحة. يختار النموذج المعلم مسبقًا، والذي تم تعليمه مسبقًا على مجموعة أكبر من الجمل الفرنسية والإنجليزية، الخيار الأسهل المتمثل في ترك الكلمة كما هي:

```py
from transformers import pipeline

model_checkpoint = "Helsinki-NLP/opus-mt-en-fr"
translator = pipeline("translation", model=model_checkpoint)
translator("Default to expanded threads")
```

```python out
[{'translation_text': 'Par défaut pour les threads élargis'}]
```

يمكن رؤية مثال آخر على هذا السلوك مع كلمة "plugin"، والتي ليست كلمة فرنسية رسمية ولكن معظم المتحدثين الأصليين يفهمونها ولن يكلفوا أنفسهم عناء ترجمتها.

في مجموعة بيانات KDE4، تمت ترجمة هذه الكلمة إلى الفرنسية إلى "module d'extension" الأكثر رسمية:

```py
split_datasets["train"][172]["translation"]
```

```python out
{'en': 'Unable to import %1 using the OFX importer plugin. This file is not the correct format.',
'fr': "Impossible d'importer %1 en utilisant le module d'extension d'importation OFX. Ce fichier n'a pas un format correct."}
```

ومع ذلك، يلتزم نموذجنا المعلم مسبقًا بالكلمة الإنجليزية المألوفة والمدمجة:

```py
translator(
"Unable to import %1 using the OFX importer plugin. This file is not the correct format."
)
```

```python out
[{'translation_text': "Impossible d'importer %1 en utilisant le plugin d'importateur OFX. Ce fichier n'est pas le bon format."}]
```

سيكون من المثير للاهتمام أن نرى إذا كان نموذجنا المضبوط الدقيق يلتقط تلك الخصائص الخاصة بمجموعة البيانات (تنبيه المفسد: سوف يفعل).

<Youtube id="0Oxphw4Q9fo"/>

<Tip>

✏️ **جرب بنفسك!** كلمة إنجليزية أخرى تستخدم غالبًا في الفرنسية هي "email". ابحث عن أول عينة في مجموعة التدريب التي تستخدم هذه الكلمة. كيف يتم ترجمتها؟ كيف يترجم النموذج المعلم مسبقًا نفس الجملة الإنجليزية؟

</Tip>
### معالجة البيانات

يجب عليك الآن أن تكون على دراية بالروتين: يجب تحويل جميع النصوص إلى مجموعات من رموز التعريف حتى يتمكن النموذج من فهمها. بالنسبة لهذه المهمة، سنقوم بتوكينز المدخلات والأهداف. تتمثل مهمتنا الأولى في إنشاء كائن tokenizer. كما ذكرنا سابقًا، سنستخدم نموذجًا مسبق التدريب من Marian English إلى French. إذا كنت تحاول استخدام هذه الشفرة مع زوج آخر من اللغات، فتأكد من تكييف نقطة تفتيش النموذج. توفر منظمة [Helsinki-NLP](https://huggingface.co/Helsinki-NLP) أكثر من ألف نموذج بعدة لغات.

```python
from transformers import AutoTokenizer

model_checkpoint = "Helsinki-NLP/opus-mt-en-fr"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors="pt")
```

يمكنك أيضًا استبدال `model_checkpoint` بأي نموذج آخر تفضله من [Hub](https://huggingface.co/models)، أو مجلد محلي قمت بحفظ نموذج مسبق التدريب ومحول فيه.

<Tip>
💡 إذا كنت تستخدم محول لغة متعدد اللغات مثل mBART أو mBART-50 أو M2M100، فستحتاج إلى تعيين رموز لغة المدخلات والأهداف في المحول من خلال تعيين `tokenizer.src_lang` و`tokenizer.tgt_lang` إلى القيم الصحيحة.
</Tip>

إن إعداد بياناتنا مباشر إلى حد ما. هناك شيء واحد فقط يجب تذكره؛ تحتاج إلى التأكد من أن المحول يرمز الأهداف في لغة الإخراج (الفرنسية هنا). يمكنك القيام بذلك عن طريق تمرير الأهداف إلى وسيط `text_targets` لأسلوب `__call__` للمحول.

لمعرفة كيفية عمل ذلك، دعنا نعالج عينة واحدة من كل لغة في مجموعة التدريب:

```python
en_sentence = split_datasets["train"][1]["translation"]["en"]
fr_sentence = split_datasets["train"][1]["translation"]["fr"]

inputs = tokenizer(en_sentence, text_target=fr_sentence)
inputs
```

```python out
{'input_ids': [47591, 12, 9842, 19634, 9, 0], 'attention_mask': [1, 1, 1, 1, 1, 1], 'labels': [577, 5891, 2, 3184, 16, 2542, 5, 1710, 0]}
```

كما نرى، يحتوي الإخراج على رموز تعريف الإدخال المرتبطة بالجملة الإنجليزية، بينما يتم تخزين رموز التعريف المرتبطة بالجملة الفرنسية في حقل `labels`. إذا نسيت الإشارة إلى أنك تقوم بتوكينز التصنيفات، فسيتم توكينزها بواسطة محول الإدخال، والذي في حالة نموذج Marian لن ينجح على الإطلاق:

```python
wrong_targets = tokenizer(fr_sentence)
print(tokenizer.convert_ids_to_tokens(wrong_targets["input_ids"]))
print(tokenizer.convert_ids_to_tokens(inputs["labels"]))
```

```python out
['▁Par', '▁dé', 'f', 'aut', ',', '▁dé', 've', 'lop', 'per', '▁les', '▁fil', 's', '▁de', '▁discussion', '</s>']
['▁Par', '▁défaut', ',', '▁développer', '▁les', '▁fils', '▁de', '▁discussion', '</s>']
```

كما نرى، يؤدي استخدام محول اللغة الإنجليزية لمعالجة جملة فرنسية إلى زيادة عدد الرموز، حيث لا يعرف المحول أي كلمات فرنسية (باستثناء تلك التي تظهر أيضًا في اللغة الإنجليزية، مثل "discussion").

نظرًا لأن `inputs` عبارة عن قاموس بمفاتيحنا المعتادة (رموز تعريف الإدخال، قناع الاهتمام، إلخ)، فإن الخطوة الأخيرة هي تحديد دالة المعالجة المسبقة التي سنطبقها على مجموعات البيانات:

```python
max_length = 128


def preprocess_function(examples):
    inputs = [ex["en"] for ex in examples["translation"]]
    targets = [ex["fr"] for ex in examples["translation"]]
    model_inputs = tokenizer(
        inputs, text_target=targets, max_length=max_length, truncation=True
    )
    return model_inputs
```

لاحظ أننا حددنا نفس الطول الأقصى لمدخلاتنا ومخرجاتنا. نظرًا لأن النصوص التي نتعامل معها تبدو قصيرة جدًا، نستخدم 128.

<Tip>
💡 إذا كنت تستخدم نموذج T5 (وبشكل أكثر تحديدًا، إحدى نقاط تفتيش `t5-xxx`)، فسيُتوقع من النموذج أن يكون للمدخلات النصية بادئة تشير إلى المهمة قيد التنفيذ، مثل `translate: English to French:`.
</Tip>

<Tip warning={true}>
⚠️ لا نهتم بقناع اهتمام الأهداف، حيث لن يتوقعها النموذج. بدلاً من ذلك، يجب تعيين التصنيفات المقابلة لرموز التعبئة إلى -100 حتى يتم تجاهلها في حساب الخسارة. سيتم ذلك بواسطة جامع البيانات الخاص بنا لاحقًا نظرًا لأننا نطبق التعبئة الديناميكية، ولكن إذا كنت تستخدم التعبئة هنا، فيجب عليك تكييف دالة المعالجة المسبقة لتعيين جميع التصنيفات التي تقابل رمز التعبئة إلى -100.
</Tip>

يمكننا الآن تطبيق هذه المعالجة المسبقة في خطوة واحدة على جميع تقسيمات مجموعة البيانات الخاصة بنا:

```py
tokenized_datasets = split_datasets.map(
    preprocess_function,
    batched=True,
    remove_columns=split_datasets["train"].column_names,
)
```

الآن بعد معالجة البيانات، نحن مستعدون لضبط نموذجنا المسبق التدريب!

{#if fw === 'pt'}
## ضبط دقيق للنموذج باستخدام واجهة برمجة تطبيقات Trainer

ستكون الشفرة الفعلية التي تستخدم `Trainer` هي نفسها كما كانت من قبل، مع تغيير واحد فقط: نستخدم [`Seq2SeqTrainer`](https://huggingface.co/transformers/main_classes/trainer.html#seq2seqtrainer) هنا، وهو فئة فرعية من `Trainer` ستسمح لنا بالتعامل بشكل صحيح مع التقييم، باستخدام طريقة `generate()` للتنبؤ بالمخرجات من المدخلات. سنغوص في ذلك بمزيد من التفاصيل عند حديثنا عن حساب المقياس.

أولًا، نحتاج إلى نموذج فعلي لضبطه بدقة. سنستخدم واجهة برمجة تطبيقات `AutoModel` المعتادة:

```py
from transformers import AutoModelForSeq2SeqLM

model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)
```

{:else}
## ضبط دقيق للنموذج باستخدام Keras

أولًا، نحتاج إلى نموذج فعلي لضبطه بدقة. سنستخدم واجهة برمجة تطبيقات `AutoModel` المعتادة:

```py
from transformers import TFAutoModelForSeq2SeqLM

model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint, from_pt=True)
```

<Tip warning={false}>
💡 تحتوي نقطة تفتيش `Helsinki-NLP/opus-mt-en-fr` على أوزان PyTorch فقط، لذا فستحصل على خطأ إذا حاولت تحميل النموذج دون استخدام وسيط `from_pt=True` في طريقة `from_pretrained()`. عندما تحدد `from_pt=True`، سيقوم المكتبة تلقائيًا بتنزيل الأوزان وتحويلها من PyTorch من أجلك. كما ترى، من السهل جدًا التبديل بين الأطر في 🤗 Transformers!
</Tip>

{/if}

لاحظ أننا هذه المرة نستخدم نموذجًا تم تدريبه على مهمة الترجمة ويمكن استخدامه بالفعل، لذا لا يوجد تحذير بشأن الأوزان المفقودة أو التي تم تهيئتها حديثًا.

### تجميع البيانات

سنحتاج إلى جامع بيانات للتعامل مع التعبئة للتغذية الدفعية الديناميكية. لا يمكننا استخدام `DataCollatorWithPadding` كما هو الحال في [الفصل 3](/course/chapter3) في هذه الحالة، لأن ذلك يقوم فقط بتعبئة المدخلات (رموز تعريف الإدخال، وقناع الاهتمام، وأنواع رموز التعريف). يجب أيضًا تعبئة التصنيفات لدينا إلى الطول الأقصى الذي تمت مواجهته في التصنيفات. وكما ذكرنا سابقًا، يجب أن تكون قيمة التعبئة المستخدمة لتعبئة التصنيفات `-100` وليس رمز التعبئة للمحول، للتأكد من تجاهل هذه القيم المبادة في حساب الخسارة.

يتم ذلك كله بواسطة [`DataCollatorForSeq2Seq`](https://huggingface.co/transformers/main_classes/data_collator.html#datacollatorforseq2seq). مثل `DataCollatorWithPadding`، فإنه يأخذ `tokenizer` المستخدم لمعالجة المدخلات، ولكنه يأخذ أيضًا `model`. ويرجع ذلك إلى أن جامع البيانات هذا سيكون مسؤولاً أيضًا عن إعداد رموز تعريف الإدخال فك التشفير، والتي هي إصدارات منزاحة من التصنيفات مع رمز خاص في البداية. نظرًا لأن هذا التحول يتم بشكل مختلف قليلاً لمختلف البنى، فإن `DataCollatorForSeq2Seq` بحاجة إلى معرفة كائن `model`:

{#if fw === 'pt'}
```py
from transformers import DataCollatorForSeq2Seq

data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)
```
{:else}
```py
from transformers import DataCollatorForSeq2Seq

data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors="tf")
```
{/if}

لاختبار ذلك على بضع عينات، ما علينا سوى استدعائه على قائمة من الأمثلة من مجموعة التدريب المعلمة الخاصة بنا:

```py
batch = data_collator([tokenized_datasets["train"][i] for i in range(1, 3)])
batch.keys()
```

```python out
dict_keys(['attention_mask', 'input_ids', 'labels', 'decoder_input_ids'])
```

يمكننا التحقق مما إذا كانت تصنيفاتنا قد تم تعبئتها إلى الطول الأقصى للدفعة، باستخدام `-100`:

```py
batch["labels"]
```

```python out
tensor([[  577,  5891,     2,  3184,    16,  2542,     5,  1710,     0,  -100,
-100,  -100,  -100,  -100,  -100,  -100],
[ 1211,     3,    49,  9409,  1211,     3, 29140,   817,  3124,   817,
550,  7032,  5821,  7907, 12649,     0]])
```

ويمكننا أيضًا إلقاء نظرة على رموز تعريف فك التشفير، لمعرفة أنها إصدارات منزاحة من التصنيفات:

```py
batch["decoder_input_ids"]
```

```python out
tensor([[59513,   577,  5891,     2,  3184,    16,  2542,     5,  1710,     0,
59513, 59513, 59513, 59513, 59513, 59513],
[59513,  1211,     3,    49,  9409,  1211,     3, 29140,   817,  3124,
817,   550,  7032,  5821,  7907, 12649]])
```

فيما يلي التصنيفات للعنصر الأول والثاني في مجموعة البيانات الخاصة بنا:

```py
for i in range(1, 3):
print(tokenized_datasets["train"][i]["labels"])
```

```python out
[577, 5891, 2, 3184, 16, 2542, 5, 1710, 0]
[1211, 3, 49, 9409, 1211, 3, 29140, 817, 3124, 817, 550, 7032, 5821, 7907, 12649, 0]
```

{#if fw === 'pt'}
سنمرر هذا `data_collator` إلى `Seq2SeqTrainer`. بعد ذلك، دعنا نلقي نظرة على المقياس.
{:else}
يمكننا الآن استخدام هذا `data_collator` لتحويل كل من مجموعات البيانات الخاصة بنا إلى `tf.data.Dataset`، جاهز للتدريب:

```python
tf_train_dataset = model.prepare_tf_dataset(
tokenized_datasets["train"],
collate_fn=data_collator,
shuffle=True,
batch_size=32,
)
tf_eval_dataset = model.prepare_tf_dataset(
tokenized_datasets["validation"],
collate_fn=data_collator,
shuffle=False,
batch_size=16,
)
```

{/if}
### المقاييس

<Youtube id="M05L1DhFqcw"/>

تتمثل الميزة التي تضيفها `Seq2SeqTrainer` إلى فئة `Trainer` الأساسية في القدرة على استخدام طريقة `generate()` أثناء التقييم أو التنبؤ. أثناء التدريب، سيستخدم النموذج `decoder_input_ids` مع قناع اهتمام يضمن عدم استخدام الرموز بعد الرمز الذي يحاول التنبؤ به، لتسريع التدريب. أثناء الاستدلال، لن نتمكن من استخدام تلك العلامات لأننا لن نملك تسميات، لذا فمن الجيد تقييم نموذجنا بنفس الإعداد.

كما رأينا في [الفصل 1](/course/chapter1/6)، يقوم فك التشفير بالاستدلال عن طريق التنبؤ بالرموز واحدًا تلو الآخر - وهو ما يتم تنفيذه خلف الكواليس في مكتبة 🤗 Transformers بواسطة طريقة `generate()`. ستسمح لنا `Seq2SeqTrainer` باستخدام هذه الطريقة للتقييم إذا قمنا بتعيين `predict_with_generate=True`.

إن المقياس التقليدي المستخدم للترجمة هو [درجة BLEU](https://en.wikipedia.org/wiki/BLEU)، التي تم تقديمها في [مقالة من عام 2002](https://aclanthology.org/P02-1040.pdf) بواسطة كيشور بابينيني وآخرون. تقيم درجة BLEU مدى قرب الترجمات من تسمياتها. ولا يقيس قابلية فهم أو صحة ناتج النموذج من الناحية النحوية، ولكنه يستخدم قواعد إحصائية للتأكد من ظهور جميع الكلمات في النواتج المولدة أيضًا في الأهداف. بالإضافة إلى ذلك، هناك قواعد تعاقب تكرار الكلمات نفسها إذا لم يتم تكرارها أيضًا في الأهداف (لتجنب إخراج النموذج لجمل مثل "the the the the the") وجمل الإخراج أقصر من تلك الموجودة في الأهداف (لتجنب قيام النموذج بإخراج جمل مثل "the").

أحد أوجه القصور في BLEU هو أنه يتوقع أن يكون النص مفصولًا مسبقًا، مما يجعل من الصعب مقارنة النتائج بين النماذج التي تستخدم برامج تحليل مختلفة. لذلك، فإن المقياس الأكثر استخدامًا لمقارنة نماذج الترجمة اليوم هو [SacreBLEU](https://github.com/mjpost/sacrebleu)، والذي يعالج هذا القصور (وغيره) من خلال توحيد خطوة التحليل. لاستخدام هذا المقياس، نحتاج أولاً إلى تثبيت مكتبة SacreBLEU:

```py
!pip install sacrebleu
```

بعد ذلك، يمكننا تحميله عبر `evaluate.load()` كما فعلنا في [الفصل 3](/course/chapter3):

```py
import evaluate

metric = evaluate.load("sacrebleu")
```

يأخذ هذا المقياس النصوص كمدخلات وأهداف. تم تصميمه لقبول عدة أهداف مقبولة، حيث توجد غالبًا ترجمات مقبولة متعددة للجملة نفسها - توفر مجموعة البيانات التي نستخدمها واحدة فقط، ولكن من الشائع في NLP العثور على مجموعات بيانات تقدم عدة جمل كعلامات تصنيف. لذلك، يجب أن تكون التنبؤات قائمة من الجمل، ولكن يجب أن تكون المراجع قائمة من قوائم الجمل.

دعونا نجرب مثالاً:

```py
predictions = [
"This plugin lets you translate web pages between several languages automatically."
]
references = [
[
"This plugin allows you to automatically translate web pages between several languages."
]
]
metric.compute(predictions=predictions, references=references)
```

```python out
{'score': 46.750469682990165,
'counts': [11, 6, 4, 3],
'totals': [12, 11, 10, 9],
'precisions': [91.67, 54.54, 40.0, 33.33],
'bp': 0.9200444146293233,
'sys_len': 12,
'ref_len': 13}
```

يحصل هذا على درجة BLEU تبلغ 46.75، وهو أمر جيد جدًا - للرجوع، حقق النموذج الأصلي Transformer في ورقة ["Attention Is All You Need"](https://arxiv.org/pdf/1706.03762.pdf) درجة BLEU تبلغ 41.8 في مهمة ترجمة مماثلة بين اللغة الإنجليزية والفرنسية! (للحصول على مزيد من المعلومات حول المقاييس الفردية، مثل `counts` و`bp`، راجع [مستودع SacreBLEU](https://github.com/mjpost/sacrebleu/blob/078c440168c6adc89ba75fe6d63f0d922d42bcfe/sacrebleu/metrics/bleu.py#L74).) من ناحية أخرى، إذا حاولنا باستخدام نوعين من التنبؤات السيئة (الكثير من التكرارات أو أقصر من اللازم) التي غالبًا ما تخرج من نماذج الترجمة، فسنحصل على درجات BLEU سيئة للغاية:

```py
predictions = ["This This This This"]
references = [
[
"This plugin allows you to automatically translate web pages between several languages."
]
]
metric.compute(predictions=predictions, references=references)
```

```python out
{'score': 1.683602693167689,
'counts': [1, 0, 0, 0],
'totals': [4, 3, 2, 1],
'precisions': [25.0, 16.67, 12.5, 12.5],
'bp': 0.10539922456186433,
'sys_len': 4,
'ref_len': 13}
```

```py
predictions = ["This plugin"]
references = [
[
"This plugin allows you to automatically translate web pages between several languages."
]
]
metric.compute(predictions=predictions, references=references)
```

```python out
{'score': 0.0,
'counts': [2, 1, 0, 0],
'totals': [2, 1, 0, 0],
'precisions': [100.0, 100.0, 0.0, 0.0],
'bp': 0.004086771438464067,
'sys_len': 2,
'ref_len': 13}
```

يمكن أن يتراوح الدرجات من 0 إلى 100، والأعلى أفضل.

للحصول على النصوص التي يمكن أن يستخدمها المقياس، سنستخدم طريقة `tokenizer.batch_decode()`، كل ما علينا فعله هو تنظيف جميع علامات `-100` في التسميات؛ وسيقوم المحلل البرمجي تلقائيًا بنفس الأمر بالنسبة لرموز التعبئة. دعونا نحدد وظيفة تأخذ نموذجنا ومجموعة بياناتنا وتحسب المقاييس عليها. سنستخدم أيضًا خدعة تحسن الأداء بشكل كبير - قم بتجميع كود التوليد الخاص بنا باستخدام [XLA](https://www.tensorflow.org/xla)، وهو مجمع الجبر الخطي المعجل لـ TensorFlow. تطبق XLA تحسينات مختلفة على مخطط الحساب الخاص بالنموذج، مما يؤدي إلى تحسينات كبيرة في السرعة واستخدام الذاكرة. كما هو موضح في مدونة Hugging Face [blog](https://huggingface.co/blog/tf-xla-generate)، تعمل XLA بشكل أفضل عندما لا تختلف أشكال الإدخال لدينا كثيرًا. للتعامل مع هذا، سنقوم بتبطين إدخالاتنا إلى مضاعفات 128، وإنشاء مجموعة بيانات جديدة مع أداة التبطين، ثم سنطبق الديكور `@tf.function(jit_compile=True)` على وظيفة التوليد الخاصة بنا، والتي تشير إلى الدالة بأكملها للتجميع باستخدام XLA.

```py
import numpy as np
import tensorflow as tf
from tqdm import tqdm

generation_data_collator = DataCollatorForSeq2Seq(
tokenizer, model=model, return_tensors="tf", pad_to_multiple_of=128
)

tf_generate_dataset = model.prepare_tf_dataset(
tokenized_datasets["validation"],
collate_fn=generation_data_collator,
shuffle=False,
batch_size=8,
)


@tf.function(jit_compile=True)
def generate_with_xla(batch):
return model.generate(
input_ids=batch["input_ids"],
attention_mask=batch["attention_mask"],
max_new_tokens=128,
)


def compute_metrics():
all_preds = []
all_labels = []

for batch, labels in tqdm(tf_generate_dataset):
predictions = generate_with_xla(batch)
decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)
labels = labels.numpy()
labels = np.where(labels != -100, labels, tokenizer.pad_token_id)
decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)
decoded_preds = [pred.strip() for pred in decoded_preds]
decoded_labels = [[label.strip()] for label in decoded_labels]
all_preds.extend(decoded_preds)
all_labels.extend(decoded_labels)

result = metric.compute(predictions=all_preds, references=all_labels)
return {"bleu": result["score"]}
```

{:else}

للحصول على النصوص التي يمكن أن يستخدمها المقياس، سنستخدم طريقة `tokenizer.batch_decode()`، كل ما علينا فعله هو تنظيف جميع علامات `-100` في التسميات؛ وسيقوم المحلل البرمجي تلقائيًا بالشيء نفسه بالنسبة لرموز التعبئة:

```py
import numpy as np


def compute_metrics(eval_preds):
preds, labels = eval_preds
# In case the model returns more than the prediction logits
if isinstance(preds, tuple):
preds = preds[0]

decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)

# Replace -100s in the labels as we can't decode them
labels = np.where(labels != -100, labels, tokenizer.pad_token_id)
decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)

# Some simple post-processing
decoded_preds = [pred.strip() for pred in decoded_preds]
decoded_labels = [[label.strip()] for label in decoded_labels]

result = metric.compute(predictions=decoded_preds, references=decoded_labels)
return {"bleu": result["score"]}
```

{/if}

الآن بعد أن انتهينا من ذلك، نحن مستعدون لضبط نموذجنا بدقة!
## تهيئة النموذج

الخطوة الأولى هي تسجيل الدخول إلى Hugging Face، حتى تتمكن من تحميل نتائجك إلى Model Hub. هناك دالة ملائمة لمساعدتك في ذلك في دفتر الملاحظات:

```python
from huggingface_hub import notebook_login

notebook_login()
```

سيتم عرض أداة يمكنك من خلالها إدخال بيانات اعتماد تسجيل الدخول إلى Hugging Face.

إذا كنت لا تعمل في دفتر الملاحظات، فما عليك سوى كتابة السطر التالي في المحطة الطرفية الخاصة بك:

```bash
huggingface-cli login
```

قبل أن نبدأ، دعونا نرى ما هي النتائج التي نحصل عليها من نموذجنا بدون أي تدريب:

```py
print(compute_metrics())
```

```
{'bleu': 33.26983701454733}
```

بمجرد الانتهاء من ذلك، يمكننا إعداد كل ما نحتاجه لتجميع وتدريب نموذجنا. لاحظ استخدام `tf.keras.mixed_precision.set_global_policy("mixed_float16")` - سيخبر هذا Keras بالتدريب باستخدام float16، والذي يمكن أن يوفر تسريعًا كبيرًا على وحدات معالجة الرسوميات (GPUs) التي تدعمه (Nvidia 20xx/V100 أو أحدث).

```python
from transformers import create_optimizer
from transformers.keras_callbacks import PushToHubCallback
import tensorflow as tf

# عدد خطوات التدريب هو عدد العينات في مجموعة البيانات، مقسومًا على حجم الدفعة ثم يتم ضربه
# بعدد العصور. لاحظ أن tf_train_dataset هنا هو tf.data.Dataset مجمع،
# وليس مجموعة بيانات Hugging Face الأصلية، لذلك len() هو بالفعل num_samples // batch_size.
num_epochs = 3
num_train_steps = len(tf_train_dataset) * num_epochs

optimizer, schedule = create_optimizer(
init_lr=5e-5,
num_warmup_steps=0,
num_train_steps=num_train_steps,
weight_decay_rate=0.01,
)
model.compile(optimizer=optimizer)

# تدريب في دقة النقطة العائمة المختلطة 16
tf.keras.mixed_precision.set_global_policy("mixed_float16")
```

بعد ذلك، نقوم بتعريف `PushToHubCallback` لتحميل نموذجنا إلى Hub أثناء التدريب، كما رأينا في [القسم 2]((/course/chapter7/2))، ثم نقوم ببساطة بتجهيز النموذج مع هذا الاستدعاء:

```python
from transformers.keras_callbacks import PushToHubCallback

callback = PushToHubCallback(
output_dir="marian-finetuned-kde4-en-to-fr", tokenizer=tokenizer
)

model.fit(
tf_train_dataset,
validation_data=tf_eval_dataset,
callbacks=[callback],
epochs=num_epochs,
)
```

لاحظ أنه يمكنك تحديد اسم المستودع الذي تريد الدفع إليه باستخدام وسيط `hub_model_id` (على وجه الخصوص، سيتعين عليك استخدام وسيط `hub_model_id` للدفع إلى منظمة). على سبيل المثال، عندما قمنا بالدفع بالنموذج إلى منظمة [`huggingface-course`](https://huggingface.co/huggingface-course)، أضفنا `hub_model_id="huggingface-course/marian-finetuned-kde4-en-to-fr"` إلى `Seq2SeqTrainingArguments`. بشكل افتراضي، سيتم استخدام المستودع الموجود في مساحة الاسم الخاصة بك ويتم تسميته باسم دليل الإخراج الذي قمت بتعيينه، لذا هنا سيكون `"sgugger/marian-finetuned-kde4-en-to-fr"` (وهو النموذج الذي ارتبطنا به في بداية هذا القسم).

<Tip>
💡 إذا كان دليل الإخراج الذي تستخدمه موجودًا بالفعل، فيجب أن يكون مستنسخًا محليًا للمستودع الذي تريد الدفع إليه. إذا لم يكن كذلك، فستحصل على خطأ عند استدعاء `model.fit()` وسيتعين عليك تعيين اسم جديد.
</Tip>

أخيرًا، دعونا نرى كيف تبدو مقاييسنا الآن بعد انتهاء التدريب:

```py
print(compute_metrics())
```

```
{'bleu': 57.334066271545865}
```

في هذه المرحلة، يمكنك استخدام أداة الاستدلال على Model Hub لاختبار نموذجك ومشاركته مع أصدقائك. لقد قمت بنجاح بضبط نموذج لمهمة الترجمة - تهانينا!

{:else}

بمجرد الانتهاء من ذلك، يمكننا تعريف `Seq2SeqTrainingArguments` الخاصة بنا. مثل المدرب، نستخدم فئة فرعية من `TrainingArguments` تحتوي على بعض الحقول الإضافية:

```python
from transformers import Seq2SeqTrainingArguments

args = Seq2SeqTrainingArguments(
f"marian-finetuned-kde4-en-to-fr",
evaluation_strategy="no"،
save_strategy="epoch"،
learning_rate=2e-5،
per_device_train_batch_size=32،
per_device_eval_batch_size=64،
weight_decay=0.01،
save_total_limit=3،
num_train_epochs=3،
predict_with_generate=True،
fp16=True،
push_to_hub=True،
)
```

بصرف النظر عن فرط المعلمات المعتادة (مثل معدل التعلم وعدد العصور وحجم الدفعة وبعض تدهور الوزن)، فيما يلي بعض التغييرات مقارنة بما رأيناه في الأقسام السابقة:

- لا نقوم بتعيين أي تقييم منتظم، حيث يستغرق التقييم بعض الوقت؛ سنقوم فقط بتقييم نموذجنا مرة واحدة قبل التدريب وبعده.
- نحدد `fp16=True`، والذي يسرع التدريب على وحدات معالجة الرسوميات الحديثة.
- نحدد `predict_with_generate=True`، كما ناقشنا أعلاه.
- نستخدم `push_to_hub=True` لتحميل النموذج إلى Hub في نهاية كل عصر.

لاحظ أنه يمكنك تحديد الاسم الكامل للمستودع الذي تريد الدفع إليه باستخدام وسيط `hub_model_id` (على وجه الخصوص، سيتعين عليك استخدام وسيط `hub_model_id` للدفع إلى منظمة). على سبيل المثال، عندما قمنا بالدفع بالنموذج إلى منظمة [`huggingface-course`](https://huggingface.co/huggingface-course)، أضفنا `hub_model_Multiplier="huggingface-course/marian-finetuned-kde4-en-to-fr"` إلى `Seq2SeqTrainingArguments`. بشكل افتراضي، سيتم استخدام المستودع الموجود في مساحة الاسم الخاصة بك ويتم تسميته باسم دليل الإخراج الذي قمت بتعيينه، لذا في حالتنا سيكون `"sgugger/marian-finetuned-kde4-en-to-fr"` (وهو النموذج الذي ارتبطنا به في بداية هذا القسم).

<Tip>
💡 إذا كان دليل الإخراج الذي تستخدمه موجودًا بالفعل، فيجب أن يكون مستنسخًا محليًا للمستودع الذي تريد الدفع إليه. إذا لم يكن كذلك، فستحصل على خطأ عند تعريف `Seq2SeqTrainer` الخاص بك وسيتعين عليك تعيين اسم جديد.
</Tip>

أخيرًا، نقوم فقط بتمرير كل شيء إلى `Seq2SeqTrainer`:

```python
from transformers import Seq2SeqTrainer

trainer = Seq2SeqTrainer(
model،
args،
train_dataset=tokenized_datasets["train"]،
eval_dataset=tokenized_datasets["validation"]،
data_collator=data_collator،
tokenizer=tokenizer،
compute_metrics=compute_metrics،
)
```

قبل التدريب، سنلقي أولاً نظرة على النتيجة التي يحصل عليها نموذجنا، للتأكد من أننا لا نجعل الأمور أسوأ مع الضبط الدقيق لدينا. سيستغرق هذا الأمر بعض الوقت، لذا يمكنك احتساء القهوة أثناء تنفيذه:

```python
trainer.evaluate(max_length=max_length)
```

```python out
{'eval_loss': 1.6964408159255981،
'eval_bleu': 39.26865061007616،
'eval_runtime': 965.8884،
'eval_samples_per_second': 21.76،
'eval_steps_per_second': 0.341}
```

درجة BLEU البالغة 39 ليست سيئة للغاية، مما يعكس حقيقة أن نموذجنا جيد بالفعل في ترجمة الجمل الإنجليزية إلى الفرنسية.

التالي هو التدريب، والذي سيستغرق أيضًا بعض الوقت:

```python
trainer.train()
```

لاحظ أنه أثناء حدوث التدريب، في كل مرة يتم فيها حفظ النموذج (هنا، كل عصر) يتم تحميله في الخلفية إلى Hub. بهذه الطريقة، ستتمكن من استئناف تدريبك على آلة أخرى إذا لزم الأمر.

بمجرد الانتهاء من التدريب، نقوم بتقييم نموذجنا مرة أخرى - نأمل أن نرى بعض التحسن في درجة BLEU!

```بي
trainer.evaluate(max_length=max_length)
```

```python out
{'eval_loss': 0.8558505773544312،
'eval_bleu': 52.94161337775576،
'eval_runtime': 714.2576،
'eval_samples_per_second': 29.426،
'eval_steps_per_second': 0.461،
'epoch': 3.0}
```

هذا تحسن كبير يبلغ 14 نقطة، وهو أمر رائع.

أخيرًا، نستخدم طريقة `push_to_hub()` للتأكد من تحميل أحدث إصدار من النموذج. كما يقوم المدرب بصياغة بطاقة نموذج بجميع نتائج التقييم وتحميلها. تحتوي بطاقة النموذج هذه على بيانات وصفية تساعد Model Hub على اختيار الأداة المساعدة لعرض الاستدلال. عادة، لا توجد حاجة لقول أي شيء لأنه يمكنه استنتاج الأداة الصحيحة من فئة النموذج، ولكن في هذه الحالة، يمكن استخدام نفس فئة النموذج لجميع أنواع المشكلات تسلسل إلى تسلسل، لذلك نحدد أنها نموذج ترجمة:

```بي
trainer.push_to_hub(tags="translation"، commit_message="Training complete")
```

تعيد هذه الأوامر عنوان URL للالتزام الذي قام به للتو، إذا كنت تريد فحصه:

```python out
'https://huggingface.co/sgugger/marian-finetuned-kde4-en-to-fr/commit/3601d621e3baae2bc63d3311452535f8f58f6ef3'
```

في هذه المرحلة، يمكنك استخدام أداة الاستدلال على Model Hub لاختبار نموذجك ومشاركته مع أصدقائك. لقد قمت بنجاح بضبط نموذج لمهمة الترجمة - تهانينا!

إذا كنت ترغب في الغوص بشكل أعمق قليلاً في حلقة التدريب، فسنقوم الآن بإظهار كيفية القيام بنفس الشيء باستخدام 🤗 Accelerate.

{/if}

## حلقة تدريب مخصصة

دعونا الآن نلقي نظرة على حلقة التدريب الكاملة، حتى تتمكن من تخصيص الأجزاء التي تحتاجها. سيشبه ذلك إلى حد كبير ما فعلناه في [القسم 2](/course/chapter7/2) و [الفصل 3](/course/chapter3/4).

### إعداد كل شيء للتدريب

لقد رأيت كل هذا عدة مرات الآن، لذا سنمر عبر التعليمات البرمجية بسرعة كبيرة. أولاً، سنقوم ببناء `DataLoader`s من مجموعات البيانات الخاصة بنا، بعد تعيين تنسيق مجموعات البيانات إلى `"torch"` حتى نحصل على تنسورات PyTorch:

```بي
from torch.utils.data import DataLoader

tokenized_datasets.set_format("torch")
train_dataloader = DataLoader(
tokenized_datasets["train"]،
shuffle=True،
collate_fn=data_collator،
batch_size=8،
)
eval_dataloader = DataLoader(
tokenized_datasets["validation"]، collate_fn=data_collator، batch_size=8
)
```

بعد ذلك، سنعيد إنشاء مثيل نموذجنا، للتأكد من أننا لا نواصل الضبط الدقيق من قبل، ولكننا نبدأ من النموذج المسبق التدريب مرة أخرى:

```بي
model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)
```

بعد ذلك، ستحتاج إلى محسن:

```بي
from transformers import AdamW

optimizer = AdamW(model.parameters()، lr=2e-5)
```

بمجرد أن نحصل على كل هذه الأشياء، يمكننا إرسالها إلى طريقة `accelerator.prepare()`. تذكر أنه إذا كنت تريد التدريب على وحدات معالجة الرسوميات في دفتر ملاحظات Colab، فسيتعين عليك نقل كل هذا الرمز إلى دالة تدريب، ولا يجب تنفيذ أي خلية تقوم بتنفيذ `Accelerator`.

```بي
from accelerate import Accelerator

accelerator = Accelerator()
model، optimizer، train_dataloader، eval_dataloader = accelerator.prepare(
model، optimizer، train_dataloader، eval_dataloader
)
```

الآن بعد أن أرسلنا `train_dataloader` إلى `accelerator.prepare()`، يمكننا استخدام طوله لحساب عدد خطوات التدريب. تذكر أنه يجب علينا دائمًا القيام بذلك بعد إعداد برنامج التغذية التلقائي، حيث ستغير طريقة الإعداد طول `DataLoader`. نستخدم جدولًا خطيًا كلاسيكيًا من معدل التعلم إلى 0:

```بي
from transformers import get_scheduler

num_train_epochs = 3
num_update_steps_per_epoch = len(train_dataloader)
num_training_steps = num_train_epochs * num_update_steps_per_epoch

lr_scheduler = get_scheduler(
"linear"،
optimizer=optimizer،
num_warmup_steps=0،
num_training_steps=num_training_steps،
)
```

أخيرًا، لدفع نموذجنا إلى Hub، سيتعين علينا إنشاء كائن `Repository` في مجلد عمل. قم بتسجيل الدخول إلى Hugging Face Hub، إذا لم تكن قد قمت بتسجيل الدخول بالفعل. سنحدد اسم المستودع من معرف النموذج الذي نريد منحه لنموذجنا (لا تتردد في استبدال `repo_name` بخيارك الخاص؛ يجب أن يحتوي فقط على اسم المستخدم الخاص بك، وهو ما تفعله وظيفة `get_full_repo_name()`):

```بي
from huggingface_hub import Repository، get_full_repo_name

model_name = "marian-finetuned-kde4-en-to-fr-accelerate"
repo_name = get_full_repo_name(model_name)
repo_name
```

```python out
'sgugger/marian-finetuned-kde4-en-to-fr-accelerate'
```

بعد ذلك، يمكننا استنساخ هذا المستودع في مجلد محلي. إذا كان موجودًا بالفعل، فيجب أن يكون هذا المجلد المحلي مستنسخًا من المستودع الذي نعمل عليه:

```بي
output_dir = "marian-finetuned-kde4-en-to-fr-accelerate"
repo = Repository(output_dir، clone_from=repo_name)
```

الآن يمكننا تحميل أي شيء نقوم بحفظه في `output_dir` عن طريق استدعاء طريقة `repo.push_to_hub()`. سيساعدنا هذا في تحميل النماذج المتوسطة في نهاية كل عصر.
## حلقة التدريب

الآن نحن مستعدون لكتابة حلقة التدريب الكاملة. لتبسيط الجزء الخاص بالتقييم، نقوم بتعريف دالة `postprocess()` التي تأخذ التوقعات والعلامات وتحولها إلى قوائم من السلاسل النصية التي يتوقعها كائن `metric`:

```py
def postprocess(predictions, labels):
    predictions = predictions.cpu().numpy()
    labels = labels.cpu().numpy()

    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)

    # استبدل -100 في العلامات لأننا لا نستطيع فك تشفيرها.
    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)

    # بعض المعالجة البسيطة بعد فك الترميز
    decoded_preds = [pred.strip() for pred in decoded_preds]
    decoded_labels = [[label.strip()] for label in decoded_labels]
    return decoded_preds, decoded_labels
```

تبدو حلقة التدريب مشابهة لتلك الموجودة في [القسم 2](/course/chapter7/2) و[الفصل 3](/course/chapter3)، مع بعض الاختلافات في جزء التقييم - لذلك دعونا نركز على ذلك!

أول شيء يجب ملاحظته هو أننا نستخدم طريقة `generate()` لحساب التوقعات، ولكن هذه طريقة في نموذجنا الأساسي، وليس النموذج الملفوف 🤗 Accelerate الذي تم إنشاؤه في طريقة `prepare()`. ولهذا نفك لف النموذج أولاً، ثم نستدعي هذه الطريقة.

والشيء الثاني هو أنه، مثلما هو الحال مع [تصنيف الرموز](/course/chapter7/2)، قد تكون عمليتان قد وسّطتا المدخلات والعلامات إلى أشكال مختلفة، لذلك نستخدم `accelerator.pad_across_processes()` لجعل التوقعات والعلامات بنفس الشكل قبل استدعاء طريقة `gather()`. إذا لم نفعل ذلك، فإن التقييم إما أن يخطئ أو يعلق إلى الأبد.

```py
from tqdm.auto import tqdm
import torch

progress_bar = tqdm(range(num_training_steps))

for epoch in range(num_train_epochs):
    # التدريب
    model.train()
    for batch in train_dataloader:
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)

    # التقييم
    model.eval()
    for batch in tqdm(eval_dataloader):
        with torch.no_grad():
            generated_tokens = accelerator.unwrap_model(model).generate(
                batch["input_ids"],
                attention_mask=batch["attention_mask"],
                max_length=128,
            )
            labels = batch["labels"]

            # ضروري لملء التوقعات والعلامات قبل جمعها
            generated_tokens = accelerator.pad_across_processes(
                generated_tokens, dim=1, pad_index=tokenizer.pad_token_id
            )
            labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)

            predictions_gathered = accelerator.gather(generated_tokens)
            labels_gathered = accelerator.gather(labels)

            decoded_preds, decoded_labels = postprocess(
                predictions_gathered, labels_gathered
            )
            metric.add_batch(predictions=decoded_preds, references=decoded_labels)

        results = metric.compute()
        print(f"epoch {epoch}, BLEU score: {results['score']:.2f}")

    # الحفظ والرفع
    accelerator.wait_for_everyone()
    unwrapped_model = accelerator.unwrap_model(model)
    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
    if accelerator.is_main_process:
        tokenizer.save_pretrained(output_dir)
        repo.push_to_hub(
            commit_message=f"Training in progress epoch {epoch}", blocking=False
        )
```

```python out
epoch 0, BLEU score: 53.47
epoch 1, BLEU score: 54.24
epoch 2, BLEU score: 54.44
```

بمجرد الانتهاء من ذلك، يجب أن يكون لديك نموذج ذو نتائج مشابهة جدًا للنموذج الذي تم تدريبه باستخدام `Seq2SeqTrainer`. يمكنك التحقق من النموذج الذي تدربنا عليه باستخدام هذا الرمز في [*huggingface-course/marian-finetuned-kde4-en-to-fr-accelerate*](https://huggingface.co/huggingface-course/marian-finetuned-kde4-en-to-fr-accelerate). وإذا كنت ترغب في تجربة أي تعديلات على حلقة التدريب، فيمكنك تنفيذها مباشرة من خلال تعديل الكود الموضح أعلاه!

## استخدام النموذج الدقيق الضبط

لقد أظهرنا لك بالفعل كيف يمكنك استخدام النموذج الذي قمنا بضبطه بدقة على Model Hub باستخدام أداة التنبؤ التفاعلية. لاستخدامه محليًا في `pipeline`، علينا فقط تحديد معرف النموذج الصحيح:

```py
from transformers import pipeline

# استبدل هذا بمعرف نقطة التفتيش الخاصة بك
model_checkpoint = "huggingface-course/marian-finetuned-kde4-en-to-fr"
translator = pipeline("translation", model=model_checkpoint)
translator("Default to expanded threads")
```

```python out
[{'translation_text': 'Par défaut, développer les fils de discussion'}]
```

كما هو متوقع، قام نموذجنا المُدرب مسبقًا بتكييف معرفته مع المجموعة التي قمنا بضبطها بدقة، وبدلاً من ترك الكلمة الإنجليزية "threads" بمفردها، فإنه يترجمها الآن إلى النسخة الفرنسية الرسمية. وينطبق الشيء نفسه على كلمة "plugin":

```py
translator(
    "Unable to import %1 using the OFX importer plugin. This file is not the correct format."
)
```

```python out
[{'translation_text': "Impossible d'importer %1 en utilisant le module externe d'importation OFX. Ce fichier n'est pas le bon format."}]
```

مثال آخر رائع على تكيف المجال!

<Tip>

✏️ **جرب بنفسك!** ماذا يعيد النموذج على العينة التي تحتوي على كلمة "email" التي حددتها سابقًا؟

</Tip>