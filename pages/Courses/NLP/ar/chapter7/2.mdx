لم يتم ترجمة الأجزاء المطلوبة حسب تنسيق Markdown المحدد:

```md
# Token classification[[token-classification]]

{#if fw === 'pt'}

<CourseFloatingBanner chapter={7}
classNames="absolute z-10 right-0 top-0"
notebooks={[
{label: "Google Colab", value: "https://colab.research.google.com/github.com/huggingface/notebooks/blob/master/course/en/chapter7/section2_pt.ipynb"},
{label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter7/section2_pt.ipynb"},
]} />

{:else}

<CourseFloatingBanner chapter={7}
classNames="absolute z-10 right-0 top-0"
notebooks={[
{label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter7/section2_tf.ipynb"},
{label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter7/section2_tf.ipynb"},
]} />

{/if}

تعد أول تطبيق سنستكشفها هو تصنيف الرموز. وتشمل هذه المهمة العامة أي مشكلة يمكن صياغتها على أنها "إسناد تسمية إلى كل رمز في جملة"، مثل:

- **التعرف على الكيانات المسماة (NER)**: العثور على الكيانات (مثل الأشخاص أو المواقع أو المنظمات) في جملة. يمكن صياغة ذلك من خلال إسناد تسمية إلى كل رمز عن طريق وجود فئة لكل كيان وفئة "بدون كيان".

- **وضع العلامات النحوية (POS)**: قم بوضع علامة على كل كلمة في جملة على أنها تتوافق مع جزء معين من الكلام (مثل الاسم أو الفعل أو الصفة، إلخ).

- **التقسيم**: العثور على الرموز التي تنتمي إلى نفس الكيان. يمكن الجمع بين هذه المهمة (مع POS أو NER) ويمكن صياغتها على أنها إسناد تسمية واحدة (عادة `B-`) إلى أي رموز تكون في بداية كتلة، وتسمية أخرى (عادة `I-`) إلى الرموز الموجودة داخل كتلة، وتسمية ثالثة (عادة `O`) إلى الرموز التي لا تنتمي إلى أي كتلة.

<Youtube id="wVHdVlPScxA"/>

بالطبع، هناك العديد من الأنواع الأخرى من مشكلات تصنيف الرموز؛ تلك مجرد أمثلة تمثيلية. في هذا القسم، سنقوم بتغيير نموذج (BERT) على مهمة NER، والذي سيكون بعد ذلك قادرًا على إجراء تنبؤات مثل هذا:

<iframe src="https://course-demos-bert-finetuned-ner.hf.space" frameBorder="0" height="350" title="Gradio app" class="block dark:hidden container p-0 flex-grow space-iframe" allow="accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking" sandbox="allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"></iframe>

<a class="flex justify-center" href="/huggingface-course/bert-finetuned-ner">
<img class="block dark:hidden lg:w-3/5" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/model-eval-bert-finetuned-ner.png" alt="One-hot encoded labels for question answering."/>
<img class="hidden dark:block lg:w-3/5" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/model-eval-bert-finetuned-ner-dark.png" alt="One-hot encoded labels for question answering."/>
</a>

يمكنك العثور على النموذج الذي سنقوم بتدريبه وتحميله إلى المحور والتحقق المزدوج من تنبؤاته [هنا](https://huggingface.co/huggingface-course/bert-finetuned-ner?text=My+name+is+Sylvain+and+I+work+at+Hugging+Face+in+Brooklyn).

## إعداد البيانات[[preparing-the-data]]

أولاً وقبل كل شيء، نحتاج إلى مجموعة بيانات مناسبة لتصنيف الرموز. في هذا القسم، سنستخدم [مجموعة بيانات CoNLL-2003](https://huggingface.co/datasets/conll2003)، والتي تحتوي على قصص إخبارية من رويترز.

<Tip>

💡 طالما أن مجموعة البيانات الخاصة بك تتكون من نصوص مقسمة إلى كلمات مع تسمياتها المقابلة، فستتمكن من تكييف إجراءات معالجة البيانات الموضحة هنا مع مجموعة البيانات الخاصة بك. راجع [الفصل 5](/course/chapter5) إذا كنت بحاجة إلى مراجعة حول كيفية تحميل بياناتك المخصصة في `Dataset`.

</Tip>

### مجموعة بيانات CoNLL-2003[[the-conll-2003-dataset]]

لتحميل مجموعة بيانات CoNLL-2003، نستخدم طريقة `load_dataset()` من مكتبة Datasets 🤗:

```py
from datasets import load_dataset

raw_datasets = load_dataset("conll2003")
```

سيؤدي هذا إلى تنزيل مجموعة البيانات وتخزينها مؤقتًا، كما رأينا في [الفصل 3](/course/chapter3) لمجموعة بيانات GLUE MRPC. يُظهر فحص هذا الكائن لنا الأعمدة الموجودة والانقسام بين مجموعات التدريب والتحقق والاختبار:

```py
raw_datasets
```

```python out
DatasetDict({
train: Dataset({
features: ['chunk_tags', 'id', 'ner_tags', 'pos_tags', 'tokens'],
num_rows: 14041
})
validation: Dataset({
features: ['chunk_tags', 'id', 'ner_tags', 'pos_tags', 'tokens'],
num_rows: 3250
})
test: Dataset({
features: ['chunk_tags', 'id', 'ner_tags', 'pos_tags', 'tokens'],
num_rows: 3453
})
})
```

على وجه الخصوص، يمكننا أن نرى أن مجموعة البيانات تحتوي على تسميات للمهمات الثلاث التي ذكرناها سابقًا: NER وPOS والتقسيم. أحد الاختلافات الكبيرة عن مجموعات البيانات الأخرى هو أن النصوص المدخلة لا يتم تقديمها على شكل جمل أو وثائق، ولكن على شكل قوائم من الكلمات (العمود الأخير يسمى `tokens`، ولكنه يحتوي على كلمات بمعنى أن هذه هي المدخلات المقسمة مسبقًا إلى رموز والتي لا تزال بحاجة إلى المرور عبر المحلل اللغوي للتقسيم إلى رموز فرعية).

دعونا نلقي نظرة على العنصر الأول من مجموعة التدريب:

```py
raw_datasets["train"][0]["tokens"]
```

```python out
['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']
```

نظرًا لأننا نريد إجراء التعرف على الكيانات المسماة، فسنلقي نظرة على علامات NER:

```py
raw_datasets["train"][0]["ner_tags"]
```

```python out
[3, 0, 7, 0, 0, 0, 7, 0, 0]
```

تلك هي التسميات كأعداد صحيحة جاهزة للتدريب، ولكنها ليست مفيدة بالضرورة عندما نريد فحص البيانات. مثل التصنيف النصي، يمكننا الوصول إلى المراسلات بين تلك الأعداد الصحيحة وأسماء التسميات عن طريق النظر في سمة `features` لمجموعة البيانات الخاصة بنا:

```py
ner_feature = raw_datasets["train"].features["ner_tags"]
ner_feature
```

```python out
Sequence(feature=ClassLabel(num_classes=9, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], names_file=None, id=None), length=-1, id=None)
```

لذا يحتوي هذا العمود على عناصر هي تسلسلات من `ClassLabel`s. نوع عناصر التسلسل موجود في سمة `feature` من هذا `ner_feature`، ويمكننا الوصول إلى قائمة الأسماء عن طريق النظر في سمة `names` من هذا `feature`:

```py
label_names = ner_feature.feature.names
label_names
```

```python out
['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']
```

لقد رأينا بالفعل هذه التسميات عند الحفر في خط أنابيب `token-classification` في [الفصل 6](/course/chapter6/3)، ولكن للمراجعة السريعة:

- يعني `O` أن الكلمة لا تتوافق مع أي كيان.

- يعني `B-PER`/`I-PER` أن الكلمة تتوافق مع بداية/داخل كيان *person*.

- يعني `B-ORG`/`I-ORG` أن الكلمة تتوافق مع بداية/داخل كيان *organization*.

- يعني `B-LOC`/`I-LOC` أن الكلمة تتوافق مع بداية/داخل كيان *location*.

- يعني `B-MISC`/`I-MISC` أن الكلمة تتوافق مع بداية/داخل كيان *miscellaneous*.

الآن فك تشفير التسميات التي رأيناها سابقًا يعطينا هذا:

```python
words = raw_datasets["train"][0]["tokens"]
labels = raw_datasets["train"][0]["ner_tags"]
line1 = ""
line2 = ""
for word, label in zip(words, labels):
full_label = label_names[label]
max_length = max(len(word), len(full_label))
line1 += word + " " * (max_length - len(word) + 1)
line2 += full_label + " " * (max_length - len(full_label) + 1)

print(line1)
print(line2)
```

```python out
'EU    rejects German call to boycott British lamb .'
'B-ORG O       B-MISC O    O  O       B-MISC  O    O'
```

وللمثال الذي يخلط تسميات `B-` و`I-`، إليك ما يعطيه نفس الرمز في الفهرس 4 من مجموعة التدريب:

```python out
'Germany \'s representative to the European Union \'s veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer .'
'B-LOC   O  O              O  O   B-ORG    I-ORG O  O          O         B-PER  I-PER     O    O  O         O         O      O   O         O    O         O     O    B-LOC   O     O   O          O      O   O       O'
```

كما نرى، يتم إسناد كيانات تمتد على كلمتين، مثل "الاتحاد الأوروبي" و"فيرنر زوينجمان"، تسمية `B-` للكلمة الأولى وتسمية `I-` للكلمة الثانية.

<Tip>

✏️ **جرب بنفسك!** قم بطباعة نفس الجملتين مع تسميات POS أو التسميات الخاصة بهما.

</Tip>
```
### معالجة البيانات

كما هو معتاد، يجب تحويل نصوصنا إلى رموز تعريف الرموز قبل أن يتمكن النموذج من فهمها. كما رأينا في [الفصل 6](/course/chapter6/)، هناك فرق كبير في حالة مهام تصنيف الرموز، وهو أن لدينا إدخالات مسبقة التمييز. لحسن الحظ، يمكن لواجهة برمجة التطبيقات للمحلل التعامل مع ذلك بسهولة؛ نحن بحاجة فقط إلى تحذير `tokenizer` باستخدام علم خاص.

لنبدأ بإنشاء كائن `tokenizer`. كما قلنا من قبل، سنستخدم نموذج BERT مسبق التدريب، لذا سنبدأ بتنزيل وتخزين المحلل اللغوي المرتبط به:

```python
from transformers import AutoTokenizer

model_checkpoint = "bert-base-cased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)
```

يمكنك استبدال `model_checkpoint` بأي نموذج آخر تفضله من [Hub](https://huggingface.co/models)، أو باستخدام مجلد محلي قمت بحفظ نموذج مسبق التدريب ومحلل لغوي فيه. القيد الوحيد هو أن المحلل اللغوي يجب أن تدعمه مكتبة 🤗 Tokenizers، بحيث يكون هناك إصدار "سريع" متاح. يمكنك الاطلاع على جميع التصميمات المعمارية التي تأتي مع إصدار سريع في [جدول كبير](https://huggingface.co/transformers/#supported-frameworks)، وللتحقق من أن كائن `tokenizer` الذي تستخدمه مدعوم بالفعل من مكتبة 🤗 Tokenizers، يمكنك إلقاء نظرة على سمة `is_fast`:

```py
tokenizer.is_fast
```

```python out
True
```

لتمييز الإدخال المميز مسبقًا، يمكننا استخدام `tokenizer` الخاص بنا كما هو معتاد وإضافة `is_split_into_words=True`:

```py
inputs = tokenizer(raw_datasets["train"][0]["tokens"], is_split_into_words=True)
inputs.tokens()
```

```python out
['[CLS]', 'EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'la', ## 'lamb', '.', '[SEP]']
```

كما نرى، أضاف المحلل اللغوي الرموز الخاصة التي يستخدمها النموذج (`[CLS]` في البداية و`[SEP]` في النهاية) وترك معظم الكلمات دون تغيير. ومع ذلك، تم تحليل كلمة `lamb` إلى رمزين فرعيين، `la` و`##mb`. وهذا يؤدي إلى عدم تطابق بين إدخالاتنا والعلامات؛ تحتوي قائمة العلامات على 9 عناصر فقط، في حين أن إدخالنا الآن لديه 12 رمزًا. من السهل حساب الرموز الخاصة (نحن نعرف أنها في البداية والنهاية)، ولكن يجب أيضًا التأكد من محاذاة جميع العلامات مع الكلمات الصحيحة.

لحسن الحظ، لأننا نستخدم محللًا سريعًا، يمكننا الوصول إلى القوى الخارقة لمكتبة 🤗 Tokenizers، والتي تعني أنه يمكننا بسهولة تعيين كل رمز للكلمة المقابلة (كما هو موضح في [الفصل 6](/course/chapter6/3)):

```py
inputs.word_ids()
```

```python out
[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]
```

مع القليل من العمل، يمكننا بعد ذلك توسيع قائمة العلامات الخاصة بنا لمطابقة الرموز. القاعدة الأولى التي سنطبقها هي أن الرموز الخاصة تحصل على علامة `-100`. ويرجع ذلك إلى أنه افتراضيًا، يتم تجاهل `-100` في دالة الخسارة التي سنستخدمها (التناقض). بعد ذلك، يحصل كل رمز على نفس العلامة مثل الرمز الذي بدأ الكلمة التي يقع فيها، لأنهما جزء من نفس الكيان. بالنسبة للرموز الموجودة داخل كلمة ولكن ليس في البداية، نستبدل `B-` بـ `I-` (حيث لا يبدأ الرمز الكيان):

```python
def align_labels_with_tokens(labels, word_ids):
    new_labels = []
    current_word = None
    for word_id in word_ids:
        if word_id != current_word:
            # بداية كلمة جديدة!
            current_word = word_id
            label = -100 if word_id is None else labels[word_id]
            new_labels.append(label)
        elif word_id is None:
            # رمز خاص
            new_labels.append(-100)
        else:
            # نفس الكلمة كالرمز السابق
            label = labels[word_id]
            # إذا كانت العلامة B-XXX، فنغيرها إلى I-XXX
            if label % 2 == 1:
                label += 1
            new_labels.append(label)

    return new_labels
```

دعونا نجربها على جملتنا الأولى:

```py
labels = raw_datasets["train"][0]["ner_tags"]
word_ids = inputs.word_ids()
print(labels)
print(align_labels_with_tokens(labels, word_ids))
```

```python out
[3, 0, 7, 0, 0, 0, 7, 0, 0]
[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]
```

كما نرى، أضافت وظيفتنا `-100` للرمزين الخاصين في البداية والنهاية، و`0` جديد لكلمتنا التي تم تقسيمها إلى رمزين.

✏️ **جرب بنفسك!** يفضل بعض الباحثين إسناد علامة واحدة فقط لكل كلمة، وتعيين `-100` إلى الرموز الفرعية الأخرى في كلمة معينة. وذلك لتجنب الكلمات الطويلة التي تنقسم إلى الكثير من الرموز الفرعية التي تساهم بشكل كبير في الخسارة. قم بتغيير الوظيفة السابقة لمواءمة العلامات مع معرفات الإدخال باتباع هذه القاعدة.

لمعالجة مجموعة البيانات بأكملها، نحتاج إلى تحليل جميع الإدخالات وتطبيق `align_labels_with_tokens()` على جميع العلامات. للاستفادة من سرعة المحلل اللغوي السريع، من الأفضل تحليل الكثير من النصوص في نفس الوقت، لذا سنكتب دالة تقوم بمعالجة قائمة من الأمثلة واستخدام طريقة `Dataset.map()` مع خيار `batched=True`. الشيء الوحيد المختلف عن مثالنا السابق هو أن دالة `word_ids()` تحتاج إلى الحصول على فهرس المثال الذي نريد معرفة معرفات الكلمات الخاصة به عندما تكون الإدخالات إلى المحلل اللغوي قوائم من النصوص (أو في حالتنا، قائمة من قوائم الكلمات)، لذا أضفنا ذلك أيضًا:

```py
def tokenize_and_align_labels(examples):
    tokenized_inputs = tokenizer(
        examples["tokens"], truncation=True, is_split_into_words=True
    )
    all_labels = examples["ner_tags"]
    new_labels = []
    for i, labels in enumerate(all_labels):
        word_ids = tokenized_inputs.word_ids(i)
        new_labels.append(align_labels_with_tokens(labels, word_ids))

    tokenized_inputs["labels"] = new_labels
    return tokenized_inputs
```

لاحظ أننا لم نقم بعد بضبط إدخالاتنا؛ سنفعل ذلك لاحقًا، عند إنشاء الدفعات باستخدام جامع البيانات.

الآن يمكننا تطبيق كل هذه المعالجة المسبقة في خطوة واحدة على الانقسامات الأخرى لمجموعة البيانات الخاصة بنا:

```py
tokenized_datasets = raw_datasets.map(
    tokenize_and_align_labels,
    batched=True,
    remove_columns=raw_datasets["train"].column_names,
)
```

لقد أنجزنا الجزء الأصعب! الآن بعد معالجة البيانات، سيكون التدريب الفعلي مشابهًا جدًا لما فعلناه في [الفصل 3](/course/chapter3).

## ضبط دقيق للنموذج باستخدام واجهة برمجة تطبيقات المدرب

سيكون الكود الفعلي الذي يستخدم واجهة برمجة التطبيقات للمدرب هو نفسه كما كان من قبل؛ التغييرات الوحيدة هي طريقة تجميع البيانات في دفعة ووظيفة حساب المقياس.

## ضبط دقيق للنموذج باستخدام Keras

سيكون الكود الفعلي الذي يستخدم Keras مشابهًا جدًا لما سبق؛ التغييرات الوحيدة هي طريقة تجميع البيانات في دفعة ووظيفة حساب المقياس.

### تجميع البيانات

لا يمكننا استخدام `DataCollatorWithPadding` كما هو الحال في [الفصل 3](/course/chapter3) لأنه يقوم فقط بضبط إدخالات (معرفات الإدخال، قناع الاهتمام، وأنواع الرموز). هنا يجب ضبط علاماتنا بنفس الطريقة التي يتم بها ضبط الإدخالات بحيث تظل بنفس الحجم، باستخدام `-100` كقيمة بحيث يتم تجاهل التوقعات المقابلة في حساب الخسارة.

يتم ذلك كله بواسطة [`DataCollatorForTokenClassification`](https://huggingface.co/transformers/main_classes/data_collator.html#datacollatorfortokenclassification). مثل `DataCollatorWithPadding`، فإنه يأخذ `tokenizer` المستخدم لمعالجة الإدخالات:

```py
from transformers import DataCollatorForTokenClassification

data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)
```

لاختبار ذلك على بعض العينات، يمكننا ببساطة استدعائه على قائمة من الأمثلة من مجموعة التدريب المميزة لدينا:

```py
batch = data_collator([tokenized_datasets["train"][i] for i in range(2)])
batch["labels"]
```

```python out
tensor([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0, -100],
[-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100]])
```

دعونا نقارن هذا بالعلامات للعنصر الأول والثاني في مجموعة البيانات لدينا:

```py
for i in range(2):
    print(tokenized_datasets["train"][i]["labels"])
```

```python out
[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]
[-100, 1, 2, -100]
```

كما نرى، تم ضبط مجموعة العلامات الثانية على طول الأولى باستخدام `-100`.

يمكننا الآن استخدامه لإنشاء `tf.data.Dataset` باستخدام طريقة `to_tf_dataset()`، يمكنك أيضًا استخدام `model.prepare_tf_dataset()` للقيام بذلك مع القليل من كود التمهيد - سترى هذا في بعض الأقسام الأخرى من هذا الفصل.

```py
tf_train_dataset = tokenized_datasets["train"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "labels", "token_type_ids"],
    collate_fn=data_collator,
    shuffle=True,
    batch_size=16,
)

tf_eval_dataset = tokenized_datasets["validation"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "labels", "token_type_ids"],
    collate_fn=data_collator,
    shuffle=False,
    batch_size=16,
)
```

المحطة التالية: النموذج نفسه.

### تحديد النموذج

نظرًا لأننا نعمل على مشكلة تصنيف الرموز، فسنستخدم فئة `TFAutoModelForTokenClassification`. الشيء الرئيسي الذي يجب تذكره عند تحديد هذا النموذج هو تمرير بعض المعلومات حول عدد العلامات التي لدينا. أسهل طريقة للقيام بذلك هي تمرير هذا الرقم باستخدام وسيط `num_labels`، ولكن إذا أردنا أداة استدلال لطيفة تعمل مثل تلك التي رأيناها في بداية هذا القسم، فمن الأفضل تعيين مراسلات العلامات الصحيحة بدلاً من ذلك.

يجب تعيينها بواسطة قاموسين، `id2label` و`label2id`، يحتويان على الخريطة من معرف إلى علامة والعكس:

```py
id2label = {i: label for i, label in enumerate(label_names)}
label2id = {v: k for k, v in id2label.items()}
```

الآن يمكننا ببساطة تمريرها إلى طريقة `TFAutoModelForTokenClassification.from_pretrained()`، وسيتم تعيينها في تكوين النموذج، ثم حفظها وتحميلها بشكل صحيح إلى Hub:

```py
from transformers import TFAutoModelForTokenClassification

model = TFAutoModelForTokenClassification.from_pretrained(
    model_checkpoint,
    id2label=id2label,
    label2id=label2id,
)
```

كما هو الحال عند تحديد نموذج `TFAutoModelForSequenceClassification` في [الفصل 3](/course/chapter3)، فإن إنشاء النموذج يصدر تحذيرًا بأن بعض الأوزان لم تستخدم (تلك الموجودة في رأس التدريب المسبق) وبعض الأوزان الأخرى تم تهيئتها بشكل عشوائي (تلك الموجودة في رأس تصنيف الرموز الجديد)، وأنه يجب تدريب هذا النموذج. سنفعل ذلك بعد قليل، ولكن أولاً دعونا نتأكد من أن نموذجنا لديه العدد الصحيح من العلامات:

```python
model.config.num_labels
```

```python out
9
```

⚠️ إذا كان لديك نموذج بعدد غير صحيح من العلامات، فستحصل على خطأ غامض عند استدعاء `model.fit()` لاحقًا. يمكن أن يكون هذا مزعجًا في تصحيح الأخطاء، لذا تأكد من إجراء هذا التحقق للتأكد من أن لديك العدد المتوقع من العلامات.
### ضبط دقيق للنمذجة

الآن، نحن مستعدون لتدريب نموذجنا! ولكن هناك بعض المهام التي يجب علينا القيام بها أولاً: يجب علينا تسجيل الدخول إلى Hugging Face وتحديد فرط معلمات التدريب. إذا كنت تعمل في دفتر ملاحظات، فهناك دالة ملائمة لمساعدتك في ذلك:

```python
from huggingface_hub import notebook_login

notebook_login()
```

سيتم عرض أداة يمكنك من خلالها إدخال بيانات اعتماد تسجيل الدخول إلى Hugging Face.

إذا كنت لا تعمل في دفتر الملاحظات، فما عليك سوى كتابة السطر التالي في المحطة الطرفية الخاصة بك:

```bash
huggingface-cli login
```

بعد تسجيل الدخول، يمكننا إعداد كل ما نحتاجه لتجميع نموذجنا. يوفر 🤗 Transformers دالة ملائمة `create_optimizer()` والتي ستعطيك محسن `AdamW` مع الإعدادات المناسبة لمعدل انحلال الوزن ومعدل انحلال التعلم، وكلاهما سيحسن أداء نموذجك مقارنة بمحسن `Adam` المدمج:

```python
from transformers import create_optimizer
import tensorflow as tf

# تدريب في دقة النقطة العائمة المختلطة 16
# علق هذا السطر إذا كنت تستخدم GPU الذي لن يستفيد من هذا
tf.keras.mixed_precision.set_global_policy("mixed_float16")

# عدد خطوات التدريب هو عدد العينات في مجموعة البيانات، مقسومة على حجم الدفعة ثم يتم ضربها
# بعدد العصور. لاحظ أن tf_train_dataset هنا عبارة عن مجموعة بيانات tf.data.Dataset مجمعة،
# ليس مجموعة بيانات Hugging Face الأصلية، لذلك len() هو بالفعل num_samples // batch_size.
num_epochs = 3
num_train_steps = len(tf_train_dataset) * num_epochs

optimizer, schedule = create_optimizer(
init_lr=2e-5,
num_warmup_steps=0,
num_train_steps=num_train_steps,
weight_decay_rate=0.01,
)
model.compile(optimizer=optimizer)
```

لاحظ أيضًا أننا لا نقدم وسيط `loss` إلى `compile()`. ويرجع ذلك إلى أن النماذج يمكنها في الواقع حساب الخسارة داخليًا - إذا قمت بالتجميع بدون خسارة وتزويد تسمياتك في قاموس الإدخال (كما نفعل في مجموعات البيانات الخاصة بنا)، فسيتم تدريب النموذج باستخدام تلك الخسارة الداخلية، والتي ستكون مناسبة لمهمة ونوع النموذج الذي اخترته.

بعد ذلك، نقوم بتعريف `PushToHubCallback` لتحميل نموذجنا إلى Hub أثناء التدريب، وتناسب النموذج مع هذا الاستدعاء:

```python
from transformers.keras_callbacks import PushToHubCallback

callback = PushToHubCallback(output_dir="bert-finetuned-ner", tokenizer=tokenizer)

model.fit(
tf_train_dataset,
validation_data=tf_eval_dataset,
callbacks=[callback],
epochs=num_epochs,
)
```

يمكنك تحديد الاسم الكامل لمستودع Git الذي تريد الدفع إليه باستخدام وسيط `hub_model_id` (على وجه الخصوص، سيتعين عليك استخدام هذا الوسيط للدفع إلى منظمة). على سبيل المثال، عندما قمنا بالدفع بالنموذج إلى منظمة [`huggingface-course`](https://huggingface.co/huggingface-course)، أضفنا `hub_model_id="huggingface-course/bert-finetuned-ner"`. بشكل افتراضي، سيتم استخدام المستودع الموجود في مساحة الاسم الخاصة بك ويتم تسميته باسم دليل الإخراج الذي قمت بتعيينه، على سبيل المثال `"cool_huggingface_user/bert-finetuned-ner"`.

💡 إذا كان دليل الإخراج الذي تستخدمه موجودًا بالفعل، فيجب أن يكون مستنسخًا محليًا لمستودع Git الذي تريد الدفع إليه. إذا لم يكن كذلك، فستحصل على خطأ عند استدعاء `model.fit()` وسيتعين عليك تعيين اسم جديد.

لاحظ أنه أثناء التدريب، في كل مرة يتم فيها حفظ النموذج (هنا، كل فترة) يتم تحميله في Hub في الخلفية. بهذه الطريقة، ستتمكن من استئناف التدريب على جهاز آخر إذا لزم الأمر.

في هذه المرحلة، يمكنك استخدام أداة الاستدلال على Model Hub لاختبار نموذجك ومشاركته مع أصدقائك. لقد نجحت في ضبط دقة نموذج لمهمة تصنيف الرموز - تهانينا! ولكن كم هو جيد نموذجنا حقًا؟ يجب أن نقيم بعض المقاييس لمعرفة ذلك.

### المقاييس

لحساب مقياس كل حقبة، سنحتاج إلى تعريف دالة `compute_metrics()` تأخذ صفائف التوقعات والتسميات، وتعيد قاموسًا بأسماء المقاييس وقيمها.

الإطار التقليدي المستخدم لتقييم تنبؤات تصنيف الرموز هو [*seqeval*](https://github.com/chakki-works/seqeval). لاستخدام هذا المقياس، يجب علينا أولاً تثبيت مكتبة *seqeval*:

```py
!pip install seqeval
```

بعد ذلك، يمكننا تحميله عبر دالة `evaluate.load()` كما فعلنا في [الفصل 3](/course/chapter3):

```py
import evaluate

metric = evaluate.load("seqeval")
```

هذا المقياس لا يتصرف مثل الدقة القياسية: في الواقع، سيأخذ قوائم التسميات كسلاسل، وليس كأعداد صحيحة، لذلك سيتعين علينا فك تشفير التوقعات والتسميات بالكامل قبل تمريرها إلى المقياس. دعونا نرى كيف يعمل. أولاً، سنحصل على التسميات لمثال التدريب الأول:

```py
labels = raw_datasets["train"][0]["ner_tags"]
labels = [label_names[i] for i in labels]
labels
```

```python out
['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']
```

بعد ذلك، يمكننا إنشاء تنبؤات وهمية لتلك عن طريق تغيير القيمة في الفهرس 2:

```py
predictions = labels.copy()
predictions[2] = "O"
metric.compute(predictions=[predictions], references=[labels])
```

لاحظ أن المقياس يأخذ قائمة من التوقعات (وليس مجرد واحدة) وقائمة من التسميات. إليك الإخراج:

```python out
{'MISC': {'precision': 1.0, 'recall': 0.5, 'f1': 0.67, 'number': 2},
'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},
'overall_precision': 1.0,
'overall_recall': 0.67,
'overall_f1': 0.8,
'overall_accuracy': 0.89}
```

ترسل هذه الطريقة الكثير من المعلومات! نحصل على الدقة والاستدعاء ومقياس F1 لكل كيان منفصل، بالإضافة إلى الإجمالي. بالنسبة لحساب المقياس، سنحتفظ فقط بالنتيجة الإجمالية، ولكن لا تتردد في ضبط دالة `compute_metrics()` لإرجاع جميع المقاييس التي تريد الإبلاغ عنها.

تقوم دالة `compute_metrics()` هذه أولاً بأخذ argmax من logits لتحويلها إلى تنبؤات (كما هو معتاد، يتم ترتيب logits والاحتمالات بنفس الترتيب، لذلك لا نحتاج إلى تطبيق softmax). بعد ذلك، يتعين علينا تحويل كل من التسميات والتنبؤات من أعداد صحيحة إلى سلاسل. نقوم بإزالة جميع القيم حيث تكون التسمية `-100`، ثم نقوم بتمرير النتائج إلى طريقة `metric.compute()`:

```py
import numpy as np


def compute_metrics(eval_preds):
logits, labels = eval_preds
predictions = np.argmax(logits, axis=-1)

# إزالة الفهرس المُتجاهَل (الرموز الخاصة) وتحويلها إلى تسميات
true_labels = [[label_names[l] for l in label if l != -100] for label in labels]
true_predictions = [
[label_names[p] for (p, l) in zip(prediction, label) if l != -100]
for prediction, label in zip(predictions, labels)
]
all_metrics = metric.compute(predictions=true_predictions, references=true_labels)
return {
"precision": all_metrics["overall_precision"],
"recall": all_metrics["overall_recall"],
"f1": all_metrics["overall_f1"],
"accuracy": all_metrics["overall_accuracy"],
}
```

الآن بعد أن انتهينا من ذلك، نحن على وشك تعريف `Trainer` الخاص بنا. كل ما نحتاجه هو `model` لضبط دقة النموذج!

هذه الطريقة ترسل الكثير من المعلومات! نحصل على الدقة والاستدعاء ومقياس F1 لكل كيان منفصل، بالإضافة إلى الإجمالي. الآن دعونا نرى ما سيحدث إذا حاولنا استخدام تنبؤات نموذجنا الفعلي لحساب بعض الدرجات الحقيقية.

لا يحب TensorFlow دمج تنبؤاتنا معًا، لأن لها أطوال تسلسل متغيرة. هذا يعني أننا لا نستطيع استخدام `model.predict()` - ولكن هذا لن يوقفنا. سنحصل على بعض التنبؤات دفعة واحدة وسنقوم بدمجها في قائمة طويلة واحدة أثناء التنقل، وإسقاط رموز `-100` التي تشير إلى التعتيم/التعبئة، ثم حساب المقاييس على القائمة في النهاية:

```py
import numpy as np

all_predictions = []
all_labels = []
for batch in tf_eval_dataset:
logits = model.predict_on_batch(batch)["logits"]
labels = batch["labels"]
predictions = np.argmax(logits, axis=-1)
for prediction, label in zip(predictions, labels):
for predicted_idx, label_idx in zip(prediction, label):
if label_idx == -100:
continue
all_predictions.append(label_names[predicted_idx])
all_labels.append(label_names[label_idx])
metric.compute(predictions=[all_predictions], references=[all_labels])
```

```python out
{'LOC': {'precision': 0.91, 'recall': 0.92, 'f1': 0.91, 'number': 1668},
'MISC': {'precision': 0.70, 'recall': 0.79, 'f1': 0.74, 'number': 702},
'ORG': {'precision': 0.85, 'recall': 0.90, 'f1': 0.88, 'number': 1661},
'PER': {'precision': 0.95, 'recall': 0.95, 'f1': 0.95, 'number': 1617},
'overall_precision': 0.87,
'overall_recall': 0.91,
'overall_f1': 0.89,
'overall_accuracy': 0.97}
```

كيف كان أداء نموذجك، مقارنة بنموذجنا؟ إذا حصلت على أرقام مماثلة، فقد نجح تدريبك!

### تعريف النموذج

نظرًا لأننا نعمل على مشكلة تصنيف الرموز، فسنستخدم فئة `AutoModelForTokenClassification`. الشيء الرئيسي الذي يجب تذكره عند تعريف هذا النموذج هو تمرير بعض المعلومات حول عدد التسميات التي لدينا. أسهل طريقة للقيام بذلك هي تمرير هذا الرقم باستخدام وسيط `num_labels`، ولكن إذا أردنا أداة استدلال تعمل بشكل جيد مثل التي رأيناها في بداية هذا القسم، فمن الأفضل تعيين مراسلات التسميات الصحيحة بدلاً من ذلك.

يجب تعيينها بواسطة قاموسين، `id2label` و`label2id`، يحتويان على الخرائط من ID إلى التسمية والعكس:

```py
id2label = {i: label for i, label in enumerate(label_names)}
label2id = {v: k for k, v in id2label.items()}
```

الآن يمكننا فقط تمريرها إلى طريقة `AutoModelForTokenClassification.from_pretrained()`، وسيتم تعيينها في تكوين النموذج ثم حفظها وتحميلها بشكل صحيح إلى Hub:

```py
from transformers import AutoModelForTokenClassification

model = AutoModelForTokenClassification.from_pretrained(
model_checkpoint,
id2label=id2label,
label2id=label2id,
)
```

كما هو الحال عند تعريف `AutoModelForSequenceClassification` الخاص بنا في [الفصل 3](/course/chapter3)، فإن إنشاء النموذج يصدر تحذيرًا مفاده أن بعض الأوزان لم تستخدم (تلك الموجودة في رأس التدريب المسبق) وأن بعض الأوزان الأخرى تم تهيئتها بشكل عشوائي (تلك الموجودة في رأس تصنيف الرموز الجديد)، وأن هذا النموذج يجب تدريبه. سنفعل ذلك بعد قليل، ولكن أولاً دعونا نتأكد من أن نموذجنا لديه العدد الصحيح من التسميات:

```python
model.config.num_labels
```

```python out
9
```

⚠️ إذا كان لديك نموذج بعدد التسميات غير الصحيحة، فستحصل على خطأ غامض عند استدعاء طريقة `Trainer.train()` لاحقًا (شيء مثل "خطأ CUDA: تم تشغيل التأكيد على جانب الجهاز"). هذا هو السبب الأول للأخطاء التي أبلغ عنها المستخدمون لمثل هذه الأخطاء، لذا تأكد من إجراء هذا الفحص للتأكد من أن لديك عدد التسميات المتوقع.
### تهيئة النموذج الدقيق

الآن نحن مستعدون لتدريب نموذجنا! نحتاج فقط إلى القيام بآخر أمرين قبل أن نحدد مدربنا: تسجيل الدخول إلى Hugging Face وتحديد حجج التدريب. إذا كنت تعمل في دفتر ملاحظات، فهناك دالة ملائمة لمساعدتك في ذلك:

```python
from huggingface_hub import notebook_login

notebook_login()
```

سيتم عرض أداة يمكنك من خلالها إدخال بيانات اعتماد تسجيل الدخول إلى Hugging Face.

إذا لم تكن تعمل في دفتر الملاحظات، فما عليك سوى كتابة السطر التالي في المحطة الطرفية الخاصة بك:

```bash
huggingface-cli login
```

بمجرد الانتهاء من ذلك، يمكننا تحديد حجج التدريب الخاصة بنا:

```python
from transformers import TrainingArguments

args = TrainingArguments(
"bert-finetuned-ner",
evaluation_strategy="epoch"،
save_strategy="epoch"،
learning_rate=2e-5,
num_train_epochs=3,
weight_decay=0.01,
push_to_hub=True,
)
```

لقد رأيت معظمها من قبل: نحدد بعض فرط المعلمات (مثل معدل التعلم، وعدد العصور التي يجب التدريب عليها، وتدهور الوزن)، ونحدد push_to_hub=True للإشارة إلى أننا نريد حفظ النموذج وتقييمه في نهاية كل حقبة، وأننا نريد تحميل نتائجنا إلى Model Hub. لاحظ أنه يمكنك تحديد اسم المستودع الذي تريد دفعه إلى باستخدام حجة hub_model_id (على وجه الخصوص، سيتعين عليك استخدام هذه الحجة للدفع إلى منظمة). على سبيل المثال، عندما قمنا بدفع النموذج إلى منظمة huggingface-course، أضفنا hub_model_id="huggingface-course/bert-finetuned-ner" إلى TrainingArguments. بشكل افتراضي، سيتم استخدام المستودع الموجود في مساحة الأسماء الخاصة بك ويتم تسميته باسم دليل الإخراج الذي قمت بتعيينه، لذلك في حالتنا سيكون "sgugger/bert-finetuned-ner".

<Tip>
💡 إذا كان دليل الإخراج الذي تستخدمه موجودًا بالفعل، فيجب أن يكون مستنسخًا محليًا للمستودع الذي تريد دفعه إليه. إذا لم يكن كذلك، فستحصل على خطأ عند تحديد مدربك وسيتعين عليك تعيين اسم جديد.
</Tip>

أخيرًا، نقوم فقط بإمرار كل شيء إلى المدرب وإطلاق التدريب:

```python
from transformers import Trainer

trainer = Trainer(
model=model,
args=args,
train_dataset=tokenized_datasets["train"],
eval_dataset=tokenized_datasets["validation"],
data_collator=data_collator,
compute_metrics=compute_metrics,
tokenizer=tokenizer,
)
trainer.train()
```

لاحظ أنه أثناء التدريب، في كل مرة يتم فيها حفظ النموذج (هنا، كل حقبة)، يتم تحميله في الخلفية إلى Hub. بهذه الطريقة، ستتمكن من استئناف تدريبك على آلة أخرى إذا لزم الأمر.

بمجرد اكتمال التدريب، نستخدم طريقة push_to_hub() للتأكد من تحميل أحدث إصدار من النموذج:

```py
trainer.push_to_hub(commit_message="Training complete")
```

تعيد هذه الأوامر عنوان URL للالتزام الذي قام به للتو، إذا كنت تريد فحصه:

```python out
'https://huggingface.co/sgugger/bert-finetuned-ner/commit/26ab21e5b1568f9afeccdaed2d8715f571d786ed'
```

كما يقوم المدرب بإنشاء مسودة لبطاقة نموذج بجميع نتائج التقييم وتحميلها. في هذه المرحلة، يمكنك استخدام أداة الاستدلال على Model Hub لاختبار نموذجك ومشاركته مع أصدقائك. لقد قمت بضبط دقيق لنموذج بنجاح على مهمة تصنيف الرموز - تهانينا!

إذا كنت تريد الغوص بشكل أعمق قليلاً في حلقة التدريب، فسنريكم الآن كيفية القيام بنفس الشيء باستخدام 🤗 Accelerate.

## حلقة تدريب مخصصة

دعونا الآن نلقي نظرة على حلقة التدريب الكاملة، حتى تتمكن من تخصيص الأجزاء التي تحتاجها. سيشبه ذلك كثيرًا ما فعلناه في الفصل 3، مع بعض التغييرات في التقييم.

### إعداد كل شيء للتدريب

أولاً، نحتاج إلى بناء DataLoader من مجموعات البيانات الخاصة بنا. سنعيد استخدام data_collator كـ collate_fn ونخلط مجموعة التدريب، ولكن ليس مجموعة التحقق:

```py
from torch.utils.data import DataLoader

train_dataloader = DataLoader(
tokenized_datasets["train"],
shuffle=True,
collate_fn=data_collator,
batch_size=8,
)
eval_dataloader = DataLoader(
tokenized_datasets["validation"], collate_fn=data_collator, batch_size=8
)
```

بعد ذلك، سنعيد إنشاء نموذجنا، للتأكد من أننا لا نواصل الضبط الدقيق من قبل، ولكننا نبدأ مرة أخرى من نموذج BERT المعلم مسبقًا:

```py
model = AutoModelForTokenClassification.from_pretrained(
model_checkpoint,
id2label=id2label,
label2id=label2id,
)
```

ثم سنحتاج إلى محسن. سنستخدم AdamW الكلاسيكي، والذي يشبه Adam، ولكن مع إصلاح في طريقة تطبيق تدهور الوزن:

```py
from torch.optim import AdamW

optimizer = AdamW(model.parameters(), lr=2e-5)
```

بمجرد أن نحصل على كل هذه الأشياء، يمكننا إرسالها إلى طريقة accelerator.prepare():

```py
from accelerate import Accelerator

accelerator = Accelerator()
model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(
model, optimizer, train_dataloader, eval_dataloader
)
```

<Tip>
🚨 إذا كنت تتدرب على وحدة معالجة الرسومات (TPU)، فسوف تحتاج إلى نقل كل التعليمات البرمجية بدءًا من الخلية أعلاه إلى دالة تدريب مخصصة. راجع الفصل 3 لمزيد من التفاصيل.
</Tip>

الآن بعد أن أرسلنا train_dataloader إلى accelerator.prepare()، يمكننا استخدام طوله لحساب عدد خطوات التدريب. تذكر أنه يجب علينا دائمًا القيام بذلك بعد إعداد DataLoader، حيث ستغير هذه الطريقة طوله. نستخدم جدولًا زمنيًا خطيًا كلاسيكيًا من معدل التعلم إلى 0:

```py
from transformers import get_scheduler

num_train_epochs = 3
num_update_steps_per_epoch = len(train_dataloader)
num_training_steps = num_train_epochs * num_update_steps_per_epoch

lr_scheduler = get_scheduler(
"linear",
optimizer=optimizer,
num_warmup_steps=0,
num_training_steps=num_training_steps,
)
```

أخيرًا، لدفع نموذجنا إلى Hub، سيتعين علينا إنشاء كائن مستودع في مجلد عمل. قم بتسجيل الدخول إلى Hugging Face أولاً، إذا لم تكن قد قمت بتسجيل الدخول بالفعل. سنحدد اسم المستودع من معرف النموذج الذي نريد منحه لنموذجنا (لا تتردد في استبدال repo_name بخيارك الخاص؛ كل ما عليك هو تضمين اسم المستخدم الخاص بك، وهو ما تفعله دالة get_full_repo_name()):

```py
from huggingface_hub import Repository, get_full_repo_name

model_name = "bert-finetuned-ner-accelerate"
repo_name = get_full_repo_name(model_name)
repo_name
```

```python out
'sgugger/bert-finetuned-ner-accelerate'
```

بعد ذلك، يمكننا استنساخ هذا المستودع في مجلد محلي. إذا كان موجودًا بالفعل، فيجب أن يكون هذا المجلد المحلي مستنسخًا موجودًا للمستودع الذي نعمل معه:

```py
output_dir = "bert-finetuned-ner-accelerate"
repo = Repository(output_dir, clone_from=repo_name)
```

الآن يمكننا تحميل أي شيء نقوم بحفظه في output_dir عن طريق استدعاء طريقة repo.push_to_hub(). سيساعدنا هذا في تحميل النماذج المتوسطة في نهاية كل حقبة.

### حلقة التدريب

نحن الآن على استعداد لكتابة حلقة التدريب الكاملة. لتبسيط الجزء الخاص بالتقييم، نقوم بتعريف دالة postprocess() هذه التي تأخذ التوقعات والعلامات وتحويلها إلى قوائم من السلاسل، مثل كائن المقياس الذي يتوقعها:

```py
def postprocess(predictions, labels):
predictions = predictions.detach().cpu().clone().numpy()
labels = labels.detach().cpu().clone().numpy()

# Remove ignored index (special tokens) and convert to labels
true_labels = [[label_names[l] for l in label if l != -100] for label in labels]
true_predictions = [
[label_names[p] for (p, l) in zip(prediction, label) if l != -100]
for prediction, label in zip(predictions, labels)
]
return true_labels, true_predictions
```

بعد ذلك، يمكننا كتابة حلقة التدريب. بعد تحديد شريط تقدم لمتابعة كيفية سير التدريب، تنقسم الحلقة إلى ثلاثة أجزاء:

- التدريب نفسه، وهو تكرار كلاسيكي عبر train_dataloader، والمرور الأمامي عبر النموذج، ثم المرور الخلفي وخطوة المحسن.
- التقييم، الذي يوجد فيه ابتكار بعد الحصول على الإخراج من نموذجنا على دفعة: نظرًا لأن عمليتين قد تكونان قد سددتا المدخلات والعلامات إلى أشكال مختلفة، فنحن بحاجة إلى استخدام accelerator.pad_across_processes() لجعل التوقعات والعلامات بنفس الشكل قبل استدعاء طريقة gather(). إذا لم نفعل ذلك، فسيؤدي التقييم إلى حدوث خطأ أو تعليق إلى الأبد. ثم نرسل النتائج إلى metric.add_batch() واستدعاء metric.compute() بمجرد انتهاء حلقة التقييم.
- الحفظ والتحميل، حيث نقوم أولاً بحفظ النموذج والمحلل اللغوي، ثم استدعاء repo.push_to_hub(). لاحظ أننا نستخدم الحجة blocking=False لإخبار مكتبة Hub 🤗 بالدفع في عملية غير متزامنة. بهذه الطريقة، يستمر التدريب بشكل طبيعي ويتم تنفيذ هذا الأمر (الطويل) في الخلفية.

فيما يلي الكود الكامل لحلقة التدريب:

```py
from tqdm.auto import tqdm
import torch

progress_bar = tqdm(range(num_training_steps))

for epoch in range(num_train_epochs):
# Training
model.train()
for batch in train_dataloader:
outputs = model(**batch)
loss = outputs.loss
accelerator.backward(loss)

optimizer.step()
lr_scheduler.step()
optimizer.zero_grad()
progress_bar.update(1)

# Evaluation
model.eval()
for batch in eval_dataloader:
with torch.no_grad():
outputs = model(**batch)

predictions = outputs.logits.argmax(dim=-1)
labels = batch["labels"]

# Necessary to pad predictions and labels for being gathered
predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)
labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)

predictions_gathered = accelerator.gather(predictions)
labels_gathered = accelerator.gather(labels)

true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)
metric.add_batch(predictions=true_predictions, references=true_labels)

results = metric.compute()
print(
f"epoch {epoch}:",
{
key: results[f"overall_{key}"]
for key in ["precision", "recall", "f1", "accuracy"]
},
)

# Save and upload
accelerator.wait_for_everyone()
unwrapped_model = accelerator.unwrap_model(model)
unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
if accelerator.is_main_process:
tokenizer.save_pretrained(output_dir)
repo.push_to_hub(
commit_message=f"Training in progress epoch {epoch}", blocking=False
)
```

في حالة رؤيتك لنموذج محفوظ باستخدام 🤗 Accelerate لأول مرة، دعنا نلقي نظرة على أسطر التعليمات البرمجية الثلاثة التي تأتي معه:

```py
accelerator.wait_for_everyone()
unwrapped_model = accelerator.unwrap_model(model)
unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
```

الخط الأول واضح: فهو يخبر جميع العمليات بالانتظار حتى يصل الجميع إلى تلك المرحلة قبل المتابعة. هذا للتأكد من أن لدينا نفس النموذج في كل عملية قبل الحفظ. ثم نلتقط unwrapped_model، وهو النموذج الأساسي الذي حددناه. تغير طريقة accelerator.prepare() النموذج للعمل في التدريب الموزع، لذا فلن يكون لديه طريقة save_pretrained() بعد الآن؛ طريقة accelerator.unwrap_model() تلغي هذه الخطوة. أخيرًا، نستدعي save_pretrained() ولكن نخبر هذه الطريقة باستخدام accelerator.save() بدلاً من torch.save().

بمجرد الانتهاء من ذلك، يجب أن يكون لديك نموذج ينتج نتائج مشابهة جدًا للنموذج الذي تم تدريبه باستخدام المدرب. يمكنك التحقق من النموذج الذي تدربنا عليه باستخدام هذا الرمز في [huggingface-course/bert-finetuned-ner-accelerate](https://huggingface.co/huggingface-course/bert-finetuned-ner-accelerate). وإذا كنت تريد تجربة أي تعديلات على حلقة التدريب، فيمكنك تنفيذها مباشرة عن طريق تحرير الكود الموضح أعلاه!

{/if}

## استخدام النموذج الدقيق

لقد أظهرنا لك بالفعل كيف يمكنك استخدام النموذج الذي قمنا بضبطه بدقة على Model Hub باستخدام أداة الاستدلال. لاستخدامه محليًا في خط أنابيب، ما عليك سوى تحديد معرف نقطة التفتيش الصحيح:

```py
from transformers import pipeline

# استبدل هذا بنقطة التفتيش الخاصة بك
model_checkpoint = "huggingface-course/bert-finetuned-ner"
token_classifier = pipeline(
"token-classification"، model=model_checkpoint، aggregation_strategy="simple"
)
token_classifier("My name is Sylvain and I work at Hugging Face in Brooklyn.")
```

```python out
[{'entity_group': 'PER', 'score': 0.9988506, 'word': 'Sylvain', 'start': 11, 'end': 18},
{'entity_group': 'ORG', 'score': 0.9647625, 'word': 'Hugging Face', 'start': 33, 'end': 45},
{'entity_group': 'LOC', 'score': 0.9986118, 'word': 'Brooklyn', 'start': 49, 'end': 57}]
```

رائع! يعمل نموذجنا جيدًا مثل النموذج الافتراضي لهذا الأنبوب!