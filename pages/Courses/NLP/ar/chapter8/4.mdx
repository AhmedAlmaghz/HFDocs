# تصحيح خطأ أنبوب التدريب

لقد كتبت نصًا جميلًا لتدريب أو ضبط نموذج على مهمة معينة، مع اتباع النصيحة من [الفصل 7](/course/chapter7) بكل دقة. ولكن عند تشغيل الأمر `trainer.train()`، يحدث شيء فظيع: تحصل على خطأ 😱! أو ما هو أسوأ، يبدو أن كل شيء على ما يرام، ويتم التدريب دون أخطاء، ولكن النموذج الناتج غير جيد. في هذا القسم، سنريكم ما يمكنكم فعله لتصحيح هذه الأنواع من المشكلات.

## تصحيح خطأ أنبوب التدريب

عند مواجهة خطأ في `trainer.train()`، قد يكون مصدره عدة أمور، حيث يقوم الـ `Trainer` عادة بجمع الكثير من الأشياء. فهو يحول مجموعات البيانات إلى محملات بيانات، لذا فقد يكون المشكل ناتج عن خطأ في مجموعة البيانات الخاصة بك، أو مشكلة ما عند محاولة دمج عناصر من مجموعات البيانات معًا. ثم يأخذ دفعة من البيانات ويرسلها إلى النموذج، لذا فقد يكون المشكل في كود النموذج. بعد ذلك، يحسب المشتقات ويؤدي خطوة التحسين، لذا فقد يكون المشكل أيضًا في محسنك. وحتى إذا سار كل شيء على ما يرام أثناء التدريب، فقد يحدث خطأ ما أثناء التقييم إذا كان هناك مشكلة في مقياسك.

أفضل طريقة لتصحيح خطأ يحدث في `trainer.train()` هي المرور يدويًا عبر خط الأنابيب هذا بأكمله لمعرفة أين حدث الخطأ. غالبًا ما يكون الخطأ سهل الحل.

لإثبات ذلك، سنستخدم النص البرمجي التالي الذي (يحاول) ضبط نموذج DistilBERT على مجموعة بيانات [MNLI](https://huggingface.co/datasets/glue):

```py
from datasets import load_dataset
import evaluate
from transformers import (
AutoTokenizer,
AutoModelForSequenceClassification,
TrainingArguments,
Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)

args = TrainingArguments(
f"distilbert-finetuned-mnli",
evaluation_strategy="epoch",
save_strategy="epoch",
learning_rate=2e-5,
num_train_epochs=3,
weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
predictions, labels = eval_pred
return metric.compute(predictions=predictions, references=labels)


trainer = Trainer(
model,
args,
train_dataset=raw_datasets["train"],
eval_dataset=raw_datasets["validation_matched"],
compute_metrics=compute_metrics,
)
trainer.train()
```

إذا حاولت تنفيذ هذا النص البرمجي، فستحصل على خطأ غامض إلى حد ما:

```python out
'ValueError: You have to specify either input_ids or inputs_embeds'
```

### تحقق من بياناتك

غني عن القول أنه إذا كانت بياناتك تالفة، فلن يتمكن الـ `Trainer` من تشكيل دفعات، ناهيك عن تدريب نموذجك. لذا، يجب عليك أولاً التحقق مما يوجد داخل مجموعة بيانات التدريب الخاصة بك.

لتجنب قضاء ساعات لا تحصى في محاولة إصلاح شيء ليس مصدر الخطأ، نوصي باستخدام `trainer.train_dataset` لعمليات التحقق الخاصة بك وعدم استخدام أي شيء آخر. لذا، دعونا نقوم بذلك هنا:

```py
trainer.train_dataset[0]
```

```python out
{'hypothesis': 'Product and geography are what make cream skimming work. ',
'idx': 0,
'label': 1,
'premise': 'Conceptually cream skimming has two basic dimensions - product and geography.'}
```

هل لاحظت شيئًا خاطئًا؟ هذا، إلى جانب رسالة الخطأ حول `input_ids` المفقودة، يجب أن يجعلك تدرك أن هذه نصوص، وليست أرقامًا يمكن للنموذج فهمها. هنا، يكون الخطأ الأصلي مضللاً للغاية لأن الـ `Trainer` يزيل تلقائيًا الأعمدة التي لا تتطابق مع توقيع النموذج (أي، الحجج التي يتوقعها النموذج). وهذا يعني أنه هنا، تم التخلص من كل شيء باستثناء العلامات. وبالتالي، لم تكن هناك مشكلة في إنشاء دفعات ثم إرسالها إلى النموذج، والذي اشتكى بدوره من أنه لم يتلق المدخلات الصحيحة.

لماذا لم تتم معالجة البيانات؟ لقد استخدمنا طريقة `Dataset.map()` على مجموعات البيانات لتطبيق الـ tokenizer على كل عينة. ولكن إذا نظرت عن كثب إلى الكود، فستلاحظ أننا ارتكبنا خطأً عند تمرير مجموعات التدريب والتقييم إلى الـ `Trainer`. بدلاً من استخدام `tokenized_datasets` هنا، استخدمنا `raw_datasets` 🤦. لذا، دعونا نصلح هذا الخطأ!

```py
from datasets import load_dataset
import evaluate
from transformers import (
AutoTokenizer,
AutoModelForSequenceClassification,
TrainingArguments,
Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)

args = TrainingArguments(
f"distilbert-finetuned-mnli",
evaluation_strategy="epoch",
save_strategy="epoch",
learning_rate=2e-5,
num_train_epochs=3,
weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
predictions, labels = eval_pred
return metric.compute(predictions=predictions, references=labels)


trainer = Trainer(
model,
args,
train_dataset=tokenized_datasets["train"],
eval_dataset=tokenized_datasets["validation_matched"],
compute_metrics=compute_metrics,
)
trainer.train()
```

سيعطي هذا الكود الجديد خطأ مختلفًا (تقدم!):

```python out
'ValueError: expected sequence of length 43 at dim 1 (got 37)'
```

بالنظر إلى تتبع المكدس، يمكننا أن نرى أن الخطأ يحدث في خطوة تجميع البيانات:

```python out
~/git/transformers/src/transformers/data/data_collator.py in torch_default_data_collator(features)
105                 batch[k] = torch.stack([f[k] for f in features])
106             else:
--> 107                 batch[k] = torch.tensor([f[k] for f in features])
108
109     return batch
```

لذا، يجب علينا الانتقال إلى ذلك. ولكن قبل أن نفعل ذلك، دعونا ننهي فحص بياناتنا، فقط للتأكد بنسبة 100% من أنها صحيحة.

هناك شيء يجب عليك دائمًا فعله عند تصحيح جلسة تدريب وهو إلقاء نظرة على المدخلات المشفرة لنموذجك. لا يمكننا فهم الأرقام التي نمررها إليها مباشرةً، لذا يجب علينا النظر إلى ما تمثله تلك الأرقام. في رؤية الكمبيوتر، على سبيل المثال، يعني ذلك النظر إلى الصور المشفرة للبكسلات التي تمررها، وفي الكلام يعني الاستماع إلى عينات الصوت المشفرة، وبالنسبة لمثال NLP هنا، يعني استخدام الـ tokenizer الخاص بنا لتشفير المدخلات:

```py
tokenizer.decode(trainer.train_dataset[0]["input_ids"])
```

```python out
'[CLS] conceptually cream skimming has two basic dimensions - product and geography. [SEP] product and geography are what make cream skimming work. [SEP]'
```

لذا يبدو ذلك صحيحًا. يجب عليك القيام بذلك لجميع المفاتيح في المدخلات:

```py
trainer.train_dataset[0].keys()
```

```python out
dict_keys(['attention_mask', 'hypothesis', 'idx', 'input_ids', 'label', 'premise'])
```

لاحظ أنه سيتم التخلص تلقائيًا من المفاتيح التي لا تتطابق مع المدخلات التي يقبلها النموذج، لذا هنا سنحتفظ فقط بـ `input_ids`، و`attention_mask`، و`label` (والتي سيتم إعادة تسميتها إلى `labels`). للتأكد من توقيع النموذج، يمكنك طباعة فئة نموذجك، ثم التحقق من وثائقه:

```py
type(trainer.model)
```

```python out
transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification
```

لذا، في حالتنا، يمكننا التحقق من المعلمات المقبولة على [هذه الصفحة](https://huggingface.co/transformers/model_doc/distilbert.html#distilbertforsequenceclassification). كما سيقوم الـ `Trainer` بتسجيل الأعمدة التي يتم التخلص منها.

لقد تحققنا من أن معرفات الإدخال صحيحة عن طريق فك تشفيرها. التالي هو `attention_mask`:

```py
trainer.train_dataset[0]["attention_mask"]
```

```python out
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
```

نظرًا لأننا لم نطبق الحشو في معالجتنا المسبقة، يبدو هذا طبيعيًا تمامًا. للتأكد من عدم وجود مشكلة مع قناع الاهتمام هذا، دعنا نتحقق من أنه بنفس طول معرفات الإدخال الخاصة بنا:

```py
len(trainer.train_dataset[0]["attention_mask"]) == len(
trainer.train_dataset[0]["input_ids"]
)
```

```python out
True
```

هذا جيد! أخيرًا، دعنا نتحقق من علامتنا:

```py
trainer.train_dataset[0]["label"]
```

```python out
1
```

مثل معرفات الإدخال، هذا رقم لا معنى له بمفرده. كما رأينا سابقًا، يتم تخزين الخريطة بين الأعداد الصحيحة وأسماء العلامات داخل السمة `names` للـ *feature* المقابلة لمجموعة البيانات:

```py
trainer.train_dataset.features["label"].names
```

```python out
['entailment', 'neutral', 'contradiction']
```

لذا فإن `1` تعني `neutral`، مما يعني أن الجملتين اللتين رأيناهما أعلاه لا تتعارضان، ولا تستلزم الجملة الأولى الجملة الثانية. يبدو ذلك صحيحًا!

لا توجد لدينا معرفات أنواع الرموز هنا، لأن DistilBERT لا يتوقعها؛ إذا كان لديك بعضها في نموذجك، فيجب عليك أيضًا التأكد من أنها تتطابق بشكل صحيح مع الجملة الأولى والثانية في الإدخال.

✏️ **جرب بنفسك!** تحقق من أن كل شيء يبدو صحيحًا مع العنصر الثاني من مجموعة البيانات التدريبية.

نحن نقوم بالتحقق من مجموعة البيانات التدريبية فقط هنا، ولكن بالطبع يجب عليك التحقق من مجموعات البيانات الخاصة بالتحقق والاختبار بنفس الطريقة.

الآن بعد أن علمنا أن مجموعات البيانات تبدو جيدة، حان الوقت للتحقق من الخطوة التالية في خط أنابيب التدريب.
### من مجموعات البيانات إلى محملات البيانات

الشيء التالي الذي قد يحدث خطأ في خط أنابيب التدريب هو عندما يحاول "المدرب" تشكيل دفعات من مجموعة التدريب أو التحقق. بمجرد التأكد من صحة مجموعات بيانات "المدرب"، يمكنك محاولة تشكيل دفعة يدويًا عن طريق تنفيذ ما يلي (استبدل "train" بـ "eval" لمجموعة بيانات التحقق):

```py
for batch in trainer.get_train_dataloader():
break
```

ينشئ هذا الكود محمل بيانات التدريب، ثم يقوم بالتعيين خلاله، والتوقف عند التكرار الأول. إذا تم تنفيذ الكود دون خطأ، فستحصل على أول دفعة تدريب يمكنك فحصها، وإذا حدث خطأ في الكود، فستعرف بالتأكيد أن المشكلة تكمن في محمل البيانات، كما هو الحال هنا:

```python out
~/git/transformers/src/transformers/data/data_collator.py in torch_default_data_collator(features)
105                 batch[k] = torch.stack([f[k] for f in features])
106             else:
--> 107                 batch[k] = torch.tensor([f[k] for f in features])
108
109     return batch

ValueError: expected sequence of length 45 at dim 1 (got 76)
```

يجب أن يكون فحص الإطار الأخير من تتبع المكدس كافيًا لمنحك تلميحًا، ولكن دعنا نقوم بالتنقيب أكثر قليلاً. تنشأ معظم المشكلات أثناء إنشاء الدفعة بسبب تجميع الأمثلة في دفعة واحدة، لذا فإن أول شيء يجب التحقق منه عند الشك هو دالة `collate_fn` التي يستخدمها `DataLoader` الخاص بك:

```py
data_collator = trainer.get_train_dataloader().collate_fn
data_collator
```

```python out
<function transformers.data.data_collator.default_data_collator(features: List[InputDataClass], return_tensors='pt') -> Dict[str, Any]>
```

لذا، هذا هو `default_data_collator`، ولكن هذا ليس ما نريده في هذه الحالة. نريد أن نملأ أمثلة لدينا إلى أطول جملة في الدفعة، والتي يتم تنفيذها بواسطة `DataCollatorWithPadding` collator. ومن المفترض أن يستخدم محمل البيانات هذا بشكل افتراضي بواسطة "المدرب"، فلماذا لا يتم استخدامه هنا؟

الإجابة هي أننا لم نمرر "محلل الرموز" إلى "المدرب"، لذلك لم يتمكن من إنشاء `DataCollatorWithPadding` الذي نريده. في الممارسة العملية، يجب ألا تتردد أبدًا في تمرير محمل البيانات الذي تريد استخدامه صراحةً، للتأكد من تجنب هذه الأنواع من الأخطاء. دعنا نقوم بتعديل الكود الخاص بنا للقيام بذلك بالضبط:

```py
from datasets import load_dataset
import evaluate
from transformers import (
AutoTokenizer,
AutoModelForSequenceClassification,
DataCollatorWithPadding,
TrainingArguments,
Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)

args = TrainingArguments(
f"distilbert-finetuned-mnli",
evaluation_strategy="epoch",
save_strategy="epoch",
learning_rate=2e-5,
num_train_epochs=3,
weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
predictions, labels = eval_pred
return metric.compute(predictions=predictions, references=labels)


data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
model,
args,
train_dataset=tokenized_datasets["train"],
eval_dataset=tokenized_datasets["validation_matched"],
compute_metrics=compute_metrics,
data_collator=data_collator,
tokenizer=tokenizer,
)
trainer.train()
```

الأخبار السارة؟ لا نحصل على نفس الخطأ كما في السابق، وهو تقدم بالتأكيد. الأخبار السيئة؟ نحصل على خطأ CUDA سيئ السمعة بدلاً من ذلك:

```python out
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
```

هذا أمر سيء لأن أخطاء CUDA يصعب تصحيحها بشكل عام. سنرى بعد لحظة كيفية حل ذلك، ولكن أولاً دعنا ننهي تحليلنا لإنشاء دفعة.

إذا كنت متأكدًا من أن محول البيانات الخاص بك هو الصحيح، فيجب عليك محاولة تطبيقه على بضع عينات من مجموعة البيانات الخاصة بك:

```py
data_collator = trainer.get_train_dataloader().collate_fn
batch = data_collator([trainer.train_dataset[i] for i in range(4)])
```

سيؤدي هذا الكود إلى الفشل لأن مجموعة "train_dataset" تحتوي على أعمدة نصية، والتي يقوم "المدرب" عادةً بإزالتها. يمكنك إزالتها يدويًا، أو إذا كنت تريد تكرار ما يفعله "المدرب" بالضبط خلف الكواليس، فيمكنك استدعاء طريقة `Trainer._remove_unused_columns()` الخاصة التي تقوم بذلك:

```py
data_collator = trainer.get_train_dataloader().collate_fn
actual_train_set = trainer._remove_unused_columns(trainer.train_dataset)
batch = data_collator([actual_train_set[i] for i in range(4)])
```

بعد ذلك، يجب أن تتمكن من تصحيح الأخطاء يدويًا في محول البيانات إذا استمر الخطأ.

الآن بعد أن قمنا بتصحيح أخطاء عملية إنشاء الدفعة، حان الوقت لمرورها عبر النموذج!

### المرور عبر النموذج

يجب أن تكون قادرًا على الحصول على دفعة عن طريق تنفيذ الأمر التالي:

```py
for batch in trainer.get_train_dataloader():
break
```

إذا كنت تشغل هذا الكود في دفتر ملاحظات، فقد تحصل على خطأ CUDA مشابه لما رأيناه سابقًا، وفي هذه الحالة، ستحتاج إلى إعادة تشغيل دفتر الملاحظات الخاص بك وإعادة تنفيذ الجزء الأخير دون سطر `trainer.train()`، وهذا ثاني أكثر الأشياء المزعجة بشأن أخطاء CUDA: فهي تحطم نواة دفتر الملاحظات الخاص بك بشكل لا يمكن إصلاحه. والأكثر إزعاجًا بشأنها هو صعوبة تصحيحها.

لماذا هذا؟ له علاقة بطريقة عمل وحدات معالجة الرسومات (GPUs). إنها فعالة للغاية في تنفيذ الكثير من العمليات بشكل متوازٍ، ولكن العيب هو أنه عندما تؤدي إحدى هذه التعليمات إلى خطأ، فلن تعرف ذلك على الفور. إنه فقط عندما يستدعي البرنامج مزامنة العمليات المتعددة على وحدة معالجة الرسومات (GPU) التي سيدرك أن شيئًا ما قد حدث خطأ، لذا يتم رفع الخطأ في الواقع في مكان لا علاقة له بما أنشأه. على سبيل المثال، إذا نظرنا إلى تتبع المكدس السابق، فقد حدث الخطأ أثناء التمرير الخلفي، ولكننا سنرى بعد لحظة أنه ينبع في الواقع من شيء في التمرير الأمامي.

إذن، كيف نقوم بتصحيح هذه الأخطاء؟ الإجابة سهلة: لا نفعل ذلك. ما لم يكن خطأ CUDA لديك خطأ في الذاكرة غير كافية (مما يعني أنه لا يوجد ذاكرة كافية في وحدة معالجة الرسومات الخاصة بك)، فيجب عليك دائمًا العودة إلى وحدة المعالجة المركزية (CPU) لتصحيح الخطأ.

للقيام بذلك في حالتنا، ما علينا سوى إعادة النموذج إلى وحدة المعالجة المركزية (CPU) واستدعائه على دفعتنا - لم يتم نقل الدفعة التي تم إرجاعها بواسطة `DataLoader` إلى وحدة معالجة الرسومات (GPU) بعد:

```python
outputs = trainer.model.cpu()(**batch)
```

```python out
~/.pyenv/versions/3.7.9/envs/base/lib/python3.7/site-packages/torch/nn/functional.py in nll_loss(input, target, weight, size_average, ignore_index, reduce, reduction)
2386         )
2387     if dim == 2:
-> 2388         ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
2389     elif dim == 4:
2390         ret = torch._C._nn.nll_loss2d(input, target, weight, _Reduction.get_enum(reduction), ignore_index)

IndexError: Target 2 is out of bounds.
```

لذا، فإن الصورة أصبحت أكثر وضوحًا. بدلاً من حدوث خطأ CUDA، لدينا الآن `IndexError` في حساب الخسارة (لذا لا علاقة لها بالتمرير الخلفي، كما قلنا سابقًا). وبشكل أكثر تحديدًا، يمكننا أن نرى أن الهدف 2 هو الذي يخلق الخطأ، لذا فهذه لحظة جيدة للتحقق من عدد العلامات في نموذجنا:

```python
trainer.model.config.num_labels
```

```python out
2
```

مع وجود علامتين، يُسمح فقط بـ 0 و1 كأهداف، ولكن وفقًا لرسالة الخطأ التي حصلنا عليها، فقد حصلنا على 2. من الطبيعي الحصول على 2: إذا تذكرنا أسماء العلامات التي استخرجناها سابقًا، فقد كان هناك ثلاثة، لذا لدينا الفهارس 0 و1 و2 في مجموعة البيانات الخاصة بنا. المشكلة هي أننا لم نخبر ذلك لنموذجنا، والذي كان من المفترض أن يتم إنشاؤه باستخدام ثلاث علامات. لذا دعنا نصلح ذلك!

```py
from datasets import load_dataset
import evaluate
from transformers import (
AutoTokenizer,
AutoModelForSequenceClassification,
DataCollatorWithPadding,
TrainingArguments,
Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=3)

args = TrainingArguments(
f"distilbert-finetuned-mnli",
evaluation_strategy="epoch",
save_strategy="epoch",
learning_rate=2e-5,
num_train_epochs=3,
weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
predictions, labels = eval_pred
return metric.compute(predictions=predictions, references=labels)


data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
model,
args,
train_dataset=tokenized_datasets["train"],
eval_dataset=tokenized_datasets["validation_matched"],
compute_metrics=compute_metrics,
data_collator=data_collator,
tokenizer=tokenizer,
)
```

نحن لا ندرج سطر `trainer.train()` بعد، لأخذ الوقت للتأكد من أن كل شيء يبدو جيدًا. إذا طلبنا دفعة ومررناها إلى نموذجنا، فإنه يعمل الآن دون خطأ!

```py
for batch in trainer.get_train_dataloader():
break

outputs = trainer.model.cpu()(**batch)
```

الخطوة التالية هي الانتقال مرة أخرى إلى وحدة معالجة الرسومات (GPU) والتحقق من أن كل شيء يعمل بشكل صحيح:

```py
import torch

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
batch = {k: v.to(device) for k, v in batch.items()}

outputs = trainer.model.to(device)(**batch)
```

إذا كنت لا تزال تحصل على خطأ، فتأكد من إعادة تشغيل دفتر الملاحظات الخاص بك وتنفيذ الإصدار الأخير من البرنامج النصي فقط.

### تنفيذ خطوة تحسين واحدة

الآن بعد أن علمنا أنه يمكننا بناء دفعات تمر بالفعل عبر النموذج، فنحن مستعدون للخطوة التالية من خط أنابيب التدريب: حساب التدرجات وأداء خطوة تحسين.

الجزء الأول هو مجرد مسألة استدعاء طريقة `backward()` على الخسارة:

```py
loss = outputs.loss
loss.backward()
```

من النادر جدًا حدوث خطأ في هذه المرحلة، ولكن إذا حدث خطأ، فتأكد من العودة إلى وحدة المعالجة المركزية (CPU) للحصول على رسالة خطأ مفيدة.

لأداء خطوة التحسين، نحتاج فقط إلى إنشاء "المحسن" واستدعاء طريقة `step()` الخاصة به:

```py
trainer.create_optimizer()
trainer.optimizer.step()
```

مرة أخرى، إذا كنت تستخدم المحسن الافتراضي في "المدرب"، فيجب ألا تحصل على خطأ في هذه المرحلة، ولكن إذا كان لديك محسن مخصص، فقد تكون هناك بعض المشكلات التي يجب تصحيحها هنا. لا تنس العودة إلى وحدة المعالجة المركزية (CPU) إذا حصلت على خطأ CUDA غريب في هذه المرحلة. وبالحديث عن أخطاء CUDA، ذكرنا سابقًا حالة خاصة. دعنا نلقي نظرة على ذلك الآن.

### التعامل مع أخطاء ذاكرة CUDA غير الكافية

عندما تحصل على رسالة خطأ تبدأ بـ "RuntimeError: CUDA out of memory"، يشير ذلك إلى أن ذاكرة وحدة معالجة الرسومات (GPU) لديك قد نفدت. هذا ليس له علاقة مباشرة بالكود الخاص بك، ويمكن أن يحدث مع برنامج نصي يعمل بشكل مثالي. يشير هذا الخطأ إلى أنك حاولت وضع الكثير من الأشياء في الذاكرة الداخلية لوحدة معالجة الرسومات (GPU) الخاصة بك، مما أدى إلى حدوث خطأ. مثل أخطاء CUDA الأخرى، ستحتاج إلى إعادة تشغيل النواة الخاصة بك لتتمكن من تشغيل التدريب مرة أخرى.

لحل هذه المشكلة، تحتاج فقط إلى استخدام مساحة أقل لوحدة معالجة الرسومات (GPU) - وهو أمر غالبًا ما يكون أسهل في القول من الفعل. أولاً، تأكد من عدم وجود نموذجين على وحدة معالجة الرسومات (GPU) في نفس الوقت (ما لم يكن ذلك مطلوبًا لمشكلتك، بالطبع). بعد ذلك، يجب عليك على الأرجح تقليل حجم الدفعة، حيث يؤثر ذلك بشكل مباشر على أحجام جميع المخرجات الوسيطة للنموذج وتدرجاتها. إذا استمرت المشكلة، ففكر في استخدام إصدار أصغر من نموذجك.

<Tip>
في الجزء التالي من الدورة التدريبية، سنلقي نظرة على تقنيات أكثر تقدمًا يمكن أن تساعدك في تقليل البصمة الخاصة بك في الذاكرة والسماح لك بضبط أكبر النماذج.
</Tip>
## تقييم النموذج

الآن بعد أن قمنا بحل جميع المشكلات في كودنا، أصبح كل شيء مثاليًا ويجب أن تسير عملية التدريب بسلاسة، أليس كذلك؟ ليس بهذه السرعة! إذا قمت بتشغيل أمر `trainer.train()`، فسيبدو كل شيء جيدًا في البداية، ولكن بعد فترة ستحصل على ما يلي:

```py
# سيستغرق هذا وقتًا طويلاً وسينتج عنه خطأ، لذا لا يجب تشغيل هذه الخلية
trainer.train()
```

```python out
TypeError: only size-1 arrays can be converted to Python scalars
```

ستدرك أن هذا الخطأ يحدث أثناء مرحلة التقييم، لذا فإن هذا هو آخر شيء سنحتاج إلى تصحيحه.

يمكنك تشغيل حلقة التقييم لـ `Trainer` بشكل مستقل عن التدريب على النحو التالي:

```py
trainer.evaluate()
```

```python out
TypeError: only size-1 arrays can be converted to Python scalars
```

<Tip>

💡 يجب عليك دائمًا التأكد من أنه يمكنك تشغيل `trainer.evaluate()` قبل إطلاق `trainer.train()`، لتجنب هدر الكثير من موارد الحوسبة قبل مواجهة خطأ.

</Tip>

قبل محاولة تصحيح مشكلة في حلقة التقييم، يجب عليك أولاً التأكد من أنك قمت بفحص البيانات، وقادر على تكوين دفعة بشكل صحيح، ويمكنك تشغيل نموذجك عليها. لقد أكملنا كل هذه الخطوات، لذا يمكن تنفيذ الكود التالي دون أخطاء:

```py
for batch in trainer.get_eval_dataloader():
break

batch = {k: v.to(device) for k, v in batch.items()}

with torch.no_grad():
outputs = trainer.model(**batch)
```

يحدث الخطأ لاحقًا، في نهاية مرحلة التقييم، وإذا نظرنا إلى تتبع المكدس، فسنرى هذا:

```python trace
~/git/datasets/src/datasets/metric.py in add_batch(self, predictions, references)
431         """
432         batch = {"predictions": predictions, "references": references}
--> 433         batch = self.info.features.encode_batch(batch)
434         if self.writer is None:
435             self._init_writer()
```

هذا يخبرنا بأن الخطأ ينشأ في وحدة `datasets/metric.py` -- لذا فهذه مشكلة في وظيفة `compute_metrics()` الخاصة بنا. إنها تأخذ زوجًا من القيم مع logits والعلامات كصفائف NumPy، لذا دعنا نحاول إطعامها بذلك:

```py
predictions = outputs.logits.cpu().numpy()
labels = batch["labels"].cpu().numpy()

compute_metrics((predictions, labels))
```

```python out
TypeError: only size-1 arrays can be converted to Python scalars
```

نحصل على نفس الخطأ، لذا فإن المشكلة تكمن بالتأكيد في تلك الوظيفة. إذا نظرنا مرة أخرى إلى كودها، فسنرى أنها تقوم فقط بإرسال `predictions` و`labels` إلى `metric.compute()`. لذا هل هناك مشكلة في هذه الطريقة؟ ليس حقا. دعنا نلقي نظرة سريعة على الأشكال:

```py
predictions.shape, labels.shape
```

```python out
((8, 3), (8,))
```

تنبؤاتنا لا تزال logits، وليست التنبؤات الفعلية، وهذا هو السبب في عودة المقياس إلى هذا الخطأ (الغامض إلى حد ما). الحل بسيط للغاية؛ كل ما علينا فعله هو إضافة argmax في وظيفة `compute_metrics()`

```py
import numpy as np


def compute_metrics(eval_pred):
predictions, labels = eval_pred
predictions = np.argmax(predictions, axis=1)
return metric.compute(predictions=predictions, references=labels)


compute_metrics((predictions, labels))
```

```python out
{'accuracy': 0.625}
```

الآن تم إصلاح خطأنا! كان هذا الأخير، لذا فإن نصنا البرمجي سيقوم الآن بتدريب نموذج بشكل صحيح.

للإشارة، فيما يلي النص البرمجي المُصلح بالكامل:

```py
import numpy as np
from datasets import load_dataset
import evaluate
from transformers import (
AutoTokenizer,
AutoModelForSequenceClassification,
DataCollatorWithPadding,
TrainingArguments,
Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=3)

args = TrainingArguments(
f"distilbert-finetuned-mnli",
evaluation_strategy="epoch",
save_strategy="epoch",
learning_rate=2e-5,
num_train_epochs=3,
weight_decay=0.01,
)

metric = evaluate.load("glue", "mnli")


def compute_metrics(eval_pred):
predictions, labels = eval_pred
predictions = np.argmax(predictions, axis=1)
return metric.compute(predictions=predictions, references=labels)


data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
model,
args,
train_dataset=tokenized_datasets["train"],
eval_dataset=tokenized_datasets["validation_matched"],
compute_metrics=compute_metrics,
data_collator=data_collator,
tokenizer=tokenizer,
)
trainer.train()
```

في هذه الحالة، لا توجد مشكلات أخرى، وسينتج نصنا البرمجي نموذجًا من شأنه أن يقدم نتائج معقولة. ولكن ماذا يمكننا أن نفعل عندما يستمر التدريب دون أي خطأ، ولا يؤدي النموذج المدرب إلى أداء جيد على الإطلاق؟ هذا هو الجزء الأصعب من التعلم الآلي، وسنوضح لك بعض التقنيات التي يمكن أن تساعد.

<Tip>

💡 إذا كنت تستخدم حلقة تدريب يدوية، تنطبق الخطوات نفسها لتصحيح خط أنابيب التدريب الخاص بك، ولكن من الأسهل فصلها. تأكد من عدم نسيان `model.eval()` أو `model.train()` في الأماكن الصحيحة، أو `zero_grad()` في كل خطوة، ومع ذلك!

</Tip>

## تصحيح الأخطاء الصامتة أثناء التدريب

ماذا يمكننا أن نفعل لتصحيح التدريب الذي يكتمل دون خطأ ولكنه لا يحقق نتائج جيدة؟ سنقدم لك بعض المؤشرات هنا، ولكن كن على علم بأن هذا النوع من التصحيح هو الجزء الأصعب من التعلم الآلي، ولا يوجد إجابة سحرية.

### تحقق من بياناتك (مرة أخرى!)

لن يتعلم نموذجك شيئًا ما لم يكن من الممكن بالفعل تعلم أي شيء من بياناتك. إذا كان هناك خطأ يؤدي إلى تلف البيانات أو تم تعيين العلامات بشكل عشوائي، فمن المحتمل ألا تحصل على أي نموذج تدريب على مجموعة بياناتك. لذا، ابدأ دائمًا بالتحقق المزدوج من إدخالاتك وعلاماتك المشفرة، واسأل نفسك الأسئلة التالية:

- هل البيانات المشفرة مفهومة؟
- هل توافق على العلامات؟
- هل هناك علامة واحدة أكثر شيوعًا من العلامات الأخرى؟
- ما هي الخسارة/المقاييس التي يجب أن تكون إذا تنبأ النموذج بإجابة عشوائية/نفس الإجابة دائمًا؟

<Tip warning={true}>

⚠️ إذا كنت تقوم بالتدريب الموزع، فقم بطباعة عينات من مجموعة بياناتك في كل عملية وتحقق ثلاث مرات من حصولك على نفس الشيء. أحد الأخطاء الشائعة هو وجود مصدر للاحتمالية في إنشاء البيانات يجعل كل عملية تحتوي على إصدار مختلف من مجموعة البيانات.

</Tip>

بعد النظر في بياناتك، انتقل خلال بعض تنبؤات نموذجك وقم بفك تشفيرها أيضًا. إذا كان النموذج يتوقع دائمًا نفس الشيء، فقد يكون ذلك لأن مجموعة بياناتك متحيزة نحو فئة واحدة (لمشكلات التصنيف)؛ قد تساعد التقنيات مثل الإفراط في أخذ عينات الفئات النادرة.

إذا كانت الخسارة/المقاييس التي تحصل عليها في نموذجك الأولي مختلفة كثيرًا عن الخسارة/المقاييس التي تتوقعها للتنبؤات العشوائية، فتحقق من طريقة حساب خسارتك أو مقياسك، حيث من المحتمل أن يكون هناك خطأ هناك. إذا كنت تستخدم عدة خسائر تضيفها في النهاية، فتأكد من أنها بنفس الحجم.

عندما تكون متأكدًا من أن بياناتك مثالية، يمكنك معرفة ما إذا كان النموذج قادرًا على التدريب عليها باختبار بسيط واحد.

### اجعل نموذجك يناسب دفعة واحدة

عادة ما نحاول تجنب الإفراط في الملاءمة أثناء التدريب، لأنه يعني أن النموذج لا يتعلم التعرف على الميزات العامة التي نريد منه ذلك، ولكنه بدلاً من ذلك يقوم فقط بحفظ عينات التدريب. ومع ذلك، فإن محاولة تدريب نموذجك على دفعة واحدة مرارًا وتكرارًا هي اختبار جيد للتحقق مما إذا كانت المشكلة كما حددتها يمكن حلها بواسطة النموذج الذي تحاول تدريبه. كما أنه سيساعدك على معرفة ما إذا كان معدل التعلم الأولي مرتفعًا جدًا.

إن القيام بذلك بمجرد تحديد `Trainer` الخاص بك أمر سهل للغاية؛ ما عليك سوى الحصول على دفعة من بيانات التدريب، ثم قم بتشغيل حلقة تدريب يدوية صغيرة باستخدام تلك الدفعة فقط لمدة 20 خطوة تقريبًا:

```py
for batch in trainer.get_train_dataloader():
break

batch = {k: v.to(device) for k, v in batch.items()}
trainer.create_optimizer()

for _ in range(20):
outputs = trainer.model(**batch)
loss = outputs.loss
loss.backward()
trainer.optimizer.step()
trainer.optimizer.zero_grad()
```

<Tip>

💡 إذا كانت بيانات التدريب غير متوازنة، فتأكد من إنشاء دفعة من بيانات التدريب تحتوي على جميع العلامات.

</Tip>

يجب أن يكون لدى النموذج الناتج نتائج مثالية تقريبًا على نفس `batch`. دعنا نحسب المقياس على التنبؤات الناتجة:

```py
with torch.no_grad():
outputs = trainer.model(**batch)
preds = outputs.logits
labels = batch["labels"]

compute_metrics((preds.cpu().numpy(), labels.cpu().numpy()))
```

```python out
{'accuracy': 1.0}
```

100% دقة، والآن هذا مثال جيد على الإفراط في الملاءمة (مما يعني أنه إذا قمت بتجربة نموذجك على أي جملة أخرى، فمن المحتمل أن يعطيك إجابة خاطئة)!

إذا لم تتمكن من جعل نموذجك يحقق نتائج مثالية مثل هذه، فهذا يعني أن هناك خطأ ما في طريقة صياغة المشكلة أو بياناتك، لذا يجب عليك إصلاح ذلك. فقط عندما تنجح في اجتياز اختبار الإفراط في الملاءمة يمكنك التأكد من أن نموذجك يمكنه بالفعل تعلم شيء ما.

<Tip warning={true}>

⚠️ سيتعين عليك إعادة إنشاء نموذجك و`Trainer` الخاص بك بعد هذا الاختبار، حيث من المحتمل ألا يتمكن النموذج الناتج من التعافي وتعلم شيء مفيد على مجموعة بياناتك الكاملة.

</Tip>

### لا تقم بالضبط حتى يكون لديك خط أساس أولي

يتم التأكيد دائمًا على ضبط فرط المعلمات باعتباره الجزء الأصعب من التعلم الآلي، ولكنه مجرد الخطوة الأخيرة لمساعدتك على تحقيق مكاسب طفيفة في المقياس. في معظم الوقت، تعمل فرط معلمات الافتراضية لـ `Trainer` بشكل جيد لإعطائك نتائج جيدة، لذا لا تطلق بحثًا مكثفًا ومكلفًا عن فرط المعلمات حتى يكون لديك شيء يتفوق على خط الأساس لديك في مجموعة بياناتك.

بمجرد حصولك على نموذج جيد بما فيه الكفاية، يمكنك البدء في التعديل قليلاً. لا تحاول إطلاق ألف عملية تشغيل بفرط معلمات مختلفة، ولكن قارن بين بضع عمليات تشغيل بفرط معلمات مختلفة لقيمة واحدة لفرط المعلمات للحصول على فكرة عن التأثير الأكبر.

إذا كنت تقوم بتعديل النموذج نفسه، فاحتفظ به بسيطًا ولا تحاول أي شيء لا يمكن تبريره بشكل معقول. تأكد دائمًا من العودة إلى اختبار الإفراط في الملاءمة للتحقق من أن تغييرك لم يكن له أي عواقب غير مقصودة.

### اطلب المساعدة

نأمل أن تكون قد وجدت بعض النصائح في هذا القسم والتي ساعدتك في حل مشكلتك، ولكن إذا لم يكن الأمر كذلك، فتذكر أنه يمكنك دائمًا طلب المساعدة من المجتمع في [المنتديات](https://discuss.huggingface.co/).

فيما يلي بعض الموارد الإضافية التي قد تكون مفيدة:

- ["قابلية إعادة الإنتاج كمركبة لأفضل الممارسات الهندسية"](https://docs.google.com/presentation/d/1yHLPvPhUs2KGI5ZWo0sU-PKU3GimAk3iTsI38Z-B5Gw/edit#slide=id.p) بقلم جويل جروس
- ["قائمة مراجعة لتصحيح أخطاء الشبكات العصبية"](https://towardsdatascience.com/checklist-for-debugging-neural-networks-d8b2a9434f21) بقلم سيسيليا شاو
- ["كيفية اختبار الوحدة لرمز التعلم الآلي"](https://medium.com/@keeper6928/how-to-unit-test-machine-learning-code-57cf6fd81765) بقلم تشيس روبرتس
- ["وصفة لتدريب الشبكات العصبية"](http://karpathy.github.io/2019/04/25/recipe/) بقلم أندريه كارباثي

بالطبع، ليست كل مشكلة تواجهها عند تدريب الشبكات العصبية خطأك! إذا صادفت شيئًا في مكتبة 🤗 Transformers أو 🤗 Datasets لا يبدو صحيحًا، فقد تكون واجهت خطأً. يجب عليك بالتأكيد إخبارنا بكل شيء عنه، وفي القسم التالي سنشرح بالضبط كيفية القيام بذلك.