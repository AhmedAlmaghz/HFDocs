# تصحيح خطأ أنبوب التدريب

لقد كتبت نصًا جميلًا لتدريب أو ضبط نموذج على مهمة معينة، مع اتباع النصيحة من [الفصل 7](/course/chapter7) بإخلاص. ولكن عند تشغيل الأمر `model.fit()`، يحدث شيء فظيع: تحصل على خطأ 😱! أو ما هو أسوأ، يبدو أن كل شيء على ما يرام، ويتم التدريب دون أي خطأ، ولكن النموذج الناتج سيء. في هذا القسم، سنريكم ما يمكنكم فعله لتصحيح هذه الأنواع من المشكلات.

## تصحيح خطأ أنبوب التدريب

إن المشكلة عند مواجهة خطأ في `model.fit()` هي أنه قد يأتي من مصادر متعددة، حيث أن التدريب عادة ما يجمع الكثير من الأشياء التي كنت تعمل عليها حتى تلك النقطة. قد تكون المشكلة خطأ ما في مجموعة البيانات الخاصة بك، أو بعض المشكلات عند محاولة دمج عناصر من مجموعات البيانات معًا. أو قد يكون هناك خطأ ما في كود النموذج، أو دالة الخسارة أو المحسن. وحتى إذا سار كل شيء على ما يرام أثناء التدريب، فقد يحدث خطأ ما أثناء التقييم إذا كانت هناك مشكلة في المقياس الخاص بك.

أفضل طريقة لتصحيح خطأ يحدث في `model.fit()` هي المرور يدويًا عبر هذا الأنبوب بأكمله لمعرفة أين حدث الخطأ. غالبًا ما يكون الخطأ سهل الحل للغاية.

ولإثبات ذلك، سنستخدم النص البرمجي التالي الذي (يحاول) ضبط نموذج DistilBERT على مجموعة بيانات [MNLI](https://huggingface.co/datasets/glue):

```py
from datasets import load_dataset
import evaluate
from transformers import (
AutoTokenizer,
TFAutoModelForSequenceClassification,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)

train_dataset = tokenized_datasets["train"].to_tf_dataset(
columns=["input_ids", "labels"], batch_size=16, shuffle=True
)

validation_dataset = tokenized_datasets["validation_matched"].to_tf_dataset(
columns=["input_ids", "labels"], batch_size=16, shuffle=True
)

model = TFAutoModelForSequenceClassification.from_pretrained(model_checkpoint)

model.compile(loss="sparse_categorical_crossentropy", optimizer="adam")

model.fit(train_dataset)
```

إذا حاولت تنفيذه، فقد تحصل على بعض التحذيرات `VisibleDeprecationWarning` أثناء تحويل مجموعة البيانات - هذه مشكلة معروفة في تجربة المستخدم لدينا، لذا يرجى تجاهلها. إذا كنت تقرأ الدورة التدريبية بعد، على سبيل المثال، نوفمبر 2021 ولا يزال يحدث ذلك، قم بإرسال تغريدات غاضبة إلى @carrigmat حتى يقوم بإصلاحها.

ومع ذلك، فإن المشكلة الأكثر خطورة هي أننا نحصل على خطأ صريح. وهو طويل جدًا ومخيف:

```python out
ValueError: No gradients provided for any variable: ['tf_distil_bert_for_sequence_classification/distilbert/embeddings/word_embeddings/weight:0', '...']
```

ماذا يعني ذلك؟ لقد حاولنا التدريب على بياناتنا، لكننا لم نحصل على تدرج؟ هذا محير للغاية؛ كيف يمكننا حتى بدء تصحيح شيء من هذا القبيل؟ عندما لا يشير الخطأ الذي تحصل عليه على الفور إلى مكان وجود المشكلة، فإن الحل الأفضل غالبًا هو المرور عبر الأشياء بترتيب تسلسلي، والتأكد في كل مرحلة من أن كل شيء يبدو صحيحًا. وبالطبع، فإن المكان الذي يجب البدء منه هو دائمًا...

### التحقق من بياناتك

هذا أمر بديهي، ولكن إذا كانت بياناتك تالفة، فلن يتمكن Keras من إصلاحها لك. لذا، يجب عليك أولاً التحقق مما هو موجود في مجموعة التدريب الخاصة بك.

على الرغم من أن من المغري النظر داخل `raw_datasets` و`tokenized_datasets`، إلا أننا نوصي بشدة بالذهاب إلى البيانات مباشرة في النقطة التي ستدخل فيها إلى النموذج. وهذا يعني قراءة إخراج من `tf.data.Dataset` الذي أنشأته باستخدام الدالة `to_tf_dataset()`! إذن، كيف نفعل ذلك؟ تمنحنا كائنات `tf.data.Dataset` دفعات كاملة في كل مرة ولا تدعم الفهرسة، لذا لا يمكننا فقط طلب `train_dataset[0]`. ومع ذلك، يمكننا أن نطلب منه بلطف دفعة:

```py
for batch in train_dataset:
break
```

ينهي `break` الحلقة بعد تكرار واحد، لذا فإن هذا يلتقط الدفعة الأولى التي تخرج من `train_dataset` ويحفظها كدفعة. الآن، دعونا نلقي نظرة على ما بداخلها:

```python out
{'attention_mask': <tf.Tensor: shape=(16, 76), dtype=int64, numpy=
array([[1, 1, 1, ..., 0, 0, 0],
[1, 1, 1, ..., 0, 0, 0],
[1, 1, 1, ..., 0, 0, 0],
...,
[1, 1, 1, ..., 1, 1, 1],
[1, 1, 1, ..., 0, 0, 0],
[1, 1, 1, ..., 0, 0, 0]])>,
'label': <tf.Tensor: shape=(16,), dtype=int64, numpy=array([0, 2, 1, 2, 1, 1, 2, 0, 0, 0, 1, 0, 1, 2, 2, 1])>,
'input_ids': <tf.Tensor: shape=(16, 76), dtype=int64, numpy=
array([[ 101, 2174, 1010, ...,    0,    0,    0],
[ 101, 3174, 2420, ...,    0,    0,    0],
[ 101, 2044, 2048, ...,    0,    0,    0],
...,
[ 101, 3398, 3398, ..., 2051, 2894,  102],
[ 101, 1996, 4124, ...,    0,    0,    0],
[ 101, 1999, 2070, ...,    0,    0,    0]])>}
```

يبدو هذا صحيحًا، أليس كذلك؟ نحن نقوم بتمرير `labels` و`attention_mask` و`input_ids` إلى النموذج، والتي يجب أن تكون كل ما يحتاجه لحساب المخرجات وحساب الخسارة. إذن لماذا لا يوجد لدينا تدرج؟ انظر عن كثب: نحن نقوم بتمرير قاموس واحد كإدخال، ولكن دفعة التدريب عادة ما تكون عبارة عن إدخال قاموس أو مصفوفة، بالإضافة إلى مصفوفة تسميات. تسمياتنا هي مجرد مفتاح في قاموس الإدخال الخاص بنا.

هل هذه مشكلة؟ في الواقع، ليست دائمًا! ولكنها واحدة من أكثر المشكلات شيوعًا التي ستواجهها عند تدريب نماذج المحول باستخدام TensorFlow. يمكن لجميع نماذجنا حساب الخسارة داخليًا، ولكن للقيام بذلك، يجب تمرير التسميات في قاموس الإدخال. هذه هي الخسارة التي يتم استخدامها عندما لا نقوم بتحديد قيمة الخسارة إلى `compile()`. من ناحية أخرى، يتوقع Keras عادةً تمرير التسميات بشكل منفصل عن قاموس الإدخال، وستفشل حسابات الخسارة عادةً إذا لم تقم بذلك.

أصبحت المشكلة الآن أكثر وضوحًا: لقد مررنا بحجة `loss`، مما يعني أننا نطلب من Keras حساب الخسائر نيابة عنا، ولكننا مررنا التسميات كإدخالات إلى النموذج، وليس كتسميات في المكان الذي يتوقعها Keras! نحن بحاجة إلى اختيار أحدهما: إما أن نستخدم الخسارة الداخلية للنموذج ونبقي التسميات حيث هي، أو نواصل استخدام خسائر Keras، ولكن نقوم بنقل التسميات إلى المكان الذي يتوقعها فيه Keras. من أجل البساطة، دعنا نأخذ النهج الأول. قم بتغيير مكالمة `compile()` لتصبح:

```py
model.compile(optimizer="adam")
```

الآن سنستخدم الخسارة الداخلية للنموذج، وينبغي حل هذه المشكلة!

<Tip>

✏️ **جرب بنفسك!** كتحدٍ اختياري بعد حل المشكلات الأخرى، يمكنك أن تحاول العودة إلى هذه الخطوة وجعل النموذج يعمل مع الخسارة الأصلية التي تم حسابها بواسطة Keras بدلاً من الخسارة الداخلية. ستحتاج إلى إضافة `"labels"` إلى وسيط `label_cols` في الدالة `to_tf_dataset()` للتأكد من إخراج التسميات بشكل صحيح، والذي سيمنحك تدرجات - ولكن هناك مشكلة أخرى مع الخسارة التي حددناها. سيستمر التدريب مع هذه المشكلة، ولكن التعلم سيكون بطيئًا جدًا وسيصل إلى مستوى مرتفع من الخسارة التدريبية. هل يمكنك معرفة ما هي؟

تلميح مشفر بـ ROT13، إذا كنت عالقًا: عندما تنظر إلى مخرجات `model.summary()` لنماذجنا، فإن أول مخرج لها هو `inputs`. ما هي المدخلات؟ وعندما تتعامل مع المصفوفات أو المصفوفات أو المصفوفات ذات الأبعاد، فإن TensorFlow يتوقع أن تكون الأبعاد الأولى هي الدفعة. ما هي أبعاد دفعاتنا؟

</Tip>

الآن، دعونا نحاول التدريب. يجب أن نحصل على تدرجات الآن، لذا نأمل (يتم تشغيل الموسيقى المقلقة هنا) أن نتمكن فقط من استدعاء `model.fit()` وأن كل شيء سيعمل بشكل جيد!

```python out
246/24543 [..............................] - ETA: 15:52 - loss: nan
```

يا إلهي.

ليست قيمة `nan` مشجعة للغاية لقيمة الخسارة. ومع ذلك، فقد تحققنا من بياناتنا، ويبدو أنها جيدة. إذا لم تكن هذه هي المشكلة، فأين يمكننا أن نذهب بعد ذلك؟ الخطوة التالية الواضحة هي...
### التحقق من النموذج الخاص بك

`model.fit()` هي دالة ملائمة حقًا في Keras، ولكنها تقوم بالكثير من الأشياء نيابة عنك، مما قد يجعل من الصعب العثور على المكان الذي حدثت فيه مشكلة ما بالضبط. إذا كنت تقوم بتصحيح أخطاء نموذجك، فإن إحدى الاستراتيجيات التي يمكن أن تساعد حقًا هي تمرير دفعة واحدة فقط إلى النموذج، والنظر في المخرجات لهذه الدفعة الواحدة بالتفصيل. ونصيحة أخرى مفيدة حقًا إذا كان النموذج يرمي أخطاء هي تجميع النموذج مع `run_eagerly=True`. سيجعله هذا أبطأ بكثير، ولكنه سيجعل رسائل الخطأ أكثر قابلية للفهم، لأنها ستشير بالضبط إلى المكان الذي حدث فيه الخطأ في كود النموذج الخاص بك.

ولكن، في الوقت الحالي، لا نحتاج إلى `run_eagerly` بعد. دعونا نقوم بتشغيل الدفعة التي حصلنا عليها سابقًا عبر النموذج ونرى كيف تبدو المخرجات:

```py
model(batch)
```

```python out
TFSequenceClassifierOutput(loss=<tf.Tensor: shape=(16,), dtype=float32, numpy=
array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
nan, nan, nan], dtype=float32)>, logits=<tf.Tensor: shape=(16, 2), dtype=float32, numpy=
array([[nan, nan],
[nan, nan],
[nan, nan],
[nan, nan],
[nan, nan],
[nan, nan],
[nan, nan],
[nan, nan],
[nan, nan],
[nan, nan],
[nan, nan],
[nan, nan],
[nan, nan],
[nan, nan],
[nan, nan],
[nan, nan]], dtype=float32)>, hidden_states=None, attentions=None)
```

حسنًا، هذا محير. كل شيء هو `nan`! لكن أليس هذا غريبًا؟ كيف أصبحت جميع احتمالاتنا `nan`؟ تعني `nan` "ليس رقمًا". وغالبًا ما تحدث قيم `nan` عند إجراء عملية محظورة، مثل القسمة على صفر. ولكن هناك أمر مهم جدًا يجب معرفته حول `nan` في التعلم الآلي وهو أن هذه القيمة تميل إلى الانتشار. إذا قمت بضرب رقم في `nan`، فإن الإخراج هو أيضًا `nan`. وإذا حصلت على `nan` في أي مكان في إخراجك، أو في خسارتك، أو تدرجك، فسيتم نشره بسرعة في جميع أنحاء نموذجك بالكامل - لأنه عندما يتم نشر قيمة `nan` هذه مرة أخرى عبر شبكتك، فستحصل على تدرجات `nan`، وعندما يتم حساب تحديثات الأوزان باستخدام هذه التدرجات، فستحصل على أوزان `nan`، وستحسب هذه الأوزان المزيد من المخرجات `nan`! وفي وقت قريب، ستصبح الشبكة بالكامل مجرد كتلة كبيرة من `nan`s. وبمجرد حدوث ذلك، يصبح من الصعب جدًا معرفة المكان الذي بدأت منه المشكلة. كيف يمكننا عزل المكان الذي تسلل فيه `nan` لأول مرة؟

الإجابة هي محاولة *إعادة تهيئة* نموذجنا. بمجرد أن بدأنا التدريب، حصلنا على `nan` في مكان ما وانتشر بسرعة في جميع أنحاء النموذج. لذا، دعونا نقوم بتحميل النموذج من نقطة تفتيش ولا نقوم بأي تحديثات للأوزان، ونرى أين نحصل على قيمة `nan`:

```py
model = TFAutoModelForSequenceClassification.from_pretrained(model_checkpoint)
model(batch)
```

عندما نقوم بتشغيل ذلك، نحصل على:

```py out
TFSequenceClassifierOutput(loss=<tf.Tensor: shape=(16,), dtype=float32, numpy=
array([0.6844486 ,        nan,        nan, 0.67127866, 0.7068601 ,
nan, 0.69309855,        nan, 0.65531296,        nan,
nan,        nan, 0.675402  ,        nan,        nan,
0.69831556], dtype=float32)>, logits=<tf.Tensor: shape=(16, 2), dtype=float32, numpy=
array([[-0.04761693, -0.06509043],
[-0.0481936 , -0.04556257],
[-0.0040929 , -0.05848458],
[-0.02417453, -0.0684005 ],
[-0.02517801, -0.05241832],
[-0.04514256, -0.0757378 ],
[-0.02656011, -0.02646275],
[ 0.00766164, -0.04350497],
[ 0.02060014, -0.05655622],
[-0.02615328, -0.0447021 ],
[-0.05119278, -0.06928903],
[-0.02859691, -0.04879177],
[-0.02210129, -0.05791225],
[-0.02363213, -0.05962167],
[-0.05352269, -0.0481673 ],
[-0.08141848, -0.07110836]], dtype=float32)>, hidden_states=None, attentions=None)
```

الآن نحن نحصل على مكان ما! لا توجد قيم `nan` في احتمالاتنا، وهو أمر مطمئن. ولكننا نرى بعض قيم `nan` في خسارتنا! هل هناك شيء ما حول هذه العينات بالذات يسبب هذه المشكلة؟ دعونا نرى ما هي (يرجى ملاحظة أنه إذا قمت بتشغيل هذا الكود بنفسك، فقد تحصل على مؤشرات مختلفة لأن مجموعة البيانات تم خلطها):

```python
import numpy as np

loss = model(batch).loss.numpy()
indices = np.flatnonzero(np.isnan(loss))
indices
```

```python out
array([ 1,  2,  5,  7,  9, 10, 11, 13, 14])
```

دعونا نلقي نظرة على العينات التي جاءت منها هذه المؤشرات:

```python
input_ids = batch["input_ids"].numpy()
input_ids[indices]
```

```python out
array([[  101,  2007,  2032,  2001,  1037, 16480,  3917,  2594,  4135,
23212,  3070,  2214, 10170,  1010,  2012,  4356,  1997,  3183,
6838, 12953,  2039,  2000,  1996,  6147,  1997,  2010,  2606,
1012,   102,  6838,  2001,  3294,  6625,  3773,  1996,  2214,
2158,  1012,   102,     0,     0,     0,     0,     0,     0,
0,     0,     0,     0,     0,     0,     0,     0,     0,
0,     0,     0,     0,     0,     0,     0,     0,     0,
0,     0,     0,     0,     0,     0,     0,     0,     0,
0,     0,     0,     0],
[  101,  1998,  6814,  2016,  2234,  2461,  2153,  1998, 13322,
2009,  1012,   102,  2045,  1005,  1055,  2053,  3382,  2008,
2016,  1005,  2222,  3046,  8103,  2075,  2009,  2153,  1012,
102,     0,     0,     0,     0,     0,     0,     0,     0,
0,     0,     0,     0,     0,     0,     0,     0,     0,
0,     0,     0,     0,     0,     0,     0,     0,     0,
0,     0,     0,     0,     0,     0,     0,     0,     0,
0,     0,     0,     0,     0,     0,     0,     0,     0,
0,     0,     0,     0,     0,     0,     0,     0,     0,
0,     0,     0,     0],
[  101,  1998,  2007,  1996,  3712,  4634,  1010,  2057,  8108,
2025,  3404,  2028,  1012,  1996,  2616, 18449,  2125,  1999,
1037,  9666,  1997,  4100,  8663, 11020,  6313,  2791,  1998,
2431,  1011,  4301,  1012,   102,  2028,  1005,  1055,  5177,
2110,  1998,  3977,  2000,  2832,  2106,  2025,  2689,  2104,
2122,  6214,  1012,   102,     0,     0,     0,     0,     0,
0,     0,      بسيطة،     0،     0،     0،     0،     0،     0،
0،     0،     0،     0،     0،     0،     0،     0،     0،
0،     0،     0،     0،     0،     0،     0،     0،     0،
0،     0،     0،     0،     0،     0،     0،     0،     0،
0،     0،     0،     0،     0،     0،     0،     0،     0،
0،     0،     0،     0],
[  101,  1045,  2001,  1999,  1037, 13090,  5948,  2007,  2048,
2308,  2006,  2026,  5001,  2043,  2026,  2171,  2001,  2170,
1012,   102,  1045,  2001,  3564,  1999,  2277,  1012,   102,
0,     0,     0,     0,     0,     0,     0,     0,     0,
0,     0,     0,     0,     0,     0,     0,     0,     0,
0,     0,     0,     0,     0,     0,     0,     0,     0,
0,     0,     0,     0,     0,     0,     0,     0,     0,
0,     0,     0,     0,     0,     0,     0,     0,     0,
0,     0,     0,     0,     0,     0,     0,     0,     0,
0,     0,     0,     0،     0،     0،     0،     0،     0،
0،     0،     0،     0،     0،     0،     0،     0،     0،
0،     0،     0،     0،     0،     0،     0،     0،     0،
0،     0،     0،     0],
[  101,  2195,  4279,  2191,  2039,  1996,  2181,  2124,  2004,
1996,  2225,  7363,  1012,   102,  2045,  2003,  2069,  2028,
2451,  1999,  1996,  2225,  7363,  1012,   102,     0,     0,
0,     0,     0,     0,     0,     0,     0,     0,     0,
0,     0,     0,     0,     0,     0,     0,     0,     0,
0,     0,     0,     0,     0,     0,     0,     0,     0,
0,     0,     0,     0,     0,     0,     0,     0,     0,
0,     0,     0,     0,     0,     0,     0,     0,     0,
0,     0,     0,     0,     0,     0,     0,     0,     0,
0,     0,     0,     0،     0،     0،     0،     0،     0،
0،     0،     0،     0،     0،     0،     0،     0،     0،
0،     0،     0،     0،     0،     0،     0،     0،     0،
0،     0،     0،     0],
[  101,  2061,  2008,  1045,  2123,  1005,  1056,  2113,  2065,
2009,  2428, 10654,  7347,  2030,  2009,  7126,  2256,  2495,
2291,   102,  2009,  2003,  5094,  2256,  2495,  2291,  2035,
2105,  1012,   102,     0,     0,     0,     0,     0,     0,
0,     0,     0,     0,     0,     0,     0,     0,     0,
0,     0,     0,     0,     0,     0,     0,     0,     0,
0,     0,     0,     0,     0,     0,     0,     0,     0,
0,     0
## تحقق من فرط المعاملات الخاصة بك

إذا عدت إلى الكود أعلاه، فقد لا تتمكن من رؤية أي فرط معلمات على الإطلاق، باستثناء ربما `batch_size`، وهذا لا يبدو أنه الجاني المحتمل. لا تنخدع، رغم ذلك؛ هناك دائمًا فرط معلمات، وإذا لم تتمكن من رؤيتها، فهذا يعني ببساطة أنك لا تعرف ما هي مضبوطة عليه. على وجه الخصوص، تذكر شيئًا بالغ الأهمية حول Keras: إذا قمت بضبط خسارة أو محسن أو دالة تنشيط باستخدام سلسلة، فسيتم ضبط جميع حججها على قيمها الافتراضية. وهذا يعني أنه على الرغم من أن استخدام السلاسل لهذا الأمر مريح للغاية، إلا أنه يجب عليك توخي الحذر الشديد عند القيام بذلك، حيث يمكنه بسهولة إخفاء أشياء بالغة الأهمية عنك. (يجب على أي شخص يحاول التحدي الاختياري أعلاه أن يأخذ بعين الاعتبار هذه الحقيقة.)

في هذه الحالة، أين قمنا بتعيين حجة باستخدام سلسلة؟ كنا نحدد الخسارة باستخدام سلسلة في البداية، لكننا لم نعد نفعل ذلك. ومع ذلك، فإننا نقوم بتعيين المحسن باستخدام سلسلة. هل يمكن أن يخفي ذلك أي شيء عنا؟ دعنا نلقي نظرة على [حججه](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam).

هل هناك أي شيء بارز هنا؟ هذا صحيح - معدل التعلم! عندما نستخدم فقط السلسلة "adam"، سنحصل على معدل التعلم الافتراضي، والذي يبلغ 0.001، أو 1e-3. هذا مرتفع للغاية بالنسبة لنموذج المحول! بشكل عام، نوصي بتجربة معدلات التعلم بين 1e-5 و 1e-4 لنماذجك؛ هذا ما بين 10X و 100X أصغر من القيمة التي نستخدمها بالفعل هنا. يبدو أن هذا قد يكون مشكلة رئيسية، لذا دعنا نحاول تقليله. للقيام بذلك، نحتاج إلى استيراد كائن "المحسن" الفعلي. وبينما نحن في ذلك، دعنا نقوم بإعادة تهيئة النموذج من نقطة التفتيش، في حالة إتلاف الأوزان بسبب التدريب بمعدل تعلم مرتفع:

```python
from tensorflow.keras.optimizers import Adam

model = TFAutoModelForSequenceClassification.from_pretrained(model_checkpoint)
model.compile(optimizer=Adam(5e-5))
```

<Tip>

💡 يمكنك أيضًا استيراد دالة `create_optimizer()` من 🤗 Transformers، والتي ستمنحك محسن AdamW مع انخفاض الوزن الصحيح بالإضافة إلى الاحماء والانخفاض في معدل التعلم. غالبًا ما ينتج هذا المحسن نتائج أفضل قليلاً من تلك التي تحصل عليها مع محسن Adam الافتراضي.

</Tip>

الآن، يمكننا محاولة تثبيت النموذج بمعدل التعلم الجديد المحسن:

```python
model.fit(train_dataset)
```

```python out
319/24543 [..............................] - ETA: 16:07 - loss: 0.9718
```

الآن، تذهب خسارتنا حقًا إلى مكان ما! يبدو التدريب أخيرًا كما لو كان يعمل. هناك درس هنا: عندما يعمل نموذجك ولكن الخسارة لا تنخفض، وأنت متأكد من أن بياناتك تعمل بشكل صحيح، فمن الجيد التحقق من فرط المعلمات مثل معدل التعلم وانخفاض الوزن. من المحتمل جدًا أن يتسبب تعيين أي منهما مرتفعًا جدًا في "توقف" التدريب عند قيمة خسارة مرتفعة.

## قضايا محتملة أخرى

لقد غطينا القضايا في البرنامج النصي أعلاه، ولكن هناك العديد من الأخطاء الشائعة الأخرى التي قد تواجهها. دعنا نلقي نظرة على قائمة (غير مكتملة للغاية).

### التعامل مع أخطاء نفاد الذاكرة

العلامة المميزة لنفاد الذاكرة هي خطأ مثل "OOM عند تخصيص tensor" - OOM اختصار لـ "نفاد الذاكرة". هذا خطر شائع جدًا عند التعامل مع نماذج اللغة الكبيرة. إذا واجهت هذا، فإن إحدى الاستراتيجيات الجيدة هي تقليل حجم دفعتك إلى النصف ومحاولة مرة أخرى. ضع في اعتبارك، مع ذلك، أن بعض النماذج *كبيرة جدًا*. على سبيل المثال، يحتوي GPT-2 بالحجم الكامل على 1.5 مليار معلمة، مما يعني أنك ستحتاج إلى 6 جيجابايت من الذاكرة لتخزين النموذج فقط، و 6 جيجابايت أخرى لمشتقاته! سيتطلب تدريب نموذج GPT-2 الكامل عادةً أكثر من 20 جيجابايت من VRAM بغض النظر عن حجم الدفعة التي تستخدمها، والتي لا يمتلكها سوى عدد قليل من وحدات معالجة الرسومات. النماذج الأكثر خفة مثل `distilbert-base-cased` أسهل في التشغيل، كما أنها تتدرب بشكل أسرع بكثير.

<Tip>

في الجزء التالي من الدورة التدريبية، سنلقي نظرة على تقنيات أكثر تقدمًا يمكن أن تساعدك في تقليل بصمة ذاكرتك والسماح لك بضبط أدق النماذج.

</Tip>

### جائع جائع TensorFlow 🦛

من الغرائب الخاصة بـ TensorFlow التي يجب أن تكون على دراية بها هي أنها تخصص *كل* ذاكرة GPU الخاصة بك لنفسها بمجرد تحميل نموذج أو إجراء أي تدريب، ثم تقسم تلك الذاكرة حسب الاقتضاء. هذا مختلف عن سلوك الأطر الأخرى، مثل PyTorch، والتي تخصص الذاكرة حسب الاقتضاء باستخدام CUDA بدلاً من القيام بذلك داخليًا. إحدى مزايا نهج TensorFlow هي أنه يمكنه غالبًا إعطاء أخطاء مفيدة عندما تنفد الذاكرة، ويمكنه التعافي من تلك الحالة دون تحطم نواة CUDA بالكامل. لكن هناك أيضًا عيب مهم: إذا قمت بتشغيل عمليتي TensorFlow في نفس الوقت، فستكون **ستعاني من وقت عصيب**.

إذا كنت تعمل على Colab، فلا داعي للقلق بشأن ذلك، ولكن إذا كنت تعمل محليًا، فهذا شيء يجب أن تكون حذرًا بشأنه. على وجه الخصوص، كن على دراية بأن إغلاق علامة تبويب الدفتر لا يؤدي بالضرورة إلى إيقاف تشغيل هذا الدفتر! قد تحتاج إلى تحديد دفاتر الملاحظات قيد التشغيل (التي بها أيقونة خضراء) وإيقاف تشغيلها يدويًا في قائمة الدليل. قد يستمر أي دفتر ملاحظات قيد التشغيل كان يستخدم TensorFlow في الاحتفاظ بجزء كبير من ذاكرة GPU الخاصة بك، مما يعني أن أي دفتر ملاحظات جديد تبدأه قد يواجه بعض المشكلات الغريبة جدًا.

إذا بدأت في الحصول على أخطاء حول CUDA أو BLAS أو cuBLAS في الكود الذي كان يعمل من قبل، فهذا غالبًا ما يكون الجاني. يمكنك استخدام أمر مثل `nvidia-smi` للتحقق - عندما تقوم بإيقاف تشغيل دفتر الملاحظات الحالي أو إعادة تشغيله، هل معظم ذاكرتك حرة، أم أنها لا تزال قيد الاستخدام؟ إذا كان لا يزال قيد الاستخدام، فهناك شيء آخر يحتفظ به!

### تحقق من بياناتك (مرة أخرى!)

لن يتعلم نموذجك شيئًا إلا إذا كان من الممكن بالفعل تعلم أي شيء من بياناتك. إذا كان هناك خطأ يؤدي إلى تلف البيانات أو تم تعيين العلامات بشكل عشوائي، فمن المحتمل ألا تحصل على أي نموذج تدريب على مجموعة البيانات الخاصة بك. تعد `tokenizer.decode()` أداة مفيدة هنا. سيحول هذا `input_ids` مرة أخرى إلى سلاسل، حتى تتمكن من عرض البيانات ومعرفة ما إذا كانت بيانات التدريب الخاصة بك تعلم ما تريد أن تعلمه. على سبيل المثال، بعد الحصول على `batch` من `tf.data.Dataset` مثلما فعلنا أعلاه، يمكنك فك ترميز العنصر الأول على النحو التالي:

```py
input_ids = batch["input_ids"].numpy()
tokenizer.decode(input_ids[0])
```

بعد ذلك، يمكنك مقارنته بالعلامة الأولى، كما يلي:

```py
labels = batch["labels"].numpy()
label = labels[0]
```

بمجرد أن تتمكن من عرض بياناتك بهذه الطريقة، يمكنك طرح الأسئلة التالية:

- هل البيانات فك تشفيرها مفهومة؟
- هل توافق على العلامات؟
- هل هناك علامة واحدة أكثر شيوعًا من العلامات الأخرى؟
- ما هي الخسارة / المقياس إذا تنبأ النموذج بإجابة عشوائية / نفس الإجابة دائمًا؟

بعد النظر في بياناتك، قم بالتمرير خلال بعض تنبؤات النموذج - إذا كان نموذجك ينتج رموزًا، فحاول فك تشفيرها أيضًا! إذا كان النموذج يتوقع دائمًا نفس الشيء، فقد يكون ذلك لأن مجموعة البيانات الخاصة بك متحيزة نحو فئة واحدة (لمشكلات التصنيف)، لذا فإن تقنيات مثل الإفراط في أخذ عينات الفئات النادرة قد تساعد. من ناحية أخرى، يمكن أن يكون هذا أيضًا بسبب مشكلات التدريب مثل إعدادات فرط المعلمات السيئة.

إذا كانت الخسارة / المقياس الذي تحصل عليه في نموذجك الأولي قبل أي تدريب مختلفًا جدًا عن الخسارة / المقياس الذي تتوقعه للتنبؤات العشوائية، فتحقق من طريقة حساب خسارتك أو مقياسك، حيث من المحتمل أن يكون هناك خطأ هناك. إذا كنت تستخدم عدة خسائر تضيفها في النهاية، فتأكد من أنها بنفس الحجم.

عندما تكون متأكدًا من أن بياناتك مثالية، فيمكنك معرفة ما إذا كان النموذج قادرًا على التدريب عليها باختبار بسيط واحد.

### قم بإفراط في ملاءمة نموذجك على دفعة واحدة

غالبًا ما نحاول تجنب الإفراط في الملاءمة أثناء التدريب، حيث يعني ذلك أن النموذج لا يتعلم التعرف على الميزات العامة التي نريد منه ذلك، ولكنه بدلاً من ذلك يقوم فقط بحفظ عينات التدريب. ومع ذلك، فإن محاولة تدريب نموذجك على دفعة واحدة مرارًا وتكرارًا هي اختبار جيد للتحقق مما إذا كانت المشكلة كما قمت بصياغتها يمكن حلها بواسطة النموذج الذي تحاول تدريبه. كما سيساعدك ذلك على معرفة ما إذا كان معدل التعلم الأولي مرتفعًا جدًا.

إن القيام بذلك بعد أن قمت بتعريف نموذجك أمر سهل للغاية؛ ما عليك سوى الحصول على دفعة من بيانات التدريب، ثم التعامل مع تلك الدفعة على أنها مجموعة البيانات بأكملها، والتدريب عليها لعدد كبير من العصور:

```py
for batch in train_dataset:
break

# تأكد من تشغيل model.compile() وتعيين محسنك،
# وخسارتك / مقاييسك إذا كنت تستخدمها

model.fit(batch، epochs=20)
```

<Tip>

💡 إذا كانت بيانات التدريب غير متوازنة، فتأكد من إنشاء دفعة من بيانات التدريب تحتوي على جميع العلامات.

</Tip>

يجب أن يكون لدى النموذج الناتج نتائج قريبة من الكمال على الدفعة، مع انخفاض الخسارة بسرعة نحو 0 (أو القيمة الدنيا للخسارة التي تستخدمها).

إذا لم تتمكن من تحقيق نتائج مثالية مثل هذه باستخدام نموذجك، فهذا يعني أن هناك خطأ ما في طريقة صياغة المشكلة أو بياناتك، لذا يجب عليك إصلاح ذلك. فقط عندما تنجح في اجتياز اختبار الإفراط في الملاءمة يمكنك التأكد من أن نموذجك قادر بالفعل على التعلم.

<Tip warning={true}>

⚠️ سيتعين عليك إعادة إنشاء نموذجك وإعادة تجميعه بعد اختبار الإفراط في الملاءمة هذا، حيث من المحتمل ألا يتمكن النموذج الذي تم الحصول عليه من التعافي والتعلم من شيء مفيد على مجموعة البيانات الكاملة الخاصة بك.

</Tip>

### لا تضبط أي شيء حتى تحصل على خط الأساس الأول

يتم التأكيد دائمًا على أن الضبط الدقيق لفرط المعلمات هو الجزء الأصعب في التعلم الآلي، ولكنه مجرد الخطوة الأخيرة لمساعدتك في الحصول على القليل من المقياس. بالطبع، فإن القيم السيئة للغاية لفرط معلماتك، مثل استخدام معدل التعلم الافتراضي لـ Adam البالغ 1e-3 مع نموذج المحول، ستجعل التعلم بطيئًا جدًا أو يتوقف تمامًا، ولكن في معظم الوقت تعمل فرط المعلمات "المعقولة"، مثل معدل التعلم من 1e-5 إلى 5e-5، بشكل جيد لمنحك نتائج جيدة. لذا، لا تطلق بحثًا مكثفًا عن فرط المعلمات حتى تحصل على شيء يتفوق على خط الأساس لديك في مجموعة البيانات الخاصة بك.

بمجرد حصولك على نموذج جيد بما فيه الكفاية، يمكنك البدء في التعديل قليلاً. لا تحاول إطلاق ألف عملية تشغيل بمعلمات مختلفة، ولكن قارن بين عدد قليل من العمليات التشغيلية بقيم مختلفة لمعلمة فرط واحدة لمعرفة أي منها له أكبر تأثير.

إذا كنت تقوم بتعديل النموذج نفسه، فاحتفظ به بسيطًا ولا تحاول أي شيء لا يمكن تبريره بشكل معقول. تأكد دائمًا من العودة إلى اختبار الإفراط في الملاءمة للتحقق من أن تغييرك لم يكن له أي عواقب غير مقصودة.

### اطلب المساعدة

نأمل أن تكون قد وجدت بعض النصائح في هذا القسم والتي ساعدتك في حل مشكلتك، ولكن إذا لم يكن الأمر كذلك، فتذكر أنه يمكنك دائمًا طلب المساعدة من المجتمع على [المنتديات](https://discuss.huggingface.co/).

فيما يلي بعض الموارد الإضافية التي قد تكون مفيدة:

- ["قابلية إعادة الإنتاج كوسيلة لممارسات الهندسة الفضلى"](https://docs.google.com/presentation/d/1yHLPvPhUs2KGI5ZWo0sU-PKU3GimAk3iTsI38Z-B5Gw/edit#slide=id.p) بقلم جويل جروس
- ["قائمة مراجعة لتصحيح أخطاء الشبكات العصبية"](https://towardsdatascience.com/checklist-for-debugging-neural-networks-d8b2a9434f21) بقلم سيسيليا شاو
- ["كيفية اختبار الوحدة لرمز التعلم الآلي"](https://medium.com/@keeper6928/how-to-unit-test-machine-learning-code-57cf6fd81765) بقلم تشيس روبرتس
- ["وصفة لتدريب الشبكات العصبية"](http://karpathy.github.io/2019/04/25/recipe/) بقلم أندريه كارباثي

بالطبع، ليست كل مشكلة تواجهها أثناء تدريب الشبكات العصبية خطأك! إذا واجهت شيئًا في مكتبة 🤗 Transformers أو 🤗 Datasets لا يبدو صحيحًا، فقد تكون واجهت خطأ. بالتأكيد يجب أن تخبرنا كل شيء عنه، وفي القسم التالي سنشرح بالضبط كيفية القيام بذلك.