# تدريب محدد رموز جديد من محدد رموز قديم

إذا لم يكن نموذج اللغة متاحًا باللغة التي تهمك، أو إذا كان نصك مختلفًا جدًا عن النص الذي تم تدريب نموذج اللغة عليه، فمن المحتمل أنك تريد إعادة تدريب النموذج من الصفر باستخدام محدد رموز مكيف على بياناتك. سيتطلب ذلك تدريب محدد رموز جديد على مجموعة بياناتك. ولكن ماذا يعني ذلك بالضبط؟ عندما نظرنا لأول مرة إلى محددات الرموز في [الفصل 2] (/course/chapter2)، رأينا أن معظم نماذج المحولات تستخدم _خوارزمية تحديد رموز فرعية_. لتحديد الرموز الفرعية ذات الأهمية والتي تحدث بشكل متكرر في النص المعني، يجب على محدد الرموز إلقاء نظرة فاحصة على جميع النصوص في النص - وهي عملية نسميها *التدريب*. تعتمد القواعد الدقيقة التي تحكم هذا التدريب على نوع محدد الرموز المستخدم، وسنتناول الخوارزميات الرئيسية الثلاثة لاحقًا في هذا الفصل.

<Tip warning={true}>
⚠️ تدريب محدد الرموز ليس مثل تدريب النموذج! يستخدم تدريب النموذج الانحدار التدريجي العشوائي لجعل الخسارة أصغر قليلاً لكل دفعة. إنه عشوائي بطبيعته (مما يعني أنه يتعين عليك تعيين بعض البذور للحصول على نفس النتائج عند إجراء التدريب نفسه مرتين). تدريب محدد الرموز هو عملية إحصائية تحاول تحديد أفضل الرموز الفرعية للاختيار لمجموعة معينة من النصوص، وتعتمد القواعد الدقيقة المستخدمة لاختيارها على خوارزمية تحديد الرموز. إنه حتمي، مما يعني أنك تحصل دائمًا على نفس النتائج عند التدريب باستخدام نفس الخوارزمية على نفس النص.
</Tip>

## تجميع نص كبير

هناك واجهة برمجة تطبيقات (API) بسيطة للغاية في 🤗 Transformers يمكنك استخدامها لتدريب محدد رموز جديد بنفس خصائص محدد رموز موجود: `AutoTokenizer.train_new_from_iterator()`. لمشاهدة ذلك في العمل، دعنا نقول أننا نريد تدريب GPT-2 من الصفر، ولكن بلغة أخرى غير اللغة الإنجليزية. ستكون مهمتنا الأولى هي جمع الكثير من البيانات بتلك اللغة في نص تدريبي. لتقديم أمثلة يمكن للجميع فهمها، لن نستخدم لغة مثل الروسية أو الصينية هنا، ولكن بدلاً من ذلك، لغة إنجليزية متخصصة: كود Python.

يمكن لمكتبة [🤗 Datasets](https://github.com/huggingface/datasets) مساعدتنا في تجميع نص من كود مصدر Python. سنستخدم الدالة المعتادة `load_dataset()` لتنزيل ذاكرة التخزين المؤقت لمجموعة البيانات [CodeSearchNet](https://huggingface.co/datasets/code_search_net). تم إنشاء هذه المجموعة للتحدي [CodeSearchNet](https://wandb.ai/github/CodeSearchNet/benchmark) وتحتوي على ملايين الوظائف من مكتبات المصادر المفتوحة على GitHub بعدة لغات برمجة. هنا، سنقوم بتحميل الجزء الخاص بـ Python من هذه المجموعة:

```py
from datasets import load_dataset

# قد يستغرق هذا الأمر بضع دقائق للتحميل، لذا احصل على فنجان من القهوة أو الشاي أثناء انتظارك!
raw_datasets = load_dataset("code_search_net", "python")
```

يمكننا إلقاء نظرة على التقسيم التدريبي لمعرفة الأعمدة التي يمكننا الوصول إليها:

```py
raw_datasets["train"]
```

```python out
Dataset({
features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language',
'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name',
'func_code_url'
],
num_rows: 412178
})
```

يمكننا أن نرى أن مجموعة البيانات تفصل الوثائق التوضيحية عن الكود وتقترح تحديد رموز لكليهما. هنا، سنستخدم عمود `whole_func_string` فقط لتدريب محدد الرموز الخاص بنا. يمكننا إلقاء نظرة على مثال عن إحدى هذه الوظائف عن طريق الفهرسة في التقسيم التدريبي:

```py
print(raw_datasets["train"][123456]["whole_func_string"])
```

الذي يجب أن يطبع ما يلي:

```out
def handle_simple_responses(
self, timeout_ms=None, info_cb=DEFAULT_MESSAGE_CALLBACK):
"""Accepts normal responses from the device.

Args:
timeout_ms: Timeout in milliseconds to wait for each response.
info_cb: Optional callback for text sent from the bootloader.

Returns:
OKAY packet's message.
"""
return self._accept_responses('OKAY', info_cb, timeout_ms=timeout_ms)
```

أول شيء يتعين علينا فعله هو تحويل مجموعة البيانات إلى _iterator_ من قوائم النصوص - على سبيل المثال، قائمة بقوائم النصوص. ستمكننا استخدام قوائم النصوص من جعل محدد الرموز أسرع (التدريب على دفعات من النصوص بدلاً من معالجة النصوص الفردية واحدًا تلو الآخر)، ويجب أن يكون iterator إذا أردنا تجنب وجود كل شيء في الذاكرة في نفس الوقت. إذا كانت مجموعة النصوص الخاصة بك ضخمة، فستحتاج إلى الاستفادة من حقيقة أن 🤗 Datasets لا يحمل كل شيء في ذاكرة الوصول العشوائي ولكنه يخزن عناصر مجموعة البيانات على القرص.

سيتطلب القيام بما يلي إنشاء قائمة بقوائم 1000 نص لكل منها، ولكنه سيحمل كل شيء في الذاكرة:

```py
# لا تقم بإلغاء التعليق عن السطر التالي ما لم تكن مجموعة البيانات الخاصة بك صغيرة!
# training_corpus = [raw_datasets["train"][i: i + 1000]["whole_func_string"] for i in range(0, len(raw_datasets["train"]), 1000)]
```

باستخدام مولد Python، يمكننا تجنب تحميل Python لأي شيء في الذاكرة حتى يكون ذلك ضروريًا. لإنشاء مثل هذا المولد، تحتاج فقط إلى استبدال الأقواس بالفواصل:

```py
training_corpus = (
raw_datasets["train"][i : i + 1000]["whole_func_string"]
for i in range(0, len(raw_datasets["train"]), 1000)
)
```

لا يقوم هذا السطر من التعليمات البرمجية باسترداد أي عناصر من مجموعة البيانات؛ فهو يقوم فقط بإنشاء كائن يمكنك استخدامه في حلقة Python `for`. لن يتم تحميل النصوص إلا عند الحاجة إليها (أي عند الوصول إلى الخطوة في حلقة `for` التي تتطلبها)، ولن يتم تحميل سوى 1000 نص في كل مرة. بهذه الطريقة، لن تستنفد كل ذاكرة الوصول العشوائي الخاصة بك حتى إذا كنت تقوم بمعالجة مجموعة بيانات ضخمة.

المشكلة مع كائن المولد هي أنه يمكن استخدامه مرة واحدة فقط. لذا، بدلاً من إعطائنا قائمة بأول 10 أرقام مرتين:

```py
gen = (i for i in range(10))
print(list(gen))
print(list(gen))
```

نحصل عليها مرة واحدة ثم قائمة فارغة:

```python out
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
[]
```

هذا هو السبب في أننا نحدد دالة تعيد مولدًا بدلاً من ذلك:

```py
def get_training_corpus():
return (
raw_datasets["train"][i : i + 1000]["whole_func_string"]
for i in range(0, len(raw_datasets["train"]), 1000)
)


training_corpus = get_training_corpus()
```

يمكنك أيضًا تحديد مولدك داخل حلقة `for` باستخدام عبارة `yield`:

```py
def get_training_corpus():
dataset = raw_datasets["train"]
for start_idx in range(0, len(dataset), 1000):
samples = dataset[start_idx : start_idx + 1000]
yield samples["whole_func_string"]
```

والذي سينتج نفس المولد كما هو الحال قبل، ولكنه يسمح لك باستخدام منطق أكثر تعقيدًا مما يمكنك في تعبير قائمة الفهم.

## تدريب محدد رموز جديد

الآن بعد أن أصبح لدينا نصنا في شكل iterator من دفعات النصوص، فنحن مستعدون لتدريب محدد رموز جديد. للقيام بذلك، نحتاج أولاً إلى تحميل محدد الرموز الذي نريد إقرانه بنموذجنا (هنا، GPT-2):

```py
from transformers import AutoTokenizer

old_tokenizer = AutoTokenizer.from_pretrained("gpt2")
```

على الرغم من أننا سنقوم بتدريب محدد رموز جديد، إلا أن هذه فكرة جيدة لتجنب البدء من الصفر تمامًا. بهذه الطريقة، لن نضطر إلى تحديد أي شيء حول خوارزمية تحديد الرموز أو الرموز الخاصة التي نريد استخدامها؛ سيكون محدد الرموز الجديد الخاص بنا مطابقًا تمامًا لـ GPT-2، والشيء الوحيد الذي سيتغير هو المفردات، والتي سيتم تحديدها بواسطة التدريب على نصنا.

أولاً دعنا نلقي نظرة على كيفية معالجة هذا المحدد لرموز مثال عن إحدى الوظائف:

```py
example = '''def add_numbers(a, b):
"""Add the two numbers `a` and `b`."""
return a + b'''

tokens = old_tokenizer.tokenize(example)
tokens
```

```python out
['def', 'Ġadd', '_', 'n', 'umbers', '(', 'a', ',', 'Ġb', '):', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġ"""', 'Add', 'Ġthe', 'Ġtwo',
'Ġnumbers', 'Ġ`', 'a', '`', 'Ġand', 'Ġ`', 'b', '`', '."', '""', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġreturn', 'Ġa', 'Ġ+', 'Ġb']
```

يحتوي هذا المحدد لرموز على بعض الرموز الخاصة، مثل `Ġ` و `Ċ`، والتي تشير إلى المسافات وعلامات الأسطر الجديدة، على التوالي. كما نرى، هذا غير فعال للغاية: يقوم محدد الرموز بإرجاع رموز فردية لكل مسافة، عندما يمكنه تجميع مستويات الإزاحة (نظرًا لأن وجود مجموعات من أربعة أو ثمانية مسافات سيكون شائعًا جدًا في الكود). كما أنه قام بتقسيم اسم الوظيفة بطريقة غريبة، حيث لم يعتد على رؤية كلمات تحتوي على حرف `_`.

دعونا نقوم بتدريب محدد رموز جديد ونرى ما إذا كان ذلك يحل هذه المشكلات. للقيام بذلك، سنستخدم طريقة `train_new_from_iterator()`:

```py
tokenizer = old_tokenizer.train_new_from_iterator(training_corpus, 52000)
```

قد يستغرق هذا الأمر بعض الوقت إذا كان نصك كبيرًا جدًا، ولكنه سريع للغاية بالنسبة لمجموعة البيانات هذه التي تبلغ 1.6 جيجابايت من النصوص (دقيقة واحدة و16 ثانية على وحدة المعالجة المركزية AMD Ryzen 9 3900X ذات 12 نواة).

لاحظ أن `AutoTokenizer.train_new_from_iterator()` يعمل فقط إذا كان محدد الرموز الذي تستخدمه هو محدد رموز "سريع". كما سترى في القسم التالي، تحتوي مكتبة 🤗 Transformers على نوعين من محددات الرموز: بعضها مكتوب بلغة Python فقط والبعض الآخر (السريع) مدعوم من مكتبة 🤗 Tokenizers، المكتوبة بلغة برمجة [Rust](https://www.rust-lang.org). Python هي اللغة الأكثر استخدامًا في علم البيانات وتطبيقات التعلم العميق، ولكن عندما يحتاج أي شيء إلى موازاة ليصبح سريعًا، يجب كتابته بلغة أخرى. على سبيل المثال، يتم كتابة عمليات الضرب بالمصفوفة التي تشكل جوهر حساب النموذج بلغة C CUDA المحسنة، لمكتبات GPU.

سيكون تدريب محدد رموز جديد تمامًا في Python بطيئًا للغاية، وهذا هو السبب في تطوير مكتبة 🤗 Tokenizers. لاحظ أنه تمامًا كما لم يكن عليك تعلم لغة CUDA لتتمكن من تشغيل نموذجك على دفعة من المدخلات على وحدة معالجة الرسومات (GPU)، فلن تحتاج إلى تعلم Rust لاستخدام محدد رموز سريع. توفر مكتبة 🤗 Tokenizers روابط Python للعديد من الطرق التي تستدعي داخليًا بعض التعليمات البرمجية في Rust؛ على سبيل المثال، لموازاة تدريب محدد رموز الجديد الخاص بك أو، كما رأينا في [الفصل 3] (/course/chapter3)، تحديد رموز دفعة من المدخلات.

تتوفر معظم نماذج المحول محدد رموز سريع (هناك بعض الاستثناءات التي يمكنك التحقق منها [هنا](https://huggingface.co/transformers/#supported-frameworks))، وAPI لـ `AutoTokenizer` يختار دائمًا محدد الرموز السريع لك إذا كان متاحًا. في القسم التالي، سنلقي نظرة على بعض الميزات الخاصة الأخرى التي تتمتع بها محددات الرموز السريعة، والتي ستكون مفيدة جدًا لمهام مثل تصنيف الرموز والإجابة على الأسئلة. قبل الغوص في ذلك، ومع ذلك، دعونا نجرب محدد الرموز الجديد الخاص بنا على المثال السابق:

```py
tokens = tokenizer.tokenize(example)
tokens
```

```python out
['def', 'Ġadd', '_', 'numbers', '(', 'a', ',', 'Ġb', '):', 'ĊĠĠĠ', 'Ġ"""', 'Add', 'Ġthe', 'Ġtwo', 'Ġnumbers', 'Ġ`',
'a', '`', 'Ġand', 'Ġ`', 'b', '`."""', 'ĊĠĠĠ', 'Ġreturn', 'Ġa', 'Ġ+', 'Ġb']
```

هنا نرى مرة أخرى الرموز الخاصة `Ġ` و `Ċ` التي تشير إلى المسافات وعلامات الأسطر الجديدة، ولكن يمكننا أيضًا أن نرى أن محدد الرموز الخاص بنا تعلم بعض الرموز التي تخص نصًا من وظائف Python: على سبيل المثال، هناك رمز `ĊĠĠĠ` يمثل إزاحة، ورمز `Ġ"""` يمثل علامات الاقتباس الثلاثة التي تبدأ بdocstring. قام محدد الرموز أيضًا بتقسيم اسم الوظيفة بشكل صحيح على `_`. هذا تمثيل مضغوط للغاية؛ على سبيل المقارنة، باستخدام محدد رموز اللغة الإنجليزية العادي على نفس المثال سيعطينا جملة أطول:

```py
print(len(tokens))
print(len(old_tokenizer.tokenize(example)))
```

```python out
27
36
```

لنلقِ نظرة على مثال آخر:

```python
example = """class LinearLayer():
def __init__(self, input_size, output_size):
self.weight = torch.randn(input_size, output_size)
self.bias = torch.zeros(output_size)

def __call__(self, x):
return x @ self.weights + self.bias
"""
tokenizer.tokenize(example)
```

```python out
['class', 'ĠLinear', 'Layer', '():', 'ĊĠĠĠ', 'Ġdef', 'Ġ__', 'init', '__(', 'self', ',', 'Ġinput', '_', 'size', ',',
'Ġoutput', '_', 'size', '):', 'ĊĠĠĠĠĠĠĠ', 'Ġself', '.', 'weight', 'Ġ=', 'Ġtorch', '.', 'randn', '(', 'input', '_',
'size', ',', 'Ġoutput', '_', 'size', ')', 'ĊĠĠĠĠĠĠĠ', 'Ġself', '.', 'bias', 'Ġ=', 'Ġtorch', '.', 'zeros', '(',
'output', '_', 'size', ')', 'ĊĊĠĠĠ', 'Ġdef', 'Ġ__', 'call', '__(', 'self', ',', 'Ġx', '):', '
## حفظ أداة تحليل الرموز (tokenizer)

للتأكد من إمكانية استخدامها لاحقًا، نحتاج إلى حفظ أداة تحليل الرموز الجديدة الخاصة بنا. ويتم ذلك، كما هو الحال مع النماذج، باستخدام طريقة `save_pretrained()`:

```py
tokenizer.save_pretrained("code-search-net-tokenizer")
```

سيؤدي هذا إلى إنشاء مجلد جديد باسم *code-search-net-tokenizer*، والذي سيتضمن جميع الملفات التي تحتاجها أداة تحليل الرموز لإعادة تحميلها. إذا كنت ترغب في مشاركة هذه الأداة مع زملائك وأصدقائك، يمكنك تحميلها إلى المحـور (Hub) عن طريق تسجيل الدخول إلى حسابك. وإذا كنت تعمل في دفتر ملاحظات، فهناك دالة ملائمة لمساعدتك في ذلك:

```python
from huggingface_hub import notebook_login

notebook_login()
```

سيؤدي هذا إلى عرض نافذة منبثقة حيث يمكنك إدخال بيانات اعتماد تسجيل الدخول إلى Hugging Face. إذا لم تكن تعمل في دفتر الملاحظات، فما عليك سوى كتابة السطر التالي في طرفية الحاسوب:

```bash
huggingface-cli login
```

بمجرد تسجيل الدخول، يمكنك إرسال أداة تحليل الرموز الخاصة بك عن طريق تنفيذ الأمر التالي:

```py
tokenizer.push_to_hub("code-search-net-tokenizer")
```

سيؤدي هذا إلى إنشاء مستودع جديد في مساحة الاسم الخاصة بك باسم `code-search-net-tokenizer`، والذي يحتوي على ملف أداة تحليل الرموز. بعد ذلك، يمكنك تحميل أداة تحليل الرموز من أي مكان باستخدام طريقة `from_pretrained()`:

```py
# استبدل "huggingface-course" أدناه بنطاقك الفعلي لاستخدام أداة تحليل الرموز الخاصة بك
tokenizer = AutoTokenizer.from_pretrained("huggingface-course/code-search-net-tokenizer")
```

والآن، أنت مستعد تمامًا لتدريب نموذج لغة من الصفر وتعديله ليناسب المهمة التي بين يديك! سنتطرق إلى ذلك في [الفصل 7](/course/chapter7)، ولكن أولاً، في بقية هذا الفصل، سنلقي نظرة فاحصة على أدوات تحليل الرموز السريعة (fast tokenizers) وسنستكشف بالتفصيل ما يحدث بالفعل عند استدعاء طريقة `train_new_from_iterator()`.