# نماذج الترتيب التسلسلي 

تستخدم نماذج الترميز فك الترميز (المعروفة أيضًا باسم *نماذج الترتيب التسلسلي*) كلا جزأي هندسة المحول. في كل مرحلة، يمكن لطبقات الاهتمام في الترميز الوصول إلى جميع الكلمات في الجملة الأولية، في حين لا يمكن لطبقات الاهتمام في فك الترميز إلا الوصول إلى الكلمات الموجودة قبل كلمة معينة في الإدخال.

يمكن إجراء التدريب المسبق لهذه النماذج باستخدام أهداف نماذج الترميز أو فك الترميز، ولكنها عادة ما تنطوي على شيء أكثر تعقيدًا إلى حد ما. على سبيل المثال، يتم التدريب المسبق لـ [T5] (https://huggingface.co/t5-base) عن طريق استبدال نطاقات عشوائية من النص (التي يمكن أن تحتوي على عدة كلمات) بكلمة قناع خاصة واحدة، ويتمثل الهدف بعد ذلك في التنبؤ بالنص الذي تستبدله هذه الكلمة القناع.

نماذج الترتيب التسلسلي مناسبة بشكل أفضل للمهام التي تدور حول توليد جمل جديدة اعتمادًا على إدخال معين، مثل الملخص أو الترجمة أو الإجابة على الأسئلة التوليدية.

ومن ممثلي عائلة النماذج هذه:

- [BART](https://huggingface.co/transformers/model_doc/bart)
- [mBART](https://huggingface.co/transformers/model_doc/mbart)
- [ماريان](https://huggingface.co/transformers/model_doc/marian)
- [T5](https://huggingface.co/transformers/model_doc/t5)