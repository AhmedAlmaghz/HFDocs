# ุถุจุท ุฏููู ููููุฐุฌ ุจุงุณุชุฎุฏุงู Keras

ุจูุฌุฑุฏ ุงูุงูุชูุงุก ูู ุฌููุน ุฃุนูุงู ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ููุจูุงูุงุช ูู ุงููุณู ุงูุฃุฎูุฑุ ูู ูุชุจู ุณูู ุจุถุน ุฎุทูุงุช ูุชุฏุฑูุจ ุงููููุฐุฌ. ูุงุญุธุ ูุน ุฐููุ ุฃู ุฃูุฑ `model.fit()` ุณูู ูุนูู ุจุจุทุก ุดุฏูุฏ ุนูู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ. ุฅุฐุง ูู ููู ูุฏูู ูุญุฏุฉ ูุนุงูุฌุฉ ุฑุณูููุฉ (GPU) ุฌุงูุฒุฉุ ูููููู ุงูุญุตูู ุนูู ูุตูู ูุฌุงูู ุฅูู ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU) ุฃู ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฏูุงููุงุช (TPU) ุนูู [Google Colab](https://colab.research.google.com/).

ุชูุชุฑุถ ุฃูุซูุฉ ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ ุฃุฏูุงู ุฃูู ููุช ุจุงููุนู ุจุชูููุฐ ุงูุฃูุซูุฉ ูู ุงููุณู ุงูุณุงุจู. ูููุง ููู ููุฎุต ูุตูุฑ ูุณุชุนุฑุถ ูุง ุชุญุชุงุฌู:

```py
from datasets import load_dataset
from transformers import AutoTokenizer, DataCollatorWithPadding
import numpy as np

raw_datasets = load_dataset("glue", "mrpc")
checkpoint = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)


def tokenize_function(example):
    return tokenizer(example["sentence1"], example["sentence2"], truncation=True)


tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)

data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors="tf")

tf_train_dataset = tokenized_datasets["train"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "token_type_ids"],
    label_cols=["labels"],
    shuffle=True,
    collate_fn=data_collator,
    batch_size=8,
)

tf_validation_dataset = tokenized_datasets["validation"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "token_type_ids"],
    label_cols=["labels"],
    shuffle=False,
    collate_fn=data_collator,
    batch_size=8,
)
```

## ุงูุชุฏุฑูุจ

ุชุนุฏ ููุงุฐุฌ TensorFlow ุงููุณุชูุฑุฏุฉ ูู ููุชุจุฉ ๐ค Transformers ููุงุฐุฌ Keras ุจุงููุนู. ูููุง ููู ููุฏูุฉ ููุฌุฒุฉ ุนู Keras.

ูุฐุง ูุนูู ุฃูู ุจูุฌุฑุฏ ุญุตูููุง ุนูู ุจูุงูุงุชูุงุ ูู ูุญุชุงุฌ ุฅูู ุงููุซูุฑ ูู ุงูุนูู ูุจุฏุก ุงูุชุฏุฑูุจ ุนูููุง.

ููุง ูู ุงูุญุงู ูู [ุงููุตู ุงูุณุงุจู](/course/chapter2)ุ ุณูุณุชุฎุฏู ูุฆุฉ `TFAutoModelForSequenceClassification`ุ ูุน ุนูุงูุชูู ุชุตููู:

```py
from transformers import TFAutoModelForSequenceClassification

model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
```

ุณุชูุงุญุธ ุฃูู ุนูู ุนูุณ [ุงููุตู 2](/course/chapter2)ุ ุณุชุญุตู ุนูู ุชุญุฐูุฑ ุจุนุฏ ุฅูุดุงุก ูุฐุง ุงููููุฐุฌ ุงูููุฏุฑุจ ูุณุจููุง. ููุฑุฌุน ุฐูู ุฅูู ุฃู BERT ูู ูุชู ุชุฏุฑูุจู ูุณุจููุง ุนูู ุชุตููู ุฃุฒูุงุฌ ุงูุฌููุ ูุฐูู ุชู ุงูุชุฎูุต ูู ุฑุฃุณ ุงููููุฐุฌ ุงูููุฏุฑุจ ูุณุจููุง ูุชู ุฅุฏุฑุงุฌ ุฑุฃุณ ุฌุฏูุฏ ููุงุณุจ ูุชุตููู ุงูุชุณูุณู ุจุฏูุงู ููู. ุชุดูุฑ ุงูุชุญุฐูุฑุงุช ุฅูู ุฃูู ูู ูุชู ุงุณุชุฎุฏุงู ุจุนุถ ุงูุฃูุฒุงู (ุงูุชู ุชุชูุงูู ูุน ุฑุฃุณ ุงูุชุฏุฑูุจ ุงููุณุจู ุงูููุณูุท) ูุฃู ุงูุจุนุถ ุงูุขุฎุฑ ุชู ุชููุฆุชู ุจุดูู ุนุดูุงุฆู (ุงูุฎุงุต ุจุงูุฑุฃุณ ุงูุฌุฏูุฏ). ููุฎุชุชู ุจุชุดุฌูุนู ุนูู ุชุฏุฑูุจ ุงููููุฐุฌุ ููู ูุง ุณูููู ุจู ุงูุขู ุจุงูุถุจุท.

ูุถุจุท ุงููููุฐุฌ ุจุฏูุฉ ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจูุงุ ูุง ุนูููุง ุณูู `compile()` ูููุฐุฌูุง ุซู ุชูุฑูุฑ ุจูุงูุงุชูุง ุฅูู ุทุฑููุฉ `fit()`. ุณูุจุฏุฃ ูุฐุง ุนูููุฉ ุงูุถุจุท ุงูุฏููู (ุงูุชู ูุฌุจ ุฃู ุชุณุชุบุฑู ุจุถุน ุฏูุงุฆู ุนูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช) ูุงูุฅุจูุงุบ ุนู ููุฏุงู ุงูุชุฏุฑูุจ ุฃุซูุงุก ุงูุชูููุ ุจุงูุฅุถุงูุฉ ุฅูู ููุฏุงู ุงูุชุญูู ูู ุงูุตุญุฉ ูู ููุงูุฉ ูู ุญูุจุฉ.

> ููุงุญุธุฉ: ุชูุชูู ููุงุฐุฌ ๐ค Transformers ูุฏุฑุฉ ุฎุงุตุฉ ูุง ุชูุชูููุง ูุนุธู ููุงุฐุฌ Keras - ูููููุง ุชููุงุฆููุง ุงุณุชุฎุฏุงู ุฎุณุงุฑุฉ ููุงุณุจุฉ ุชุญุณุจูุง ุฏุงุฎูููุง. ุณูุชู ุงุณุชุฎุฏุงู ูุฐู ุงูุฎุณุงุฑุฉ ุจุดูู ุงูุชุฑุงุถู ุฅุฐุง ูู ุชููู ุจุชุนููู ุญุฌุฉ ุงูุฎุณุงุฑุฉ ูู `compile()`. ูุงุญุธ ุฃูู ูุงุณุชุฎุฏุงู ุงูุฎุณุงุฑุฉ ุงูุฏุงุฎููุฉุ ุณูุชุนูู ุนููู ุชูุฑูุฑ ุชุณููุงุชู ูุฌุฒุก ูู ุงูุฅุฏุฎุงูุ ูููุณ ูุชุณููุฉ ูููุตูุฉุ ูุงูุชู ุชุนุฏ ุงูุทุฑููุฉ ุงููุนุชุงุฏุฉ ูุงุณุชุฎุฏุงู ุงูุชุณููุงุช ูุน ููุงุฐุฌ Keras. ุณุชุฌุฏ ุฃูุซูุฉ ุนูู ุฐูู ูู ุงูุฌุฒุก 2 ูู ุงูุฏูุฑุฉ ุงูุชุฏุฑูุจูุฉุ ุญูุซ ูููู ุฃู ูููู ุชุนุฑูู ุฏุงูุฉ ุงูุฎุณุงุฑุฉ ุงูุตุญูุญุฉ ุฃูุฑูุง ุตูููุง. ุจุงููุณุจุฉ ูุชุตููู ุงูุชุณูุณูุ ุชุนูู ุฏุงูุฉ ุฎุณุงุฑุฉ Keras ุงูููุงุณูุฉ ุจุดูู ุฌูุฏุ ูุฐุง ููุฐุง ูุง ุณูุณุชุฎุฏูู ููุง.

```py
from tensorflow.keras.losses import SparseCategoricalCrossentropy

model.compile(
    optimizer="adam",
    loss=SparseCategoricalCrossentropy(from_logits=True),
    metrics=["accuracy"],
)
model.fit(
    tf_train_dataset,
    validation_data=tf_validation_dataset,
)
```

> ููุงุญุธุฉ: ููุงู ูุฎ ุดุงุฆุน ุฌุฏูุง ููุง - ููููู ููุท ุชูุฑูุฑ ุงุณู ุงูุฎุณุงุฑุฉ ูุณูุณูุฉ ุฅูู Kerasุ ูููู ุจุดูู ุงูุชุฑุงุถูุ ููุชุฑุถ Keras ุฃูู ูุฏ ุทุจูุช ุจุงููุนู ุฏุงูุฉ softmax ุนูู ุงูุฅุฎุฑุงุฌ ุงูุฎุงุต ุจู. ููุน ุฐููุ ูุฅู ุงูุนุฏูุฏ ูู ุงูููุงุฐุฌ ุชุฎุฑุฌ ุงูููู ูุจุงุดุฑุฉ ูุจู ุชุทุจูู ุฏุงูุฉ softmaxุ ูุงููุนุฑููุฉ ุฃูุถูุง ุจุงุณู *logits*. ูุญู ุจุญุงุฌุฉ ุฅูู ุฅุฎุจุงุฑ ุฏุงูุฉ ุงูุฎุณุงุฑุฉ ุจุฃู ูุฐุง ูุง ููุนูู ูููุฐุฌูุงุ ูุงูุทุฑููุฉ ุงููุญูุฏุฉ ููููุงู ุจุฐูู ูู ุงุณุชุฏุนุงุคูุง ูุจุงุดุฑุฉุ ุจุฏูุงู ูู ุงูุงุณู ุจุงุณุชุฎุฏุงู ุณูุณูุฉ.

## ุชุญุณูู ุฃุฏุงุก ุงูุชุฏุฑูุจ

ุฅุฐุง ููุช ุจุชุฌุฑุจุฉ ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ ุฃุนูุงูุ ูุณุชุนูู ุจุงูุชุฃููุฏุ ููููู ุณุชุฌุฏ ุฃู ุงูุฎุณุงุฑุฉ ุชูุฎูุถ ุจุจุทุก ููุท ุฃู ุจุดูู ูุชูุทุน. ุงูุณุจุจ ุงูุฑุฆูุณู ูู *ูุนุฏู ุงูุชุนูู*. ููุง ูู ุงูุญุงู ูุน ุงูุฎุณุงุฑุฉุ ุนูุฏูุง ููุฑุฑ ุงุณู ููุญุณู ุฅูู Keras ูุณูุณูุฉุ ูููู Keras ุจุฅุนุฏุงุฏ ุงููุญุณู ูุฐุง ุจุงุณุชุฎุฏุงู ุงูููู ุงูุงูุชุฑุงุถูุฉ ูุฌููุน ุงููุนููุงุชุ ุจูุง ูู ุฐูู ูุนุฏู ุงูุชุนูู. ููุน ุฐููุ ูู ุฎูุงู ุงูุชุฌุฑุจุฉ ุงูุทูููุฉุ ูุนูู ุฃู ููุงุฐุฌ ุงููุญูู ุชููุฏ ูู ุงูุฎูุงุถ ูุนุฏู ุงูุชุนูู ุฃูุซุฑ ูู ุงูุงูุชุฑุงุถู ูุจุฑูุงูุฌ Adamุ ูุงูุฐู ูุจูุบ 1e-3ุ ุฃู 0.001. ูุนุฏ 5e-5 (0.00005)ุ ููู ุฃูู ุจุนุดุฑูู ูุฑุฉุ ููุทุฉ ุจุฏุงูุฉ ุฃูุถู ุจูุซูุฑ.

ุจุงูุฅุถุงูุฉ ุฅูู ุฎูุถ ูุนุฏู ุงูุชุนููุ ูุฏููุง ุญููุฉ ุซุงููุฉ: ูููููุง ุชูููู ูุนุฏู ุงูุชุนูู ุจุจุทุก ุนูู ูุฏุงุฑ ุงูุชุฏุฑูุจ. ูู ุงูุฃุฏุจูุงุชุ ูุฏ ูุดุงุฑ ุฅูู ุฐูู ุฃุญูุงููุง ุจุงุณู *ุชุญูู* ุฃู *ุงูุชุฏุฑุฌ* ูุนุฏู ุงูุชุนูู. ูู Kerasุ ุฃูุถู ุทุฑููุฉ ููููุงู ุจุฐูู ูู ุงุณุชุฎุฏุงู *ุฌุฏูู ูุนุฏู ุงูุชุนูู*. ูุนุฏ `PolynomialDecay` ุฎูุงุฑูุง ุฌูุฏูุง ููุงุณุชุฎุฏุงู - ุนูู ุงูุฑุบู ูู ุงูุงุณูุ ูุฅูู ุจุจุณุงุทุฉ ูููู ุฎุทููุง ูุนุฏู ุงูุชุนูู ูู ุงููููุฉ ุงูุฃูููุฉ ุฅูู ุงููููุฉ ุงูููุงุฆูุฉ ุนูู ูุฏุงุฑ ุงูุชุฏุฑูุจุ ููู ุจุงูุถุจุท ูุง ูุฑูุฏู. ููุน ุฐููุ ููู ูุณุชุฎุฏู ุฌุฏูููุง ุจุดูู ุตุญูุญุ ูุชุนูู ุนูููุง ุฅุฎุจุงุฑู ุจูุฏุฉ ุงูุชุฏุฑูุจ. ูุญุณุจ ุฐูู ุนูู ุฃูู `num_train_steps` ุฃุฏูุงู.

```py
from tensorflow.keras.optimizers.schedules import PolynomialDecay

batch_size = 8
num_epochs = 3
# ุนุฏุฏ ุฎุทูุงุช ุงูุชุฏุฑูุจ ูู ุนุฏุฏ ุงูุนููุงุช ูู ูุฌููุนุฉ ุงูุจูุงูุงุชุ ููุณูููุง ุนูู ุญุฌู ุงูุฏูุนุฉ ุซู ูุชู ุถุฑุจู
# ุจุนุฏุฏ ุงูุนุตูุฑ. ูุงุญุธ ุฃู tf_train_dataset ููุง ุนุจุงุฑุฉ ุนู ูุฌููุนุฉ ุจูุงูุงุช tf.data.Dataset ูุฌูุนุฉุ
# ูููุณ ูุฌููุนุฉ Hugging Face ุงูุฃุตููุฉุ ูุฐุง ูุฅู len() ุงูุฎุงุตุฉ ุจูุง ูู ุจุงููุนู num_samples // batch_size.
num_train_steps = len(tf_train_dataset) * num_epochs
lr_scheduler = PolynomialDecay(
    initial_learning_rate=5e-5, end_learning_rate=0.0, decay_steps=num_train_steps
)
from tensorflow.keras.optimizers import Adam

opt = Adam(learning_rate=lr_scheduler)
```

> ููุงุญุธุฉ: ุชุญุชูู ููุชุจุฉ ๐ค Transformers ุฃูุถูุง ุนูู ุฏุงูุฉ `create_optimizer()` ุณุชูุดุฆ ูุญุณู `AdamW` ุจูุนุฏู ุชุนูู ููุฎูุถ. ูุฐุง ุงุฎุชุตุงุฑ ูููุฏ ุณุชุฑุงู ุจุงูุชูุตูู ูู ุงูุฃูุณุงู ุงููุณุชูุจููุฉ ูู ุงูุฏูุฑุฉ ุงูุชุฏุฑูุจูุฉ.

ุงูุขู ุจุนุฏ ุฃู ุฃุตุจุญ ูุฏููุง ูุญุณู ุฌุฏูุฏ ุชูุงููุงุ ูููููุง ุชุฌุฑุจุฉ ุงูุชุฏุฑูุจ ุจุงุณุชุฎุฏุงูู. ุฃููุงูุ ุฏุนูุง ูุนูุฏ ุชุญููู ุงููููุฐุฌุ ูุฅุนุงุฏุฉ ุชุนููู ุงูุชุบููุฑุงุช ุนูู ุงูุฃูุฒุงู ูู ุชุดุบูู ุงูุชุฏุฑูุจ ุงูุฐู ูููุง ุจู ููุชูุ ุซู ูููููุง ุชุฌููุนู ูุน ุงููุญุณู ุงูุฌุฏูุฏ:

```py
import tensorflow as tf

model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
model.compile(optimizer=opt, loss=loss, metrics=["accuracy"])
```

ุงูุขูุ ูููู ุจุงูุชุฏุฑูุจ ูุฑุฉ ุฃุฎุฑู:

```py
model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=3)
```

> ๐ก ุฅุฐุง ููุช ุชุฑูุฏ ุชุญููู ูููุฐุฌู ุชููุงุฆููุง ุฅูู Hub ุฃุซูุงุก ุงูุชุฏุฑูุจุ ูููููู ุชูุฑูุฑ `PushToHubCallback` ูู ุทุฑููุฉ `model.fit()`. ุณูุชุนูู ุงููุฒูุฏ ุนู ูุฐุง ูู [ุงููุตู 4](/course/chapter4/3).

## ุชูุจุคุงุช ุงููููุฐุฌ

ุงูุชุฏุฑูุจ ููุดุงูุฏุฉ ุงูุฎุณุงุฑุฉ ุชูุฎูุถ ุฃูุฑ ุฑุงุฆุนุ ูููู ูุงุฐุง ูู ุฃุฑุฏูุง ุงูุญุตูู ุนูู ุงูุฅุฎุฑุงุฌ ูู ุงููููุฐุฌ ุงููุฏุฑุจุ ุฅูุง ูุญุณุงุจ ุจุนุถ ุงูููุงููุณุ ุฃู ูุงุณุชุฎุฏุงู ุงููููุฐุฌ ูู ุงูุฅูุชุงุฌุ ููููุงู ุจุฐููุ ูููููุง ุจุจุณุงุทุฉ ุงุณุชุฎุฏุงู ุทุฑููุฉ `predict()`. ุณูุนูุฏ ูุฐุง *logits* ูู ุฑุฃุณ ุงูุฅุฎุฑุงุฌ ูููููุฐุฌุ ูุงุญุฏ ููู ูุฆุฉ.

```py
preds = model.predict(tf_validation_dataset)["logits"]
```

ูููููุง ุชุญููู ูุฐู ุงูููู ุฅูู ุชูุจุคุงุช ูุฆุฉ ุงููููุฐุฌ ุจุงุณุชุฎุฏุงู `argmax` ููุนุซูุฑ ุนูู ุฃุนูู ูููุฉุ ูุงูุชู ุชุชูุงูู ูุน ุงููุฆุฉ ุงูุฃูุซุฑ ุงุญุชูุงููุง:

```py
class_preds = np.argmax(preds, axis=1)
print(preds.shape, class_preds.shape)
```

```python out
(408, 2) (408,)
```

ุงูุขูุ ุฏุนูุง ูุณุชุฎุฏู ุชูู `preds` ูุญุณุงุจ ุจุนุถ ุงูููุงููุณ! ูููููุง ุชุญููู ุงูููุงููุณ ุงููุฑุชุจุทุฉ ุจูุฌููุนุฉ ุจูุงูุงุช MRPC ุจุณูููุฉ ูุซู ุชุญููู ูุฌููุนุฉ ุงูุจูุงูุงุชุ ูุฐู ุงููุฑุฉ ุจุงุณุชุฎุฏุงู ุฏุงูุฉ `evaluate.load()`. ูุญุชูู ุงููุงุฆู ุงูุฐู ุชู ุฅุฑุฌุงุนู ุนูู ุทุฑููุฉ `compute()` ูููููุง ุงุณุชุฎุฏุงููุง ูุญุณุงุจ ุงููููุงุณ:

```py
import evaluate

metric = evaluate.load("glue", "mrpc")
metric.compute(predictions=class_preds, references=raw_datasets["validation"]["label"])
```

```python out
{'accuracy': 0.8578431372549019, 'f1': 0.8996539792387542}
```

ูุฏ ุชุฎุชูู ุงููุชุงุฆุฌ ุงูุชู ุชุญุตู ุนูููุง ุจุงูุถุจุทุ ุญูุซ ูุฏ ูุคุฏู ุงูุชููุฆุฉ ุงูุนุดูุงุฆูุฉ ูุฑุฃุณ ุงููููุฐุฌ ุฅูู ุชุบููุฑ ุงูููุงููุณ ุงูุชู ุญูููุง. ููุงุ ูููููุง ุฃู ูุฑู ุฃู ูููุฐุฌูุง ูุฏูู ุฏูุฉ 85.78% ุนูู ูุฌููุนุฉ ุงูุชุญูู ูู ุงูุตุญุฉ ููููุงุณ F1 ูุจูุบ 89.97. ูุฐุงู ููุง ุงููููุงุณุงู ุงููุณุชุฎุฏูุงู ูุชูููู ุงููุชุงุฆุฌ ุนูู ูุฌููุนุฉ ุจูุงูุงุช MRPC ููููุงุณ GLUE. ูุนุฑุถ ุงูุฌุฏูู ูู [ูุฑูุฉ BERT](https://arxiv.org/pdf/1810.04805.pdf) ุฏุฑุฌุฉ F1 ุชุจูุบ 88.9 ูููููุฐุฌ ุงูุฃุณุงุณู. ูุงู ูุฐุง ูู ุงููููุฐุฌ "ุบูุฑ ุงููููุฒ" ุจูููุง ูุณุชุฎุฏู ุญุงูููุง ุงููููุฐุฌ "ุงููููุฒ"ุ ูุงูุฐู ููุณุฑ ุงููุชูุฌุฉ ุงูุฃูุถู.

ูุฎุชุชู ูุฐุง ุงูููุฏูุฉ ููุถุจุท ุงูุฏููู ุจุงุณุชุฎุฏุงู ูุงุฌูุฉ ุจุฑูุฌุฉ ุชุทุจููุงุช Keras. ุณูุชู ุชูุฏูู ูุซุงู ุนูู ุงูููุงู ุจุฐูู ููุนุธู ููุงู NLP ุงูุดุงุฆุนุฉ ูู [ุงููุตู 7](/course/chapter7). ุฅุฐุง ููุช ุชุฑุบุจ ูู ุตูู ููุงุฑุงุชู ูู ูุงุฌูุฉ ุจุฑูุฌุฉ ุชุทุจููุงุช Kerasุ ูุญุงูู ุถุจุท ูููุฐุฌ ุจุฏูุฉ ุนูู ูุฌููุนุฉ ุจูุงูุงุช GLUE SST-2ุ ุจุงุณุชุฎุฏุงู ูุนุงูุฌุฉ ุงูุจูุงูุงุช ุงูุชู ููุช ุจูุง ูู ุงููุณู 2.