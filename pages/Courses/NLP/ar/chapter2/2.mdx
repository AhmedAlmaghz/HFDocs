# ุฎูู ุงูููุงููุณ

<Tip>
ูุฐุง ูู ุงููุณู ุงูุฃูู ุงูุฐู ูุฎุชูู ููู ุงููุญุชูู ููููุงู ุจูุงุกู ุนูู ูุง ุฅุฐุง ููุช ุชุณุชุฎุฏู PyTorch ุฃู TensorFlow. ูู ุจุงูุชุจุฏูู ุจูู ุงูููุชุงุญ ุงูููุฌูุฏ ุฃุนูู ุงูุนููุงู ูุงุฎุชูุงุฑ ุงูููุตุฉ ุงูุชู ุชูุถููุง!
</Tip>

ุฏุนููุง ูุจุฏุฃ ุจูุซุงู ูุงููุ ูู ุฎูุงู ุฅููุงุก ูุธุฑุฉ ุนูู ูุง ุญุฏุซ ุฎูู ุงูููุงููุณ ุนูุฏูุง ูููุง ุจุชูููุฐ ุงูููุฏ ุงูุชุงูู ูู [ุงููุตู 1](/course/chapter1):

```python
from transformers import pipeline

classifier = pipeline("sentiment-analysis")
classifier(
[
"I've been waiting for a HuggingFace course my whole life.",
"I hate this so much!",
]
)
```

ูุญุตููุง ุนูู:

```python out
[{'label': 'POSITIVE', 'score': 0.9598047137260437},
{'label': 'NEGATIVE', 'score': 0.9994558095932007}]
```

ููุง ุฑุฃููุง ูู [ุงููุตู 1](/course/chapter1)ุ ุชููู ูุฐู ุงูุฃูุงุจูุจ ุจุชุฌููุน ุซูุงุซ ุฎุทูุงุช ูุนูุง: ูุง ูุจู ุงููุนุงูุฌุฉุ ูุฅุฏุฎุงู ุงูุฅุฏุฎุงูุงุช ุนุจุฑ ุงููููุฐุฌุ ููุง ุจุนุฏ ุงููุนุงูุฌุฉ:

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline.svg" alt="ุฎุท ุฃูุงุจูุจ NLP ุงููุงูู: ุชููููุฒุงุช ุงููุตุ ูุชุญูููู ุฅูู ูุนุฑูุงุชุ ูุงูุงุณุชูุชุงุฌ ูู ุฎูุงู ูููุฐุฌ Transformer ูุฑุฃุณ ุงููููุฐุฌ." />
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline-dark.svg" alt="ุฎุท ุฃูุงุจูุจ NLP ุงููุงูู: ุชููููุฒุงุช ุงููุตุ ูุชุญูููู ุฅูู ูุนุฑูุงุชุ ูุงูุงุณุชูุชุงุฌ ูู ุฎูุงู ูููุฐุฌ Transformer ูุฑุฃุณ ุงููููุฐุฌ." />
</div>

ุฏุนููุง ููุฑ ุจุณุฑุนุฉ ุนุจุฑ ูู ูููุง.

## ูุง ูุจู ุงููุนุงูุฌุฉ ุจุงุณุชุฎุฏุงู tokenizer

ูุซู ุงูุดุจูุงุช ุงูุนุตุจูุฉ ุงูุฃุฎุฑูุ ูุง ูููู ูููุงุฐุฌ Transformer ูุนุงูุฌุฉ ุงููุต ุงูุฎุงู ูุจุงุดุฑุฉูุ ูุฐูู ุชุชูุซู ุงูุฎุทูุฉ ุงูุฃููู ูู ุฎุท ุงูุฃูุงุจูุจ ุงูุฎุงุต ุจูุง ูู ุชุญููู ุฅุฏุฎุงูุงุช ุงููุต ุฅูู ุฃุฑูุงู ูููู ูููููุฐุฌ ููููุง. ููููุงู ุจุฐููุ ูุณุชุฎุฏู *tokenizer*ุ ูุงูุฐู ุณูููู ูุณุคููุงู ุนูุง ููู:

- ุชูุณูู ุงูุฅุฏุฎุงู ุฅูู ูููุงุช ุฃู ูููุงุช ูุฑุนูุฉ ุฃู ุฑููุฒ (ูุซู ุนูุงูุงุช ุงูุชุฑููู) ุชุณูู *ุฑููุฒ*
- ุชุนููู ูู ุฑูุฒ ุฅูู ุฑูู ุตุญูุญ
- ุฅุถุงูุฉ ุฅุฏุฎุงูุงุช ุฅุถุงููุฉ ูุฏ ุชููู ูููุฏุฉ ูููููุฐุฌ

ูุฌุจ ุฅุฌุฑุงุก ูู ูุฐู ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ุจููุณ ุงูุทุฑููุฉ ุชูุงููุง ููุง ุญุฏุซ ุฃุซูุงุก ุงูุชุฏุฑูุจ ุงููุณุจู ูููููุฐุฌุ ูุฐูู ูุฌุจ ุนูููุง ุฃููุงู ุชูุฒูู ูุฐู ุงููุนูููุงุช ูู [Model Hub](https://huggingface.co/models). ููููุงู ุจุฐููุ ูุณุชุฎุฏู ูุฆุฉ `AutoTokenizer` ูุทุฑููุชูุง `from_pretrained()`. ุจุงุณุชุฎุฏุงู ุงุณู ููุทุฉ ุชูุชูุด ูููุฐุฌูุงุ ุณูููู ุชููุงุฆููุง ุจุงุณุชุฑุฏุงุฏ ุงูุจูุงูุงุช ุงููุฑุชุจุทุฉ tokenizer ุงููููุฐุฌ ูุชุฎุฒูููุง ูุคูุชูุง (ูุฐูู ูุชู ุชูุฒูููุง ููุท ูู ุงููุฑุฉ ุงูุฃููู ุงูุชู ุชุดุบู ูููุง ุงูููุฏ ุฃุฏูุงู).

ูุธุฑูุง ูุฃู ููุทุฉ ุงูุชูุชูุด ุงูุงูุชุฑุงุถูุฉ ูุฃูุจูุจ "ุงูุชุญููู ุงูุดุนูุฑู" ูู `distilbert-base-uncased-finetuned-sst-2-english` (ููููู ุงูุงุทูุงุน ุนูู ุจุทุงูุฉ ุงููููุฐุฌ ุงูุฎุงุตุฉ ุจูุง [ููุง](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english))ุ ูุฅููุง ูููู ุจุชุดุบูู ูุง ููู:

```python
from transformers import AutoTokenizer

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
```

ุจูุฌุฑุฏ ุญุตูููุง ุนูู tokenizerุ ูููููุง ุชูุฑูุฑ ุฌูููุง ูุจุงุดุฑุฉู ุฅููู ูุณูุญุตู ุนูู ูุงููุณ ุฌุงูุฒ ููุชุบุฐูุฉ ูู ูููุฐุฌูุง! ูู ูุง ุชุจูู ูู ุชุญููู ูุงุฆูุฉ ูุนุฑูุงุช ุงูุฅุฏุฎุงู ุฅูู ุชูุณูุฑุงุช.

ููููู ุงุณุชุฎุฏุงู ููุชุจุฉ ๐ค Transformers ุฏูู ุงูููู ุจุดุฃู ุฅุทุงุฑ ุนูู ML ุงููุณุชุฎุฏู ูุฎูููุฉุ ููุฏ ูููู PyTorch ุฃู TensorFlowุ ุฃู Flax ูุจุนุถ ุงูููุงุฐุฌ. ููุน ุฐููุ ุชูุจู ููุงุฐุฌ Transformer ููุท *tensors* ูุฅุฏุฎุงู. ุฅุฐุง ูุงูุช ูุฐู ูู ุงููุฑุฉ ุงูุฃููู ุงูุชู ุชุณูุน ูููุง ุนู tensorsุ ูููููู ุงุนุชุจุงุฑูุง ูุตูููุงุช NumPy. ูููู ุฃู ูููู ูุตูููุฉ NumPy ููุงุณูุฉ (0D)ุ ุฃู ูุชุฌููุง (1D)ุ ุฃู ูุตูููุฉ (2D)ุ ุฃู ุชุญุชูู ุนูู ุฃุจุนุงุฏ ุฃูุซุฑ. ุฅูู ูู ุงูุฃุณุงุณ tensorุ ุชุชุตุฑู ุงูุชูุณูุฑุงุช ุงูุฎุงุตุฉ ุจุฅุทุงุฑุงุช ุงูุนูู ุงูุฃุฎุฑู ุจุดูู ูุดุงุจูุ ูุนุงุฏุฉ ูุง ุชููู ุจุณูุทุฉ ูุซู ูุตูููุงุช NumPy.

ูุชุญุฏูุฏ ููุน ุงูุชูุณูุฑุงุช ุงูุชู ูุฑูุฏ ุฅุฑุฌุงุนูุง (PyTorch ุฃู TensorFlow ุฃู NumPy ุงูุนุงุฏู)ุ ูุณุชุฎุฏู ูุณูุท `return_tensors`:

{#if fw === 'pt'}
```python
raw_inputs = [
"I've been waiting for a HuggingFace course my whole life.",
"I hate this so much!",
]
inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors="pt")
print(inputs)
```
{:else}
```python
raw_inputs = [
"I've been waiting for a HuggingFace course my whole life.",
"I hate this so much!",
]
inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors="tf")
print(inputs)
```
{/if}

ูุง ุชููู ุจุดุฃู ุงูุญุดู ูุงูุชุดุฐูุจ ุงูุขูุ ุณูุดุฑุญ ุฐูู ูุงุญููุง. ุงูุฃุดูุงุก ุงูุฑุฆูุณูุฉ ุงูุชู ูุฌุจ ุชุฐูุฑูุง ููุง ูู ุฃูู ููููู ุชูุฑูุฑ ุฌููุฉ ูุงุญุฏุฉ ุฃู ูุงุฆูุฉ ูู ุงูุฌููุ ููุฐูู ุชุญุฏูุฏ ููุน ุงูุชูุณูุฑุงุช ุงูุชู ุชุฑูุฏ ุฅุฑุฌุงุนูุง (ุฅุฐุง ูู ูุชู ุชูุฑูุฑ ุฃู ููุนุ ูุณุชุญุตู ุนูู ูุงุฆูุฉ ูู ุงูููุงุฆู ููุชูุฌุฉ).

{#if fw === 'pt'}

ููุฐุง ุชุจุฏู ุงููุชุงุฆุฌ ุจุงุณุชุฎุฏุงู ุชูุณูุฑุงุช PyTorch:

```python out
{
'input_ids': tensor([
[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172, 2607,  2026,  2878,  2166,  1012,   102],
[  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,     0,     0,     0,     0,     0,     0]
]),
'attention_mask': tensor([
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]
])
}
```
{:else}

ููุฐุง ุชุจุฏู ุงููุชุงุฆุฌ ุจุงุณุชุฎุฏุงู ุชูุณูุฑุงุช TensorFlow:

```python out
{
'input_ids': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=
array([
[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,  2026,  2878,  2166,  1012,   102],
[  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,     0,     0,     0,     0,     0,     0]
], dtype=int32)>,
'attention_mask': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=
array([
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]
], dtype=int32)>
}
```
{/if}

ูุญุชูู ุงูุฅุฎุฑุงุฌ ููุณู ุนูู ูุงููุณ ูุญุชูู ุนูู ููุชุงุญููุ `input_ids` ู`attention_mask`. ูุญุชูู `input_ids` ุนูู ุตููู ูู ุงูุฃุนุฏุงุฏ ุงูุตุญูุญุฉ (ูุงุญุฏ ููู ุฌููุฉ) ููู ุงููุนุฑูุงุช ุงููุฑูุฏุฉ ููุฑููุฒ ูู ูู ุฌููุฉ. ุณูุดุฑุญ ูุง ูู `attention_mask` ูุงุญููุง ูู ูุฐุง ุงููุตู.

## ุงููุฑูุฑ ุฎูุงู ุงููููุฐุฌ

{#if fw === 'pt'}

ูููููุง ุชูุฒูู ูููุฐุฌูุง ุงูููุฏุฑุจ ูุณุจููุง ุจููุณ ุงูุทุฑููุฉ ุงูุชู ูููุง ุจูุง ูุน tokenizer. ุชููุฑ ููุชุจุฉ ๐ค Transformers ูุฆุฉ `AutoModel` ูุงูุชู ุชุญุชูู ุฃูุถูุง ุนูู ุทุฑููุฉ `from_pretrained()`:

```python
from transformers import AutoModel

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
model = AutoModel.from_pretrained(checkpoint)
```
{:else}

ูููููุง ุชูุฒูู ูููุฐุฌูุง ุงูููุฏุฑุจ ูุณุจููุง ุจููุณ ุงูุทุฑููุฉ ุงูุชู ูููุง ุจูุง ูุน tokenizer. ุชููุฑ ููุชุจุฉ ๐ค Transformers ูุฆุฉ `TFAutoModel` ูุงูุชู ุชุญุชูู ุฃูุถูุง ุนูู ุทุฑููุฉ `from_pretrained`:

```python
from transformers import TFAutoModel

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
model = TFAutoModel.from_pretrained(checkpoint)
```
{/if}

ูู ูุฐุง ุงูููุชุทู ูู ุงูููุฏุ ูููุง ุจุชูุฒูู ููุณ ููุทุฉ ุงูุชูุชูุด ุงูุชู ุงุณุชุฎุฏููุงูุง ูู ุฎุท ุงูุฃูุงุจูุจ ุงูุฎุงุต ุจูุง ูู ูุจู (ูู ุงูููุชุฑุถ ุฃููุง ูุงูุช ูุฎุฒูุฉ ูุคูุชูุง ุจุงููุนู) ููููุง ุจุชููุฆุฉ ูููุฐุฌ ุจูุง.

ุชุชุถูู ูุฐู ุงูููุฏุณุฉ ูุญุฏุฉ Transformer ุงูุฃุณุงุณูุฉ ููุท: ููู ุชุนุทู ูุง ุณูุทูู ุนููู ุงุณู *ุงูุญุงูุงุช ุงููุฎููุฉ*ุ ูุงููุนุฑููุฉ ุฃูุถูุง ุจุงุณู *ุงูููุฒุงุช*. ููู ุฅุฏุฎุงู ูููุฐุฌุ ุณูุญุตู ุนูู ูุชุฌู ุนุงูู ุงูุฃุจุนุงุฏ ููุซู **ุงูููู ุงูุณูุงูู ููุฐุง ุงูุฅุฏุฎุงู ุจูุงุณุทุฉ ูููุฐุฌ Transformer**.

ุฅุฐุง ูู ููู ูุฐุง ููุทูููุงุ ููุง ุชููู. ุณูุดุฑุญ ูู ุดูุก ูุงุญููุง.

ูู ุญูู ุฃู ูุฐู ุงูุญุงูุงุช ุงููุฎููุฉ ูููู ุฃู ุชููู ูููุฏุฉ ุจููุฑุฏูุงุ ุฅูุง ุฃููุง ุนุงุฏุฉู ูุง ุชููู ุฅุฏุฎุงูุงุช ูุฌุฒุก ุขุฎุฑ ูู ุงููููุฐุฌุ ููุนุฑู ุจุงุณู *ุงูุฑุฃุณ*. ูู [ุงููุตู 1](/course/chapter1)ุ ูููู ุชูููุฐ ุงูููุงู ุงููุฎุชููุฉ ุจุงุณุชุฎุฏุงู ููุณ ุงูููุฏุณุฉุ ูููู ุณูููู ููู ูู ูุฐู ุงูููุงู ุฑุฃุณ ูุฎุชูู ูุฑุชุจุท ุจูุง.

### ูุชุฌู ุนุงูู ุงูุฃุจุนุงุฏุ

ุงููุชุฌู ุงูุฐู ูุฎุฑุฌู ูุญุฏุฉ Transformer ูุจูุฑ ุงูุญุฌู ุนุงุฏุฉู. ุนุงุฏุฉู ูุง ูููู ูู ุซูุงุซุฉ ุฃุจุนุงุฏ:

- **ุญุฌู ุงูุฏูุนุฉ**: ุนุฏุฏ ุงูุชุณูุณูุงุช ุงูุชู ุชุชู ูุนุงูุฌุชูุง ูู ููุช ูุงุญุฏ (2 ูู ูุซุงููุง).
- **ุทูู ุงูุชุณูุณู**: ุทูู ุงูุชูุซูู ุงูุฑููู ููุชุณูุณู (16 ูู ูุซุงููุง).
- **ุงูุญุฌู ุงููุฎูู**: ุงูุจุนุฏ ุงููุชุฌูู ููู ุฅุฏุฎุงู ูููุฐุฌ.

ูููุงู ุฅูู "ุนุงูู ุงูุฃุจุนุงุฏ" ุจุณุจุจ ุงููููุฉ ุงูุฃุฎูุฑุฉ. ูููู ุฃู ูููู ุงูุญุฌู ุงููุฎูู ูุจูุฑูุง ุฌุฏูุง (768 ุดุงุฆุน ููููุงุฐุฌ ุงูุฃุตุบุฑุ ููู ุงูููุงุฐุฌ ุงูุฃูุจุฑ ูููู ุฃู ูุตู ุฅูู 3072 ุฃู ุฃูุซุฑ).

ูููููุง ุฃู ูุฑู ูุฐุง ุฅุฐุง ูููุง ุจุชุบุฐูุฉ ุงูุฅุฏุฎุงูุงุช ุงูุชู ูููุง ุจูุนุงูุฌุชูุง ูุณุจููุง ูู ูููุฐุฌูุง:

{#if fw === 'pt'}
```python
outputs = model(**inputs)
print(outputs.last_hidden_state.shape)
```
```python out
torch.Size([2, 16, 768])
```
{:else}
```py
outputs = model(inputs)
print(outputs.last_hidden_state.shape)
```
```python out
(2, 16, 768)
```
{/if}

ูุงุญุธ ุฃู ุงูุฅุฎุฑุงุฌ ูู ููุงุฐุฌ ๐ค Transformers ูุชุตุฑู ูุซู `namedtuple`s ุฃู ุงูููุงููุณ. ููููู ุงููุตูู ุฅูู ุงูุนูุงุตุฑ ุจูุงุณุทุฉ ุงูุณูุงุช (ููุง ูุนููุง) ุฃู ุจูุงุณุทุฉ ุงูููุชุงุญ (`outputs["last_hidden_state"]`)ุ ุฃู ุญุชู ุจูุงุณุทุฉ ุงูููุฑุณ ุฅุฐุง ููุช ุชุนุฑู ุจุงูุถุจุท ุงูููุงู ุงูุฐู ุชุจุญุซ ููู ุนู ุงูุดูุก ุงูุฐู ุชุจุญุซ ุนูู (`outputs[0]`).

### ุฑุคูุณ ุงูููุงุฐุฌ: ุฅุนุทุงุก ูุนูู ููุฃุฑูุงู

ุชุฃุฎุฐ ุฑุคูุณ ุงูููุงุฐุฌ ุงููุชุฌู ุนุงูู ุงูุฃุจุนุงุฏ ููุญุงูุงุช ุงููุฎููุฉ ูุฅุฏุฎุงู ูุชููู ุจูุดุฑูุนูุง ุนูู ุจุนุฏ ูุฎุชูู. ุนุงุฏุฉ ูุง ุชุชููู ูู ุทุจูุฉ ุฎุทูุฉ ูุงุญุฏุฉ ุฃู ุนุฏุฏ ูููู ูู ุงูุทุจูุงุช ุงูุฎุทูุฉ:

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/transformer_and_head.svg" alt="ุดุจูุฉ Transformer ุฅูู ุฌุงูุจ ุฑุฃุณูุง." />
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/transformer_and_head-dark.svg" alt="ุดุจูุฉ Transformer ุฅูู ุฌุงูุจ ุฑุฃุณูุง." />
</div>

ูุชู ุฅุฑุณุงู ุฅุฎุฑุงุฌ ูููุฐุฌ Transformer ูุจุงุดุฑุฉู ุฅูู ุฑุฃุณ ุงููููุฐุฌ ูููุนุงูุฌุฉ.

ูู ูุฐุง ุงููุฎุทุทุ ูุชู ุชูุซูู ุงููููุฐุฌ ุจุทุจูุฉ ุชุถูููุงุชู ูุงูุทุจูุงุช ุงููุงุญูุฉ. ุชููู ุทุจูุฉ ุงูุชุถููู ุจุชุญููู ูู ูุนุฑู ุฅุฏุฎุงู ูู ุงูุฅุฏุฎุงู ุงููุนุงูุฌ ุฅูู ูุชุฌู ููุซู ุงูุฑูุฒ ุงูููุชุฑู ุจู. ุชููู ุงูุทุจูุงุช ุงููุงุญูุฉ ุจููุงูุฑุฉ ุชูู ุงููุชุฌูุงุช ุจุงุณุชุฎุฏุงู ุขููุฉ ุงูุงูุชูุงู ูุฅูุชุงุฌ ุงูุชูุซูู ุงูููุงุฆู ููุฌูู.

ููุงู ุงูุนุฏูุฏ ูู ุงูููุฏุณุงุช ุงููุฎุชููุฉ ุงููุชุงุญุฉ ูู ๐ค Transformersุ ุญูุซ ุชู ุชุตููู ูู ูููุง ุญูู ูุนุงูุฌุฉ ูููุฉ ูุญุฏุฏุฉ. ูููุง ููู ูุงุฆูุฉ ุบูุฑ ุดุงููุฉ:

- `*Model` (ุงุณุชุฑุฏุงุฏ ุงูุญุงูุงุช ุงููุฎููุฉ)
- `*ForCausalLM`
- `*ForMaskedLM`
- `*ForMultipleChoice`
- `*ForQuestionAnswering`
- `*ForSequenceClassification`
- `*ForTokenClassification`
- ูุบูุฑูุง ุงููุซูุฑ ๐ค

{#if fw === 'pt'}

ุจุงููุณุจุฉ ููุซุงููุงุ ุณูุญุชุงุฌ ุฅูู ูููุฐุฌ ุจุฑุฃุณ ุชุตููู ุชุณูุณู (ูุชุตููู ุงูุฌูู ุนูู ุฃููุง ุฅูุฌุงุจูุฉ ุฃู ุณูุจูุฉ). ูุฐููุ ูู ูุณุชุฎุฏู ูู ุงููุงูุน ูุฆุฉ `AutoModel`ุ ูููู `AutoModelForSequenceClassification`:

```python
from transformers import AutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)
outputs = model(**inputs)
```
{:else}

ุจุงููุณุจุฉ ููุซุงููุงุ ุณูุญุชุงุฌ ุฅูู ูููุฐุฌ ุจุฑุฃุณ ุชุตููู ุชุณูุณู (ูุชุตููู ุงูุฌูู ุนูู ุฃููุง ุฅูุฌุงุจูุฉ ุฃู ุณูุจูุฉ). ูุฐููุ ูู ูุณุชุฎุฏู ูู ุงููุงูุน ูุฆุฉ `TFAutoModel`ุ ูููู `TFAutoModelForSequenceClassification`:

```python
from transformers import TFAutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)
outputs = model(inputs)
```
{/if}

ุงูุขู ุฅุฐุง ูุธุฑูุง ุฅูู ุดูู ุงูุฅุฎุฑุงุฌ ุงูุฎุงุต ุจูุงุ ูุณูููู ุงูุจุนุฏ ุฃูู ุจูุซูุฑ: ูุฃุฎุฐ ุฑุฃุณ ุงููููุฐุฌ ูุฅุฏุฎุงู ุงููุชุฌูุงุช ุนุงููุฉ ุงูุฃุจุนุงุฏ ุงูุชู ุฑุฃููุงูุง ุณุงุจููุงุ ููุฎุฑุฌ ูุชุฌูุงุช ุชุญุชูู ุนูู ูููุชูู (ูุงุญุฏุฉ ููู ุชุณููุฉ):

```python
print(outputs.logits.shape)
```
{#if fw === 'pt'}
```python out
torch.Size([2, 2])
```
{:else}
```python out
(2, 2)
```
{/if}

ูุธุฑูุง ูุฃู ูุฏููุง ุฌููุชูู ูุชุณููุชูู ููุทุ ูุฅู ุงููุชูุฌุฉ ุงูุชู ูุญุตู ุนูููุง ูู ูููุฐุฌูุง ูู 2 ร 2.
## ูุนุงูุฌุฉ ุฅุฎุฑุงุฌ ุงููููุฐุฌ

ุฅู ุงูููู ุงูุชู ูุญุตู ุนูููุง ูุฅุฎุฑุงุฌ ูู ูููุฐุฌูุง ูุง ุชูุซู ุจุงูุถุฑูุฑุฉ ุงุญุชูุงูุงุช ูููููุฉ. ุฏุนููุง ูููู ูุธุฑุฉ:

```python
print(outputs.logits)
```

{#if fw === 'pt'}
```python out
tensor([[-1.5607, 1.6123],
[4.1692, -3.3464]], grad_fn=<AddmmBackward>)
```
{:else}
```python out
<tf.Tensor: shape=(2, 2), dtype=float32, numpy=
array([[-1.5606991, 1.6122842],
[4.169231, -3.3464472]], dtype=float32)>
```
{/if}

ูุชููุน ูููุฐุฌูุง `[-1.5607, 1.6123]` ููุฌููุฉ ุงูุฃููู ู`[4.1692, -3.3464]` ููุฌููุฉ ุงูุซุงููุฉ. ูุฐู ููุณุช ุงุญุชูุงูุงุช ูููููุง *logits*ุ ููู ุงูุฏุฑุฌุงุช ุงูุฎุงู ูุบูุฑ ุงููุนูุงุฑูุฉ ุงูุชู ูุฎุฑุฌูุง ุงูุทุจูุฉ ุงูุฃุฎูุฑุฉ ูู ุงููููุฐุฌ. ููุชุญููููุง ุฅูู ุงุญุชูุงูุงุชุ ูุฌุจ ุฃู ุชูุฑ ุนุจุฑ ุทุจูุฉ [SoftMax](https://en.wikipedia.org/wiki/Softmax_function) (ุฌููุน ููุงุฐุฌ ๐ค Transformers ุชุฎุฑุฌ ุงูููู ุงูุฎุงูุ ูุฃู ุฏุงูุฉ ุงูุฎุณุงุฑุฉ ููุชุฏุฑูุจ ุณุชููู ุนุงุฏุฉ ุจุฏูุฌ ุฏุงูุฉ ุงูุชูุดูุท ุงูุฃุฎูุฑุฉุ ูุซู SoftMaxุ ูุน ุฏุงูุฉ ุงูุฎุณุงุฑุฉ ุงููุนููุฉุ ูุซู entropy ุงููุชูุงุทุน):

{#if fw === 'pt'}
```py
import torch

predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
print(predictions)
```
{:else}
```py
import tensorflow as tf

predictions = tf.math.softmax(outputs.logits, axis=-1)
print(predictions)
```
{/if}

{#if fw === 'pt'}
```python out
tensor([[4.0195e-02, 9.5980e-01],
[9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward>)
```
{:else}
```python out
tf.Tensor(
[[4.01951671e-02 9.59804833e-01]
[9.9945587e-01 5.4418424e-04]], shape=(2, 2), dtype=float32)
```
{/if}

ุงูุขู ูููููุง ุฃู ูุฑู ุฃู ุงููููุฐุฌ ุชููุน `[0.0402, 0.9598]` ููุฌููุฉ ุงูุฃููู ู`[0.9995, 0.0005]` ููุฌููุฉ ุงูุซุงููุฉ. ูุฐู ุฏุฑุฌุงุช ุงุญุชูุงููุฉ ูููููุฉ.

ูููุญุตูู ุนูู ุงูุชุตูููุงุช ุงูููุงุจูุฉ ููู ููุถุนุ ูููููุง ูุญุต ุฎุงุตูุฉ `id2label` ูู ุชูููู ุงููููุฐุฌ (ุณูุชุญุฏุซ ุนู ูุฐุง ุจูุฒูุฏ ูู ุงูุชูุตูู ูู ุงููุณู ุงูุชุงูู):

```python
model.config.id2label
```

```python out
{0: 'NEGATIVE', 1: 'POSITIVE'}
```

ุงูุขู ูููููุง ุฃู ูุณุชูุชุฌ ุฃู ุงููููุฐุฌ ุชูุจุฃ ุจูุง ููู:

- ุงูุฌููุฉ ุงูุฃููู: NEGATIVE: 0.0402ุ POSITIVE: 0.9598
- ุงูุฌููุฉ ุงูุซุงููุฉ: NEGATIVE: 0.9995ุ POSITIVE: 0.0005

ููุฏ ูุฌุญูุง ูู ุงุณุชูุณุงุฎ ุฎุทูุงุช ุฎุท ุงูุฃูุงุจูุจ ุงูุซูุงุซ: ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ุจุงุณุชุฎุฏุงู ุจุฑุงูุฌ ุงูุชุนุงูู ูุน ุงูุฑููุฒุ ูุชูุฑูุฑ ุงููุฏุฎูุงุช ุนุจุฑ ุงููููุฐุฌุ ููุนุงูุฌุฉ ุงูุฅุฎุฑุงุฌ! ุงูุขู ุฏุนููุง ูุฃุฎุฐ ุจุนุถ ุงูููุช ููุบูุต ุจุดูู ุฃุนูู ูู ูู ูู ูุฐู ุงูุฎุทูุงุช.

<Tip>

โ๏ธ **ุฌุฑุจูุง ุจููุณู!** ุงุฎุชุฑ ูุตูู (ุฃู ุฃูุซุฑ) ูู ุงุฎุชูุงุฑู ููู ุจุชุดุบููููุง ุนุจุฑ ุฎุท ุฃูุงุจูุจ `sentiment-analysis`. ุซู ูู ุจุชูุฑุงุฑ ุงูุฎุทูุงุช ุงูุชู ุฑุฃูุชูุง ููุง ุจููุณู ูุชุญูู ูู ุญุตููู ุนูู ููุณ ุงููุชุงุฆุฌ!

</Tip>