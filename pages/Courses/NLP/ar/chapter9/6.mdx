# الميزات المتقدمة للواجهة

الآن بعد أن تعلمنا كيفية بناء واجهة أساسية ومشاركتها، دعونا نستكشف بعض الميزات المتقدمة مثل الحالة والتفسير.

## استخدام الحالة لإبقاء البيانات

يدعم Gradio *حالة الجلسة*، حيث تبقى البيانات ثابتة عبر إرسالات متعددة ضمن تحميل الصفحة. حالة الجلسة مفيدة لبناء عروض توضيحية، على سبيل المثال، دردشة الآلي حيث تريد الاحتفاظ بالبيانات أثناء تفاعل المستخدم مع النموذج. لاحظ أن حالة الجلسة لا تشارك البيانات بين مستخدمين مختلفين لنموذجك.

لتخزين البيانات في حالة الجلسة، تحتاج إلى القيام بثلاثة أشياء:

1. قم بتمرير *معامل إضافي* إلى دالتك، والذي يمثل حالة الواجهة.
2. في نهاية الدالة، قم بإرجاع القيمة المحدثة للحالة كـ *قيمة إرجاع إضافية*.
3. أضف مكونات 'state' input و 'state' output عند إنشاء واجهة 'Interface'.

انظر مثال الدردشة الآلية أدناه:

```py
import random

import gradio as gr


def chat(message, history):
    history = history or []
    if message.startswith("How many"):
        response = random.randint(1, 10)
    elif message.startswith("How"):
        response = random.choice(["Great", "Good", "Okay", "Bad"])
    elif message.startswith("Where"):
        response = random.choice(["Here", "There", "Somewhere"])
    else:
        response = "I don't know"
    history.append((message, response))
    return history, history


iface = gr.Interface(
    chat,
    ["text", "state"],
    ["chatbot", "state"],
    allow_screenshot=False,
    allow_flagging="never",
)
iface.launch()
```

لاحظ كيف تبقى حالة مكون الإخراج ثابتة عبر الإرسالات.

ملاحظة: يمكنك تمرير قيمة افتراضية إلى معامل الحالة، والتي يتم استخدامها كقيمة أولية للحالة.

## استخدام التفسير لفهم التنبؤات

معظم نماذج التعلم الآلي عبارة عن صناديق سوداء ومنطقها الداخلي مخفي عن المستخدم النهائي. لتشجيع الشفافية، جعلناه سهلاً للغاية لإضافة التفسير إلى نموذجك ببساطة عن طريق تعيين كلمة التفسير الأساسية في فئة الواجهة إلى الافتراضية. يتيح هذا للمستخدمين فهم أجزاء الإدخال المسؤولة عن الإخراج. الق نظرة على الواجهة البسيطة أدناه والتي تعرض مصنف الصور الذي يتضمن أيضًا التفسير:

```py
import requests
import tensorflow as tf

import gradio as gr

inception_net = tf.keras.applications.MobileNetV2() # تحميل النموذج

# تنزيل التسميات التي يمكن قراءتها بواسطة الإنسان لـ ImageNet.
response = requests.get("https://git.io/JJkYN")
labels = response.text.split("\n")


def classify_image(inp):
    inp = inp.reshape((-1, 224, 224, 3))
    inp = tf.keras.applications.mobilenet_v2.preprocess_input(inp)
    prediction = inception_net.predict(inp).flatten()
    return {labels[i]: float(prediction[i]) for i in range(1000)}


image = gr.Image(shape=(224, 224))
label = gr.Label(num_top_classes=3)

title = "مثال Gradio على تصنيف الصور + التفسير"
gr.Interface(
    fn=classify_image, inputs=image, outputs=label, interpretation="default", title=title
).launch()
```

اختبر دالة التفسير عن طريق إرسال إدخال ثم النقر فوق "Interpret" أسفل مكون الإخراج.

بالإضافة إلى طريقة التفسير الافتراضية التي يوفرها Gradio، يمكنك أيضًا تحديد `shap` لمعلمة `interpretation` وتعيين معلمة `num_shap`. يستخدم هذا التفسير القائم على Shapley، والذي يمكنك قراءة المزيد عنه [هنا](https://christophm.github.io/interpretable-ml-book/shap.html).

أخيرًا، يمكنك أيضًا تمرير دالة التفسير الخاصة بك إلى معلمة التفسير. راجع المثال في صفحة Gradio للبدء [هنا](https://gradio.app/getting_started/).

هذا يختتم غوصنا العميق في فئة "الواجهة" في Gradio. كما رأينا، تجعل هذه الفئة من السهل إنشاء عروض توضيحية للتعلم الآلي في بضع سطور من رمز Python. ومع ذلك، في بعض الأحيان، قد ترغب في تخصيص عرضك التوضيحي عن طريق تغيير التخطيط أو ربط وظائف التنبؤ المتعددة معًا. أليس من الرائع إذا كان بإمكاننا بطريقة ما تقسيم الواجهة إلى "كتل" قابلة للتخصيص؟ لحسن الحظ، هناك! هذا هو موضوع القسم الأخير.