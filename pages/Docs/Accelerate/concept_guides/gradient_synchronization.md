# ูุฒุงููุฉ ุงูุชุฏุฑุฌ 

ุชุนูู ุงููุญุฏุฉ ุงูููุทูุฉ ุงูููุฒุนุฉ ูู PyTorch ูู ุฎูุงู ุงูุชูุงุตู ุฐูุงุจูุง ูุฅูุงุจูุง ุจูู ุฌููุน ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) ูู ูุธุงูู. ูุณุชุบุฑู ูุฐุง ุงูุชูุงุตู ููุชูุงุ ููุญุฏุซ ุงูุชุฃูุฏ ูู ูุนุฑูุฉ ุฌููุน ุงูุนูููุงุช ูุญุงูุงุช ุจุนุถูุง ุงูุจุนุถ ูู ููุงุท ุชุดุบูู ูุนููุฉ ุนูุฏ ุงุณุชุฎุฏุงู ูุญุฏุฉ `ddp`.

ุชุถุงู ููุงุท ุงูุชุดุบูู ูุฐู ุฅูู ูููุฐุฌ PyTorchุ ูุชุญุฏูุฏูุง ุฅูู ุทุฑููุชู `forward()` ู`backward()` ุงูุฎุงุตุชูู ุจูุง. ูุญุฏุซ ูุฐุง ุนูุฏูุง ูุชู ูู ุงููููุฐุฌ ุจุงุณุชุฎุฏุงู `DistributedDataParallel`:

```python
import torch.nn as nn
from torch.nn.parallel import DistributedDataParallel

model = nn.Linear(10, 10)
ddp_model = DistributedDataParallel(model)
```

ูู ๐ค Accelerateุ ูุญุฏุซ ูุฐุง ุงูุชุญููู ุชููุงุฆููุง ุนูุฏ ุงุณุชุฏุนุงุก [`~Accelerator.prepare`] ูุฅุฏุฎุงู ูููุฐุฌู.

```diff
+ from accelerate import Accelerator
+ accelerator = Accelerator()
  import torch.nn as nn
- from torch.nn.parallel import DistributedDataParallel

  model = nn.Linear(10,10)
+ model = accelerator.prepare(model)
```

## ุงูุชุจุงุทุค ูู ุชุฑุงูู ุงูุชุฏุฑุฌุงุช

ุงูุขูุ ุฃูุช ุชููู ุฃู PyTorch ุชุถูู ุฎุทุงูุงุช ุฅูู ุทุฑููุฉ `forward` ู`backward` ููููุฐุฌ PyTorch ุงูุฎุงุต ุจู ุนูุฏ ุงูุชุฏุฑูุจ ูู ุฅุนุฏุงุฏ ููุฒุน. ูููู ููู ูููู ุฃู ูุคุฏู ูุฐุง ุฅูู ุฅุจุทุงุก ุงูููุฏ ุงูุฎุงุต ุจูุ

ูู DDP (ุงูุจูุงูุงุช ุงูููุฒุนุฉ ุงููุชูุงุฒูุฉ)ุ ููุชููุน ุงูุชุฑุชูุจ ุงููุญุฏุฏ ุงูุฐู ูุชู ููู ุชูููุฐ ุงูุนูููุงุช ูุชุดุบูููุง ูู ููุงุท ูุนููุฉุ ููุฌุจ ุฃูุถูุง ุฃู ุชุญุฏุซ ูุฐู ุงูููุงุท ุชูุฑูุจูุง ูู ููุณ ุงูููุช ูุจู ุงููุชุงุจุนุฉ.

ูุฃูุถุญ ูุซุงู ุนูู ุฐูู ูู ุนูุฏ ุชุญุฏูุซ ูุนููุงุช ุงููููุฐุฌ ูู ุฎูุงู `optimizer.step()`.

ุจุฏูู ุชุฑุงูู ุงูุชุฏุฑุฌุ ูุฌุจ ุฃู ูููู ูุฏู ุฌููุน ูุซููุงุช ุงููููุฐุฌ ุชุญุฏูุซ ุชุฏุฑุฌุงุชูุง ุงููุญุณูุจุฉ ูุงููุฌููุนุฉ ูุงููุญุฏุซุฉ ูุจู ุงูุงูุชูุงู ุฅูู ุงูุฏูุนุฉ ุงูุชุงููุฉ ูู ุงูุจูุงูุงุช.

ุนูุฏ ุชูููุฐ ุชุฑุงูู ุงูุชุฏุฑุฌุ ุชููู ุจุชุฑุงูู ุชุฏุฑุฌุงุช ููุฏุงู `n` ูุชุฎุทู `optimizer.step()` ุญุชู ูุชู ุงููุตูู ุฅูู `n` ุฏูุนุงุช. ูุธุฑูุง ูุฃู ุฌููุน ุนูููุงุช ุงูุชุฏุฑูุจ ุชุญุชุงุฌ ููุท ุฅูู ูุฒุงููุฉ ุงูููุช ุงูุฐู ูุชู ููู ุงุณุชุฏุนุงุก `optimizer.step()`ุ ุฏูู ุฃู ุชุนุฏูู ุนูู ุฎุทูุฉ ุงูุชุฏุฑูุจ ุงูุฎุงุตุฉ ุจูุ ูููู ุฃู ูุชุณุจุจ ูุฐุง ุงูุชูุงุตู ุบูุฑ ุงูุถุฑูุฑู ุจูู ุงูุนูููุงุช ูู ุญุฏูุซ ุชุจุงุทุค ูุจูุฑ.

ููู ููููู ุชุฌูุจ ูุฐู ุงููููุงุช ุงูุนุงูุฉุ

## ุญู ูุดููุฉ ุงูุชุจุงุทุค

ูุธุฑูุง ูุฃูู ุชููู ุจุชุฎุทู ุชุญุฏูุซุงุช ูุนููุงุช ุงููููุฐุฌ ุนูุฏ ุงูุชุฏุฑูุจ ุนูู ูุฐู ุงูุฏูุนุงุชุ ููุง ููุฒู ูุฒุงููุฉ ุชุฏุฑุฌุงุชูุง ุญุชู ุงูููุทุฉ ุงูุชู ูุชู ูููุง ุงุณุชุฏุนุงุก `optimizer.step()` ุจุงููุนู.

ูุง ูููู ูู PyTorch ุฃู ูุฎุจุฑู ุชููุงุฆููุง ุนูุฏูุง ุชุญุชุงุฌ ุฅูู ุงูููุงู ุจุฐููุ ููููู ูููุฑ ุฃุฏุงุฉ ูุณุงุนุฏุฉ ูู ุฎูุงู ูุฏูุฑ ุงูุณูุงู [`no_sync`](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel.no_sync)

ุงูุฐู ุชูุช ุฅุถุงูุชู ุฅูู ูููุฐุฌู ุจุนุฏ ุชุญูููู ุฅูู DDP.

ุถูู ูุฏูุฑ ุงูุณูุงู ูุฐุงุ ุณุชุชุฎุทู PyTorch ูุฒุงููุฉ ุงูุชุฏุฑุฌุงุช ุนูุฏ ุงุณุชุฏุนุงุก `.backward()`ุ ูุณูุคุฏู ุฃูู ุงุณุชุฏุนุงุก ูู `.backward()` ุฎุงุฑุฌ ูุฏูุฑ ุงูุณูุงู ูุฐุง ุฅูู ุชุดุบูู ุงููุฒุงููุฉ. ุฑุงุฌุน ุงููุซุงู ุฃุฏูุงู:

```python
ddp_model, dataloader, optimizer = accelerator.prepare(model, dataloader, optimizer)

for index, batch in enumerate(dataloader):
    inputs, targets = batch
    # Trigger gradient synchronization on the last batch
    if index != (len(dataloader) - 1):
        with ddp_model.no_sync():
            # Gradients only accumulate
            outputs = ddp_model(inputs)
            loss = loss_func(outputs)
            accelerator.backward(loss)
    else:
        # Gradients finally sync
        outputs = ddp_model(inputs)
        loss = loss_func(outputs)
        accelerator.backward(loss)
        optimizer.step()
```

ูู ๐ค Accelerate ูุฌุนู ูุฐุง ูุงุฌูุฉ ุจุฑูุฌุฉ ุชุทุจููุงุช ูููู ุงุณุชุฏุนุงุคูุง ุจุบุถ ุงููุธุฑ ุนู ุฌูุงุฒ ุงูุชุฏุฑูุจ (ุนูู ุงูุฑุบู ูู ุฃูู ูุฏ ูุง ููุนู ุฃู ุดูุก ุฅุฐุง ูู ุชูู ูู ูุธุงู ููุฒุน!)ุ ูุชู ุงุณุชุจุฏุงู `ddp_model.no_sync` ุจู [`~Accelerator.no_sync`] ููุนูู ุจููุณ ุงูุทุฑููุฉ:

```diff
  ddp_model, dataloader, optimizer = accelerator.prepare(model, dataloader, optimizer)

  for index, batch in enumerate(dataloader):
      inputs, targets = batch
      # Trigger gradient synchronization on the last batch
      if index != (len(dataloader)-1):
-         with ddp_model.no_sync():
+         with accelerator.no_sync(model):
              # Gradients only accumulate
              outputs = ddp_model(inputs)
              loss = loss_func(outputs, targets)
              accelerator.backward(loss)
      else:
          # Gradients finally sync
          outputs = ddp_model(inputs)
          loss = loss_func(outputs)
          accelerator.backward(loss)
          optimizer.step()
          optimizer.zero_grad()
```

ููุง ุชุชููุนุ ูุฅู ุฏุงูุฉ [`~Accelerator.accumulate`] ุชุญูุท ุจูุฐุง ุงููุญุต ุงูุดุฑุทู ูู ุฎูุงู ูุชุงุจุนุฉ ุฑูู ุงูุฏูุนุฉ ุงูุญุงููุ ููุง ูุชุฑูู ุจูุงุฌูุฉ ุจุฑูุฌุฉ ุชุทุจููุงุช ุชุฑุงูู ุงูุชุฏุฑุฌ ุงูููุงุฆูุฉ:

```python
ddp_model, dataloader, optimizer = accelerator.prepare(model, dataloader, optimizer)

for batch in dataloader:
    with accelerator.accumulate(model):
        optimizer.zero_grad()
        inputs, targets = batch
        outputs = model(inputs)
        loss = loss_function(outputs, targets)
        accelerator.backward(loss)
        optimizer.step()
        optimizer.zero_grad()
```

ููุชูุฌุฉ ูุฐููุ ูุฌุจ ุนููู ุฅูุง ุงุณุชุฎุฏุงู *`accelerator.accumulate` ุฃู `accelerator.no_sync`* ุนูุฏูุง ูุชุนูู ุงูุฃูุฑ ุจุฎูุงุฑ ูุงุฌูุฉ ุจุฑูุฌุฉ ุงูุชุทุจููุงุช.

## ุฅูู ุฃู ูุฏู ูุญุฏุซ ุงูุชุจุงุทุคุ ูุงูุฃุฎุทุงุก ุงูุดุงุฆุนุฉ ุงูุชู ููููู ุงุฑุชูุงุจูุง

ูุฅุนุฏุงุฏ ูุซุงู ูุงูุนูุ ุถุน ูู ุงุนุชุจุงุฑู ุงูุฅุนุฏุงุฏ ุงูุชุงูู:

- ุนูุฏุชุงู ูู GPU ูุงุญุฏุฉ ููุญุฏุฉ ูุนุงูุฌุฉ ูุฑูุฒูุฉ (CPU) ูุงุญุฏุฉ ูุนูุฏุฉ ูุงุญุฏุฉ ุจูุง ูุญุฏุชุง GPU
- ูู GPU ุนุจุงุฑุฉ ุนู T4ุ ููุชู ุงุณุชุถุงูุชูุง ุนูู GCP
- ุงููุต ุงูุจุฑูุฌู ุงููุณุชุฎุฏู ูู ุชุนุฏูู ููุต ุงูุจุฑูุงูุฌ ุงููุตู [NLP Example](https://github.com/muellerzr/timing_experiments/blob/main/baseline.py)
- ุญุฌู ุงูุฏูุนุฉ ููู GPU ูู 16ุ ููุชู ุชุฑุงูู ุงูุชุฏุฑุฌุงุช ูู 4 ุฎุทูุงุช

ุชุชููุฑ ุฌููุน ุงููุตูุต ุงูุจุฑูุฌูุฉ ูู [ูุฐุง ุงููุณุชูุฏุน](https://github.com/muellerzr/timing_experiments).

ุฅุฐุง ูู ุชูู ุญุฐุฑูุง ุจุดุฃู ูุฒุงููุฉ ุงูุชุฏุฑุฌ ูุชูุงุตู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU)ุ ููููู ุฃู ูุถูุน ูุฏุฑ *ูุจูุฑ* ูู ุงูููุช ุนูุฏูุง ุชุชูุงุตู ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณูููุงุช ูุฐู ูุน ุจุนุถูุง ุงูุจุนุถ ุฎูุงู ุงููุชุฑุงุช ุบูุฑ ุงูุถุฑูุฑูุฉ.

ุจุฃู ูุฏุฑุ

ูุฑุงุฌุน:

- Baseline: ูุง ุชุณุชุฎุฏู ููุงุฑุณุงุช ุงููุฒุงููุฉ ุงูุชู ุชูุช ููุงูุดุชูุง ููุง
- `no_sync` ุจุดูู ุบูุฑ ุตุญูุญ: `no_sync` ููุท ุญูู ุงุณุชุฏุนุงุก `backward`ุ ูููุณ `forward`
- `no_sync`: ุงุณุชุฎุฏุงู ููุท `no_sync` ุจุดูู ุตุญูุญ
- `accumulate`: ุงุณุชุฎุฏุงู [`~Accelerator.accumulate`] ุจุดูู ุตุญูุญ

ูููุง ููู ูุชูุณุท ุนุฏุฏ ุงูุซูุงูู ููู ุฏูุนุฉ ุฃุซูุงุก ุงูุชููู ุฎูุงู 29 ุฏูุนุฉ ูู ุงูุจูุงูุงุช ููู ุฅุนุฏุงุฏ ููู ูู ุงูุฅุนุฏุงุฏ ุฃุญุงุฏู ุงูุนูุฏุฉ ูุงูุฅุนุฏุงุฏ ุซูุงุฆู ุงูุนูุฏุฉ:

|             | Baseline  | `no_sync` ุจุดูู ุบูุฑ ุตุญูุญ | `no_sync` | `accumulate`|
| :---------: | :-------: | :------------------: | :-------: | :---------: |
| Multi-Node  | 2ยฑ0.01s    | 2.13ยฑ0.08s | **0.91ยฑ0.11s** | **0.91ยฑ0.11s** |
| Single Node | 0.50ยฑ0.01s | 0.50ยฑ0.01s | **0.41ยฑ0.015s** | **0.41ยฑ0.015s** |

ููุง ุชุฑููุ ุฅุฐุง ูู ุชูู ุญุฐุฑูุง ุจุดุฃู ููููุฉ ุฅุนุฏุงุฏ ูุฒุงููุฉ ุงูุชุฏุฑุฌ ุงูุฎุงุต ุจูุ ูููููู ุงูุญุตูู ุนูู ุชุจุงุทุค ูุฒูุฏ ุนู ุถุนู ุงูุณุฑุนุฉ ุฃุซูุงุก ุงูุชุฏุฑูุจ!

ุฅุฐุง ููุช ููููุง ุจุดุฃู ุงูุชุฃูุฏ ูู ุงูููุงู ุจูู ุดูุก ุจุดูู ุตุญูุญุ ููุญู ููุตู ุจุดุฏุฉ ุจุงุณุชุฎุฏุงู ุฏุงูุฉ [`~Accelerator.accumulate`] ูุฅุฏุฎุงู
`gradient_accumulation_steps` ุฃู `gradient_accumulation_plugin` ูู ูุงุฆู [`Accelerator`] ุญุชู ูุชููู Accelerate ูู ุงูุชุนุงูู ูุน ุฐูู ููุงุจุฉ ุนูู.

### ูุชุทูุจ `no_sync` ุฐุงูุฑุฉ GPU ุฅุถุงููุฉ ุนูุฏ ุงุณุชุฎุฏุงู FSDP

ูู ุนูู ุนูู ุจุฃู ุนุฏู ูุฒุงููุฉ ุงูุชุฏุฑุฌุงุช ูููู ุฃู ูููู ูู ุขุซุงุฑ ุถุงุฑุฉ ุฃุซูุงุก ุงูุชุฏุฑูุจ ุจุงุณุชุฎุฏุงู FSDP. ููุง ูู ูุญุฐุฑ ูู `torch`ุ ูุฅู [ูุฏูุฑ ุณูุงู `no_sync` ูู FSDP](https://pytorch.org/docs/stable/fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.no_sync) ุณูุชุทูุจ ุฐุงูุฑุฉ ุฅุถุงููุฉ.

ูุฐููุ ูู ุงูููุงูู ูุซูุฑุฉ ุงูุงุณุชุฎุฏุงู ููุฐุงูุฑุฉ ุฃุซูุงุก ุงุณุชุฎุฏุงู FSDPุ ููุตู ุจุชุนููู `sync_each_batch` ุฅูู `True` ูู [`~utils.GradientAccumulationPlugin`] ูุชุนุทูู `no_sync`.

ุฑุงุฌุน ุงููุซุงู ุฃุฏูุงู ุญูุซ ูููู ุจุชุฏุฑูุจ ูููุฐุฌ Mixtral (47 ูููุงุฑ ูุนููุฉ) ุนูู 8 ูุญุฏุงุช ูุนุงูุฌุฉ ุฑุณููุงุช A100-80 ุฌูุฌุงุจุงูุช. ููุงุญุธ ุฃูู ุญุชู ุจุงููุณุจุฉ ูู `gradient_accumulation_steps=2` ุงููุชูุงุถุนุ ูุฅููุง ูุชุนุฑุถ ุจุณุฑุนุฉ ูุชุฌุงูุฒ ุณุนุฉ ุงูุฐุงูุฑุฉ (OOM) ุฅุฐุง ุชู ุชูููู `no_sync`. ููุฑุฌุน ุฐูู ูุฑุฉ ุฃุฎุฑู ุฅูู ุงููููุงุช ุงูุนุงูุฉ ุงูุฅุถุงููุฉ ููุฐุงูุฑุฉ ุจุณุจุจ `no_sync` ูู FSDP. ููุน ุฐููุ ุฅุฐุง ุชู ุชุนุทูู `no_sync` ุนู ุทุฑูู `sync_each_batch=True`ุ ูุฅู ุงุณุชููุงู ุงูุฐุงูุฑุฉ ูู `gradient_accumulation_steps=16` ูุนูุฏ ุฅูู ูุง ูุงู ุนููู ูู `gradient_accumulation_steps=1`.

| ุงููููุฐุฌ           | `no_sync` (accum=1) | `no_sync` (accum=2) | `no_sync` ูุนุทู (accum=16)
| :-------------: | :-----------------: | :-----------------: | :-----------------:
mixtral 8x7B      | 69 ุฌูุฌุง ุจุงูุช                 | ุชุฌุงูุฒ ุณุนุฉ ุงูุฐุงูุฑุฉ                 | 69 ุฌูุฌุง ุจุงูุช
> [!ุชุญุฐูุฑ]
> ุชุนุทูู `no_sync` ูุนูู ุฃูู _ุณูููู ููุงู ุชุจุงุทุค_ ุจุณุจุจ ุนูููุงุช ูุฒุงููุฉ ุงูุจูุงูุงุช ุงูุฅุถุงููุฉุ ููุง ูู ููุถุญ ูู ุงูุฃูุณุงู ุงูุณุงุจูุฉ ูู ูุฐุง ุงูุฏููู.