# ุงูุถุจุท ุงูููู 

## ุชูุงูู `bitsandbytes` 

๐ค Accelerate ูุฌูุจ ุงูุถุจุท ุงูููู `bitsandbytes` ุฅูู ูููุฐุฌู. ููููู ุงูุขู ุชุญููู ุฃู ูููุฐุฌ PyTorch ุจ8 ุจุชุงุช ุฃู 4 ุจุชุงุช ูู ุจุถุน ุณุทูุฑ ูู ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ. 

ุฅุฐุง ููุช ุชุฑูุฏ ุงุณุชุฎุฏุงู ููุงุฐุฌ ๐ค Transformers ูุน `bitsandbytes`ุ ููุฌุจ ุนููู ุงุชุจุงุน ูุฐู [ุงููุซุงุฆู](https://huggingface.co/docs/transformers/main_classes/quantization). 

ููุนุฑูุฉ ุงููุฒูุฏ ุนู ููููุฉ ุนูู ุงูุถุจุท ุงูููู `bitsandbytes`ุ ุงุทูุน ุนูู ุงูููุดูุฑุงุช ุนูู ุงููุฏููุฉ ุญูู ุงูุถุจุท ุงูููู [8-ุจุช](https://huggingface.co/blog/hf-bitsandbytes-integration) ู [4-ุจุช](https://huggingface.co/blog/4bit-transformers-bitsandbytes). 

### ุงููุชุทูุจุงุช ุงูุฃุณุงุณูุฉ 

ุณุชุญุชุงุฌ ุฅูู ุชุซุจูุช ุงููุชุทูุจุงุช ุงูุชุงููุฉ: 

- ุชุซุจูุช ููุชุจุฉ `bitsandbytes`

```bash
pip install bitsandbytes
```

- ุชุซุจูุช ุฃุญุฏุซ ุฅุตุฏุงุฑ ูู `accelerate` ูู ุงููุตุฏุฑ

```bash
pip install git+https://github.com/huggingface/accelerate.git
```

- ุชุซุจูุช `minGPT` ู `huggingface_hub` ูุชุดุบูู ุงูุฃูุซูุฉ

```bash
git clone https://github.com/karpathy/minGPT.git
pip install minGPT/
pip install huggingface_hub
```

### ููููุฉ ุนููู 

ุฃููุงูุ ูุญุชุงุฌ ุฅูู ุชููุฆุฉ ูููุฐุฌูุง. ูุชูููุฑ ุงูุฐุงูุฑุฉุ ูููููุง ุชููุฆุฉ ูููุฐุฌ ูุงุฑุบ ุจุงุณุชุฎุฏุงู ูุฏูุฑ ุงูุณูุงู [`init_empty_weights`]. 

ููุฃุฎุฐ ูููุฐุฌ GPT2 ูู ููุชุจุฉ minGPT ููุซุงู.

```py
from accelerate import init_empty_weights
from mingpt.model import GPT

model_config = GPT.get_default_config()
model_config.model_type = 'gpt2-xl'
model_config.vocab_size = 50257
model_config.block_size = 1024

with init_empty_weights():
    empty_model = GPT(model_config)
``` 

ุจุนุฏ ุฐููุ ูุญุชุงุฌ ุฅูู ุงูุญุตูู ุนูู ุงููุณุงุฑ ุฅูู ุฃูุฒุงู ูููุฐุฌู. ูููู ุฃู ูููู ุงููุณุงุฑ ููู ุญุงูุฉ (ูุซู "pytorch_model.bin") ุฃู ูุฌูุฏ ูุญุชูู ุนูู ููุงุท ุชูุชูุด ูุฌุฒุฃุฉ. 

```py
from huggingface_hub import snapshot_download
weights_location = snapshot_download(repo_id="marcsun13/gpt2-xl-linear-sharded")
``` 

ุฃุฎูุฑูุงุ ุชุญุชุงุฌ ุฅูู ุชุนููู ุชูููู ุงูุถุจุท ุงูููู ุงูุฎุงุต ุจู ุจุงุณุชุฎุฏุงู [`~utils.BnbQuantizationConfig`]. 

ูููุง ููู ูุซุงู ุนูู ุงูุถุจุท ุงูููู 8-ุจุช:

```py
from accelerate.utils import BnbQuantizationConfig
bnb_quantization_config = BnbQuantizationConfig(load_in_8bit=True, llm_int8_threshold = 6)
``` 

ูููุง ููู ูุซุงู ุนูู ุงูุถุจุท ุงูููู 4-ุจุช:

```py
from accelerate.utils import BnbQuantizationConfig
bnb_quantization_config = BnbQuantizationConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.bfloat16, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type="nf4")
``` 

ูุถุจุท ูููุฐุฌู ุงููุงุฑุบ ุจุงุณุชุฎุฏุงู ุงูุชูููู ุงููุญุฏุฏุ ุชุญุชุงุฌ ุฅูู ุงุณุชุฎุฏุงู [`~utils.load_and_quantize_model`]. 

```py
from accelerate.utils import load_and_quantize_model
quantized_model = load_and_quantize_model(empty_model, weights_location=weights_location, bnb_quantization_config=bnb_quantization_config, device_map = "auto")
```

### ุญูุธ ูุชุญููู ุงููููุฐุฌ 8-ุจุช 

ููููู ุญูุธ ูููุฐุฌ 8-ุจุช ุงูุฎุงุต ุจู ุจุงุณุชุฎุฏุงู Accelerate ุจุงุณุชุฎุฏุงู [`~Accelerator.save_model`]. 

```py
from accelerate import Accelerator
accelerate = Accelerator()
new_weights_location = "path/to/save_directory"
accelerate.save_model(quantized_model, new_weights_location)

quantized_model_from_saved = load_and_quantize_model(empty_model, weights_location=new_weights_location, bnb_quantization_config=bnb_quantization_config, device_map = "auto")
``` 

ููุงุญุธุฉ: ูุง ูุชู ุฏุนู ุชุณูุณู ูููุฐุฌ 4-ุจุช ุญุงูููุง. 

### ููู ุงููุญุฏุงุช ุงูููุทูุฉ ุฅูู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ ูุงููุฑุต 

ููููู ููู ุจุนุถ ุงููุญุฏุงุช ุงูููุทูุฉ ุฅูู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ/ุงููุฑุต ุฅุฐุง ูู ููู ูุฏูู ูุณุงุญุฉ ูุงููุฉ ุนูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU) ูุชุฎุฒูู ุงููููุฐุฌ ุจุงููุงูู ุนูู ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณููุงุช ุงูุฎุงุตุฉ ุจู. 

ูุณุชุฎุฏู ูุฐุง ุงูููู ุงููุญุฏุงุช ุงูููุทูุฉ ุฅูู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ ูุงููุฑุต ูู ุงูุงุณุชุฏูุงู ุจุงุณุชุฎุฏุงู ุงูููุงุฐุฌ ุงููุจูุฑุฉ. ุฑุงุฌุน ูุฐู [ุงููุซุงุฆู](https://huggingface.co/docs/accelerate/usage_guides/big_modeling) ููุฒูุฏ ูู ุงูุชูุงุตูู. 

ุจุงููุณุจุฉ ููุถุจุท ุงูููู 8-ุจุชุ ุณูุชู ุชุญููู ุงููุญุฏุงุช ุงูููุทูุฉ ุงููุญุฏุฏุฉ ุฅูู ุฏูุฉ 8-ุจุช. 

ุจุงููุณุจุฉ ููุถุจุท ุงูููู 4-ุจุชุ ุณูุชู ุงูุงุญุชูุงุธ ุจุงููุญุฏุงุช ุงูููุทูุฉ ุงููุญุฏุฏุฉ ูู `torch_dtype` ุงูุชู ูุฑุฑูุง ุงููุณุชุฎุฏู ูู `BnbQuantizationConfig`. ุณูุถูู ุฏุนููุง ูุชุญููู ูุฐู ุงููุญุฏุงุช ุงูููุทูุฉ ุงููููููุฉ ุฅูู 4-ุจุช ุนูุฏูุง ูุตุจุญ ุงูุชุณูุณู 4-ุจุช ูููููุง. 

ูู ูุง ุนููู ูุนูู ูู ุชูุฑูุฑ ุฎุฑูุทุฉ ุฃุฌูุฒุฉ ูุฎุตุตุฉ ูููู ุงููุญุฏุงุช ุงูููุทูุฉ ุฅูู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ/ุงููุฑุต. ุณูุชู ุฅุฑุณุงู ุงููุญุฏุงุช ุงูููุทูุฉ ุงููููููุฉ ุฅูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช ุนูุฏ ุงูุญุงุฌุฉ. ูููุง ููู ูุซุงู: 

```py
device_map = {
    "transformer.wte": 0,
    "transformer.wpe": 0,
    "transformer.drop": 0,
    "transformer.h": "cpu",
    "transformer.ln_f": "disk",
    "lm_head": "disk",
}
```

### ุถุจุท ูููุฐุฌ ูุถุจูุท ุจุฏูุฉ 

ูุง ูููู ุฅุฌุฑุงุก ุชุฏุฑูุจ 8 ุจุชุงุช ุฃู 4 ุจุชุงุช ููู ุนูู ูุฐู ุงูููุงุฐุฌ. ููุน ุฐููุ ููููู ุชุฏุฑูุจ ูุฐู ุงูููุงุฐุฌ ูู ุฎูุงู ุงูุงุณุชูุงุฏุฉ ูู ุทุฑู ุงูุถุจุท ุงูุฏููู ุงููุนุงูุฉ ูููุนุงูู (PEFT) ูุชุฏุฑูุจ ูุญููุงุชุ ุนูู ุณุจูู ุงููุซุงูุ ุฃุนูู ูููุง. ูุฑุฌู ุงูุงุทูุงุน ุนูู ููุชุจุฉ [peft](https://github.com/huggingface/peft) ููุฒูุฏ ูู ุงูุชูุงุตูู. 

ุญุงูููุงุ ูุง ููููู ุฅุถุงูุฉ ูุญููุงุช ุฃุนูู ุฃู ูููุฐุฌ ูุถุจูุท. ููุน ุฐููุ ูุน ุงูุฏุนู ุงูุฑุณูู ูููุญููุงุช ูุน ููุงุฐุฌ ๐ค Transformersุ ููููู ุถุจุท ุงูููุงุฐุฌ ุงููุถุจูุทุฉ. ุฅุฐุง ููุช ุชุฑูุฏ ุถุจุท ูููุฐุฌ ๐ค Transformersุ ูุงุชุจุน ูุฐู [ุงููุซุงุฆู](https://huggingface.co/docs/transformers/main_classes/quantization) ุจุฏูุงู ูู ุฐูู. ุงุทูุน ุนูู ูุฐุง [ุงูุนุฑุถ ุงูุชูุถูุญู](https://colab.research.google.com/drive/1VoYNfYDKcKRQRor98Zbf2-9VQTtGJ24k?usp=sharing) ุญูู ููููุฉ ุถุจุท ูููุฐุฌ ๐ค Transformers 4-ุจุช. 

ููุงุญุธุฉ: ูุง ุชุญุชุงุฌ ุฅูู ุชูุฑูุฑ `device_map` ุนูุฏ ุชุญููู ุงููููุฐุฌ ููุชุฏุฑูุจ. ุณูููู ุจุชุญููู ุงููููุฐุฌ ุชููุงุฆููุง ุนูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช ุงูุฎุงุตุฉ ุจู. ูุฑุฌู ููุงุญุธุฉ ุฃูู ูุฌุจ ุงุณุชุฎุฏุงู `device_map=auto` ููุงุณุชุฏูุงู ููุท. 

### ูุซุงู ุชูุถูุญู - ุชุดุบูู GPT2 1.5b ุนูู Google Colab 

ุงุทูุน ุนูู ุงูุนุฑุถ ุงูุชูุถูุญู ูู Google Colab [demo](https://colab.research.google.com/drive/1T1pOgewAWVpR9gKpaEWw4orOrzPFb3yM?usp=sharing) ูุชุดุบูู ุงูููุงุฐุฌ ุงููุถุจูุทุฉ ุนูู ูููุฐุฌ GTP2. ููุทุฉ ุชูุชูุด ูููุฐุฌ GPT2-1.5B ูู FP32 ุงูุชู ุชุณุชุฎุฏู 6 ุฌูุฌุงุจุงูุช ูู ุงูุฐุงูุฑุฉ. ุจุนุฏ ุงูุถุจุทุ ูุณุชุฎุฏู 1.6 ุฌูุฌุงุจุงูุช ูุน ูุญุฏุงุช 8 ุจุชุงุช ู 1.2 ุฌูุฌุงุจุงูุช ูุน ูุญุฏุงุช 4 ุจุชุงุช.