# ุงููููุฐุฌ ุงููุชูุงุฒู ููุจูุงูุงุช ุงููุฌุฒุฃุฉ ุจุงููุงูู

ูุชุณุฑูุน ุชุฏุฑูุจ ุงูููุงุฐุฌ ุงูุถุฎูุฉ ุจุงุณุชุฎุฏุงู ุฃุญุฌุงู ุฏูุนุงุช ุฃูุจุฑุ ูููููุง ุงุณุชุฎุฏุงู ูููุฐุฌ ูุชูุงุฒู ููุจูุงูุงุช ูุฌุฒุฃ ุจุงููุงูู. ููููู ูุฐุง ุงูููุน ูู ุงูููุงุฐุฌ ุงููุชูุงุฒูุฉ ููุจูุงูุงุช ูู ููุงุกูุฉ ุงููุฒูุฏ ูู ุงูุจูุงูุงุช ูุงูููุงุฐุฌ ุงูุฃูุจุฑ ุนู ุทุฑูู ุชุฌุฒุฆุฉ ุญุงูุงุช ุงููุญุณู ูุงูุชุฏุฑุฌุงุช ูุงููุณุงุฆุท.

ููุนุฑูุฉ ุงููุฒูุฏ ุญูู ุฐูู ูุงููุฒุงูุงุ ุชุญูู ูู [ูุฏููุฉ ุงููููุฐุฌ ุงููุชูุงุฒู ููุจูุงูุงุช ุงููุฌุฒุฃุฉ ุจุงููุงูู](https://pytorch.org/blog/introducing-pytorch-fully-sharded-data-parallel-api/).

ููุฏ ูููุง ุจุชูุงูู ุฃุญุฏุซ ููุฒุฉ ุชุฏุฑูุจ PyTorch's Fully Sharded Data Parallel (FSDP). ูู ูุง ุนููู ูุนูู ูู ุชููููู ูู ุฎูุงู config.

## ููู ูุนูู ุฎุงุฑุฌ ุงูุตูุฏูู

ูู ุจุจุณุงุทุฉ ุจุชุดุบูู ูุง ููู ุนูู ุขูุชู (ุขูุงุชู):

```bash
accelerate config
```

ูุงูุฅุฌุงุจุฉ ุนู ุงูุฃุณุฆูุฉ ุงููุทุฑูุญุฉ. ุณูุคุฏู ูุฐุง ุฅูู ุฅูุดุงุก ููู ุชูููู ุณูุชู ุงุณุชุฎุฏุงูู ุชููุงุฆููุง ูุชุนููู ุงูุฎูุงุฑุงุช ุงูุงูุชุฑุงุถูุฉ ุจุดูู ุตุญูุญ ุนูุฏ ุงูููุงู ุจูุง ููู:

```bash
accelerate launch my_script.py --args_to_my_script
```

ุนูู ุณุจูู ุงููุซุงูุ ูููุง ููู ููููุฉ ุชุดุบูู `examples/nlp_example.py` (ูู ุงูุฌุฐุฑ ุงูุฎุงุต ุจุงููุณุชูุฏุน) ูุน ุชูููู FSDP:

```bash
compute_environment: LOCAL_MACHINE
debug: false
distributed_type: FSDP
downcast_bf16: 'no'
fsdp_config:
  fsdp_auto_wrap_policy: TRANSFORMER_BASED_WRAP
  fsdp_backward_prefetch_policy: BACKWARD_PRE
  fsdp_forward_prefetch: false
  fsdp_cpu_ram_efficient_loading: true
  fsdp_offload_params: false
  fsdp_sharding_strategy: FULL_SHARD
  fsdp_state_dict_type: SHARDED_STATE_DICT
  fsdp_sync_module_states: true
  fsdp_transformer_layer_cls_to_wrap: BertLayer
  fsdp_use_orig_params: true
machine_rank: 0
main_training_function: main
mixed_precision: bf16
num_machines: 1
num_processes: 2
rdzv_backend: static
same_network: true
tpu_env: []
tpu_use_cluster: false
tpu_use_sudo: false
use_cpu: false
```

```bash
accelerate launch examples/nlp_example.py
```

ูุฏุนู `Accelerate` ุญุงูููุง ุงูุชูููู ุงูุชุงูู ุนุจุฑ CLI:

`fsdp_sharding_strategy`: [1] FULL_SHARD (ุชุฌุฒุฆุฉ ุญุงูุงุช ุงููุญุณู ูุงูุชุฏุฑุฌุงุช ูุงููุณุงุฆุท)ุ [2] SHARD_GRAD_OP (ุชุฌุฒุฆุฉ ุญุงูุงุช ุงููุญุณู ูุงูุชุฏุฑุฌุงุช)ุ [3] NO_SHARD (DDP)ุ [4] HYBRID_SHARD (ุชุฌุฒุฆุฉ ุญุงูุงุช ุงููุญุณู ูุงูุชุฏุฑุฌุงุช ูุงููุณุงุฆุท ุฏุงุฎู ูู ุนูุฏุฉ ูู ุญูู ุฃู ููู ุนูุฏุฉ ูุณุฎุฉ ูุงููุฉ)ุ [5] HYBRID_SHARD_ZERO2 (ุชุฌุฒุฆุฉ ุญุงูุงุช ุงููุญุณู ูุงูุชุฏุฑุฌุงุช ุฏุงุฎู ูู ุนูุฏุฉ ูู ุญูู ุฃู ููู ุนูุฏุฉ ูุณุฎุฉ ูุงููุฉ). ููุฒูุฏ ูู ุงููุนูููุงุชุ ูุฑุฌู ุงูุฑุฌูุน ุฅูู ูุซุงุฆู PyTorch ุงูุฑุณููุฉ [ููุง](https://pytorch.org/docs/stable/fsdp.html#torch.distributed.fsdp.ShardingStrategy).

`fsdp_offload_params` : ููุฑุฑ ูุง ุฅุฐุง ูุงู ุณูุชู ููู ุงููุนููุงุช ูุงูุชุฏุฑุฌุงุช ุฅูู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ

`fsdp_auto_wrap_policy`: [1] TRANSFORMER_BASED_WRAPุ [2] SIZE_BASED_WRAPุ [3] NO_WRAP

`fsdp_transformer_layer_cls_to_wrap`: ููุทุจู ููุท ุนูู ๐ค Transformers. ุนูุฏูุง ูููู `fsdp_auto_wrap_policy=TRANSFORMER_BASED_WRAP`ุ ูููู ูููุณุชุฎุฏู ุชูููุฑ ุณูุณูุฉ ููุตููุฉ ุจููุงุตู ูุนูุงููู ูุฆุงุช ุทุจูุฉ ุงููุญูู (ูุน ูุฑุงุนุงุฉ ุญุงูุฉ ุงูุฃุญุฑู)ุ ูุซู `BertLayer`ุ `GPTJBlock`ุ `T5Block`ุ `BertLayerุBertEmbeddingsุBertSelfOutput`. ูุฐุง ููู ูุฃู ุงููุญุฏุงุช ุงููุฑุนูุฉ ุงูุชู ุชุดุชุฑู ูู ุงูุฃูุฒุงู (ูุซู ุทุจูุงุช ุงูุชุนูู) ูุฌุจ ุฃูุง ุชูุชูู ูู ูุญุฏุงุช FSDP ูุฎุชููุฉ. ุจุงุณุชุฎุฏุงู ูุฐู ุงูุณูุงุณุฉุ ูุญุฏุซ ุงูุชุบููู ููู ูุชูุฉ ุชุญุชูู ุนูู Attention ูุชุนุฏุฏ ุงูุฑุคูุณ ุชูููุง ุทุจูุงุช MLP. ูุชู ุชุบููู ุงูุทุจูุงุช ุงููุชุจููุฉ ุจูุง ูู ุฐูู ุงูุชุนูู ุงููุดุชุฑู ุจุดูู ููุงุณุจ ูู ููุณ ูุญุฏุฉ FSDP ุงูุฎุงุฑุฌูุฉ. ูุฐููุ ุงุณุชุฎุฏู ูุฐุง ููููุงุฐุฌ ุงููุณุชูุฏุฉ ุฅูู ุงููุญูู. ููููู ุงุณุชุฎุฏุงู `model._no_split_modules` ูู ๐ค Transformer models ูู ุฎูุงู ุงูุฅุฌุงุจุฉ ุจู "ูุนู" ุนูู "ูู ุชุฑูุฏ ุงุณุชุฎุฏุงู` _no_split_modules` ููุทุฑุงุฒุ" ุณูุญุงูู ุงุณุชุฎุฏุงู `model._no_split_modules` ุนูุฏ ุงูุฅููุงู.

`fsdp_min_num_params`: ุงูุญุฏ ุงูุฃุฏูู ูุนุฏุฏ ุงููุนููุงุช ุนูุฏ ุงุณุชุฎุฏุงู `fsdp_auto_wrap_policy=SIZE_BASED_WRAP`.

`fsdp_backward_prefetch_policy`: [1] BACKWARD_PREุ [2] BACKWARD_POSTุ [3] NO_PREFETCH

`fsdp_forward_prefetch`: ุฅุฐุง ูุงู ุตุญูุญูุงุ ูุณูููู FSDP ุจุดูู ุตุฑูุญ ุจุงุณุชุจุงู ุงูุชุฌููุน ุงูุชุงูู ุฃุซูุงุก ุงูุชูููุฐ ูู ุชูุฑูุฑ ุงูุฅุฑุณุงู. ูุฌุจ ุงุณุชุฎุฏุงูู ููุท ูููุงุฐุฌ ุงูุฑุณูู ุงูุจูุงููุฉ ุงูุซุงุจุชุฉ ูุธุฑูุง ูุฃู ุงูุงุณุชุจุงู ูุชุจุน ุชุฑุชูุจ ุงูุชูููุฐ ุงูุฎุงุต ุจุงูุชูุฑุงุฑ ุงูุฃูู. ุฃู ุฅุฐุง ุชู ุชุบููุฑ ุชุฑุชูุจ ุงููุญุฏุงุช ุงููุฑุนูุฉ ุฏููุงูููููุง ุฃุซูุงุก ุชูููุฐ ุงููููุฐุฌุ ููุง ุชูู ุจุชูููู ูุฐู ุงูููุฒุฉ.

`fsdp_state_dict_type`: [1] FULL_STATE_DICTุ [2] LOCAL_STATE_DICTุ [3] SHARDED_STATE_DICT

`fsdp_use_orig_params`: ุฅุฐุง ูุงู ุตุญูุญูุงุ ููุณูุญ ุจู `requires_grad` ุบูุฑ ุงูููุญุฏ ุฃุซูุงุก ุงูุชููุฆุฉุ ููุง ูุนูู ุฏุนููุง ูููุนููุงุช ุงููุฌูุฏุฉ ูุงููุงุจูุฉ ููุชุฏุฑูุจ ุงููุชูุงุซุฑุฉ. ูุฐุง ุงูุฅุนุฏุงุฏ ูููุฏ ูู ุญุงูุงุช ูุซู ุงูุถุจุท ุงูุฏููู ุงููุนุงู ูููุนููุงุช ููุง ูู ููุถุญ ูู [ูุฐู ุงููุดุงุฑูุฉ](https://dev-discuss.pytorch.org/t/rethinking-pytorch-fully-sharded-data-parallel-fsdp-from-first-principles/1019). ูุณูุญ ูุฐุง ุงูุฎูุงุฑ ุฃูุถูุง ุจูุฌูุฏ ุนุฏุฉ ูุฌููุนุงุช ูู ุงููุนููุงุช ุงููุญุณูุฉ. ูุฌุจ ุฃู ูููู ูุฐุง `True` ุนูุฏ ุฅูุดุงุก ูุญุณู ูุจู ุฅุนุฏุงุฏ/ุชุบููู ุงููููุฐุฌ ุจุงุณุชุฎุฏุงู FSDP.

`fsdp_cpu_ram_efficient_loading`: ููุทุจู ููุท ุนูู ููุงุฐุฌ ๐ค Transformers. ุฅุฐุง ูุงู ุตุญูุญูุงุ ูุฅู ุงูุนูููุฉ ุงูุฃููู ููุท ุชููู ุจุชุญููู ููุทุฉ ุชูุชูุด ุงููููุฐุฌ ุงููุณุจู ุงูุชุฏุฑูุจ ูู ุญูู ุฃู ุฌููุน ุงูุนูููุงุช ุงูุฃุฎุฑู ููุง ุฃูุฒุงู ูุงุฑุบุฉ. ูุฌุจ ุชุนููู ูุฐุง ุนูู false ุฅุฐุง ูุงุฌูุช ุฃุฎุทุงุก ุนูุฏ ุชุญููู ูููุฐุฌ ๐ค Transformers ุงููุณุจู ุงูุชุฏุฑูุจ ุนุจุฑ ุทุฑููุฉ `from_pretrained`. ุนูุฏูุง ูููู ูุฐุง ุงูุฅุนุฏุงุฏ ุตุญูุญูุงุ ูุฌุจ ุฃูุถูุง ุฃู ูููู `fsdp_sync_module_states` ุตุญูุญูุงุ ูุฅูุง ูุณุชููู ุฌููุน ุงูุนูููุงุช ุจุงุณุชุซูุงุก ุงูุนูููุฉ ุงูุฑุฆูุณูุฉ ุฐุงุช ุฃูุฒุงู ุนุดูุงุฆูุฉ ุชุคุฏู ุฅูู ุณููู ุบูุฑ ูุชููุน ุฃุซูุงุก ุงูุชุฏุฑูุจ. ููู ูุนูู ุฐููุ ุชุฃูุฏ ูู ุชููุฆุฉ ูุฌููุนุฉ ุงูุนูููุงุช ุงูููุฒุนุฉ ูุจู ุงุณุชุฏุนุงุก ุทุฑููุฉ `from_pretrained` ุงูุฎุงุตุฉ ุจู Transformers. ุนูุฏ ุงุณุชุฎุฏุงู ูุงุฌูุฉ ุจุฑูุฌุฉ ุชุทุจููุงุช ูุฏุฑุจ ๐คุ ูุชู ุชููุฆุฉ ูุฌููุนุฉ ุงูุนูููุงุช ุงูููุฒุนุฉ ุนูุฏ ุฅูุดุงุก ูุซูู ููุฆุฉ `TrainingArguments`.

`fsdp_sync_module_states`: ุฅุฐุง ูุงู ุตุญูุญูุงุ ูุณุชููู ูู ูุญุฏุฉ FSDP ูููููุฉ ุจุดูู ูุฑุฏู ุจุจุซ ูุนููุงุช ุงููุญุฏุฉ ุงูููุทูุฉ ูู ุงูุฑุชุจุฉ 0.

ููุญุตูู ุนูู ุชุญูู ุฅุถุงูู ูุฃูุซุฑ ุฏูุฉุ ููููู ุชุญุฏูุฏ ูุนููุงุช FSDP ุงูุฃุฎุฑู ุนุจุฑ `FullyShardedDataParallelPlugin`.

ุนูุฏ ุฅูุดุงุก ูุงุฆู `FullyShardedDataParallelPlugin`ุ ูู ุจุชูุฑูุฑู ุฅูู ุงููุนููุงุช ุงูุชู ูู ุชูู ุฌุฒุกูุง ูู ุชูููู ุงูุชุณุฑูุน ุฃู ุฅุฐุง ููุช ุชุฑูุฏ ุชุฌุงูุฒูุง.

ุณูุชู ุชุญุฏูุฏ ูุนููุงุช FSDP ุจูุงุกู ุนูู ููู ุชูููู ุงูุชุณุฑูุน ุฃู ุญุฌุฌ ุฃูุฑ ุงูุฅุทูุงูุ ูุณุชููู ุงููุนููุงุช ุงูุฃุฎุฑู ุงูุชู ุชููู ุจุชูุฑูุฑูุง ูุจุงุดุฑุฉู ูู ุฎูุงู ูุงุฆู `FullyShardedDataParallelPlugin` ุจุชุนููู/ุชุฌุงูุฒ ุฐูู.

ูููุง ููู ูุซุงู:

```py
from accelerate import FullyShardedDataParallelPlugin
from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig

fsdp_plugin = FullyShardedDataParallelPlugin(
    state_dict_config=FullStateDictConfig(offload_to_cpu=False, rank0_only=False),
    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=False, rank0_only=False),
)

accelerator = Accelerator(fsdp_plugin=fsdp_plugin)
```

## ุงูุญูุธ ูุงูุชุญููู

ุงูุทุฑููุฉ ุงูุฌุฏูุฏุฉ ุงูููุตู ุจูุง ูุฅูุดุงุก ููุทุฉ ุชูุชูุด ุนูุฏ ุงุณุชุฎุฏุงู ููุงุฐุฌ FSDP ูู ุงุณุชุฎุฏุงู `SHARDED_STATE_DICT` ูู `StateDictType` ุนูุฏ ุฅุนุฏุงุฏ ุชูููู ุงูุชุณุฑูุน.

ูููุง ููู ููุชุทู ูู ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ ูุญูุธ ุจุงุณุชุฎุฏุงู ุจุฑูุงูุฌ ุงููุณุงุนุฏุฉ `save_state` ูู Accelerate:

```py
accelerator.save_state("ckpt")
```

ุชููุฏ ูุฌูุฏ ููุทุฉ ุงูุชูุชูุด ูุฑุคูุฉ ุงููููุฐุฌ ูุงููุญุณู ูุดุธุงูุง ููู ุนูููุฉ:

```
ls ckpt
# optimizer_0  pytorch_model_0  random_states_0.pkl  random_states_1.pkl  scheduler.bin

cd ckpt

ls optimizer_0
# __0_0.distcp  __1_0.distcp

ls pytorch_model_0
# __0_0.distcp  __1_0.distcp
```

ูุชุญููููุง ูุฑุฉ ุฃุฎุฑู ูุงุณุชุฆูุงู ุงูุชุฏุฑูุจุ ุงุณุชุฎุฏู ุจุฑูุงูุฌ ุงููุณุงุนุฏุฉ `load_state` ูู Accelerate:

```py
accelerator.load_state("ckpt")
```

ุนูุฏ ุงุณุชุฎุฏุงู `save_pretrained` ูู Transformersุ ูู ุจุชูุฑูุฑ `state_dict=accelerator.get_state_dict(model)` ูุญูุธ ุญุงูุฉ ูุงููุณ ุงููููุฐุฌ.

ูููุง ููู ูุซุงู:

```diff
  unwrapped_model.save_pretrained(
      args.output_dir,
      is_main_process=accelerator.is_main_process,
      save_function=accelerator.save,
+     state_dict=accelerator.get_state_dict(model),
)
```

### ูุงููุณ ุงูุญุงูุฉ

ุณูููู `accelerator.get_state_dict` ุจุงุณุชุฏุนุงุก ุชูููุฐ `model.state_dict` ุงูุฃุณุงุณู ุจุงุณุชุฎุฏุงู `FullStateDictConfig(offload_to_cpu=Trueุ rank0_only=True)` ููุฏูุฑ ุณูุงู ููุญุตูู ุนูู ูุงููุณ ุงูุญุงูุฉ ููุฑุชุจุฉ 0 ููุท ูุณูุชู ูููู ุฅูู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ.

ููููู ุจุนุฏ ุฐูู ุชูุฑูุฑ `state` ุฅูู ุทุฑููุฉ `save_pretrained`. ููุงู ุนุฏุฉ ุฃูุถุงุน ูู `StateDictType` ู`FullStateDictConfig` ููููู ุงุณุชุฎุฏุงููุง ููุชุญูู ูู ุณููู `state_dict`. ููุฒูุฏ ูู ุงููุนูููุงุชุ ุฑุงุฌุน [ูุซุงุฆู PyTorch](https://pytorch.org/docs/stable/fsdp.html).

ุฅุฐุง ุงุฎุชุฑุช ุงุณุชุฎุฏุงู `StateDictType.SHARDED_STATE_DICT`ุ ูุณูุชู ุชูุณูู ุฃูุฒุงู ุงููููุฐุฌ ุฃุซูุงุก `Accelerator.save_state` ุฅูู `n` ูููุงุช ููู ูุณู ูุฑุนู ูู ุงููููุฐุฌ. ูุฏูุฌูุง ูุฑุฉ ุฃุฎุฑู ูู ูุงููุณ ูุงุญุฏ ูุชุญููููุง ูุฑุฉ ุฃุฎุฑู ูู ุงููููุฐุฌ ูุงุญููุง ุจุนุฏ ุงูุชุฏุฑูุจุ ููููู ุงุณุชุฎุฏุงู ุจุฑูุงูุฌ ุงููุณุงุนุฏุฉ `merge_weights`:

```py
from accelerate.utils import merge_fsdp_weights

# ูุชู ุญูุธ ุฃูุฒุงููุง ุนุงุฏุฉู ูู ูุฌูุฏ `pytorch_model_fsdp_{model_number}`
merge_fsdp_weights("pytorch_model_fsdp_0", "output_path", safe_serialization=True)
```

ุณุชููู ุงููุชูุฌุฉ ุงูููุงุฆูุฉ ูุญููุธุฉ ุฅูุง ูู `model.safetensors` ุฃู `pytorch_model.bin` (ุฅุฐุง ุชู ุชูุฑูุฑ `safe_serialization=False`).

ูููู ุงุณุชุฏุนุงุก ูุฐุง ุฃูุถูุง ุจุงุณุชุฎุฏุงู CLI:

```bash
accelerate merge-weights pytorch_model_fsdp_0/ output_path
```

## ุงูุชุทุงุจู ุจูู ุงุณุชุฑุงุชูุฌูุงุช ุชุฌุฒุฆุฉ FSDP ููุฑุงุญู DeepSpeed ZeRO

* `FULL_SHARD` ูุชูุงูู ูุน DeepSpeed `ZeRO Stage-3`. ุชุฌุฒุฆุฉ ุญุงูุงุช ุงููุญุณู ูุงูุชุฏุฑุฌุงุช ูุงููุณุงุฆุท.
* `SHARD_GRAD_OP` ูุชูุงูู ูุน DeepSpeed `ZeRO Stage-2`. ุชุฌุฒุฆุฉ ุญุงูุงุช ุงููุญุณู ูุงูุชุฏุฑุฌุงุช.
* `NO_SHARD` ูุชูุงูู ูุน `ZeRO Stage-0`. ูุง ุชูุฌุฏ ุชุฌุฒุฆุฉ ุญูุซ ุชุญุชูู ูู ูุญุฏุฉ ูุนุงูุฌุฉ ุฑุณูููุฉ ุนูู ูุณุฎุฉ ูุงููุฉ ูู ุงููููุฐุฌ ูุญุงูุงุช ุงููุญุณู ูุงูุชุฏุฑุฌุงุช.
* `HYBRID_SHARD` ูุชูุงูู ูุน `ZeRO++ Stage-3` ุญูุซ `zero_hpz_partition_size=<num_gpus_per_node>`. ููุงุ ุณูุชู ุชุฌุฒุฆุฉ ุญุงูุงุช ุงููุญุณู ูุงูุชุฏุฑุฌุงุช ูุงููุณุงุฆุท ุฏุงุฎู ูู ุนูุฏุฉ ูู ุญูู ุฃู ููู ุนูุฏุฉ ูุณุฎุฉ ูุงููุฉ.

## ุจุนุถ ุงูุชุญุฐูุฑุงุช ุงูุชู ูุฌุจ ูุฑุงุนุงุชูุง

- ูู ุญุงูุฉ ูุฌูุฏ ุนุฏุฉ ููุงุฐุฌุ ูู ุจุชูุฑูุฑ ุงููุญุณูุงุช ุฅูู ููุงููุฉ ุงูุฅุนุฏุงุฏ ุจููุณ ุงูุชุฑุชูุจ ุงูุฎุงุต ุจุงูููุงุฐุฌ ุงูููุงุจูุฉุ ูุฅูุง ูุฅู `accelerator.save_state()` ู`accelerator.load_state()` ุณุชุคุฏู ุฅูู ุณููู ุบูุฑ ุตุญูุญ/ุบูุฑ ูุชููุน.
- ูุฐู ุงูููุฒุฉ ุบูุฑ ูุชูุงููุฉ ูุน `--predict_with_generate` ูู ูุต `run_translation.py` ูู ููุชุจุฉ ๐ค `Transformers`.

ููุฒูุฏ ูู ุงูุชุญููุ ูููู ูููุณุชุฎุฏููู ุงูุงุณุชูุงุฏุฉ ูู `FullyShardedDataParallelPlugin`. ุจุนุฏ ุฅูุดุงุก ูุซูู ููุฐู ุงููุฆุฉุ ูููู ูููุณุชุฎุฏููู ุชูุฑูุฑู ุฅูู ูุซูู ูุฆุฉ Accelerator.

ููุฒูุฏ ูู ุงููุนูููุงุช ุญูู ูุฐู ุงูุฎูุงุฑุงุชุ ูุฑุฌู ุงูุฑุฌูุน ุฅูู ุฑูุฒ PyTorch [FullyShardedDataParallel](https://github.com/pytorch/pytorch/blob/0df2e863fbd5993a7b9e652910792bd21a516ff3/torch/distributed/fsdp/fully_sharded_data_parallel.py#L236).

<Tip>

ุจุงููุณุจุฉ ูุฃููุฆู ุงูููุชููู ุจุฃูุฌู ุงูุชุดุงุจู ูุงูุงุฎุชูุงู ุจูู FSDP ูDeepSpeedุ ูุฑุฌู ุงูุงุทูุงุน ุนูู [ุฏููู ุงูููุงููู ููุง](../concept_guides/fsdp_and_deepspeed.md)!

</Tip>