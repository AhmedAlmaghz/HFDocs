# ุงุณุชุฎุฏุงู Local SGD ูุน ๐ค Accelerate

Local SGD ูู ุชูููุฉ ููุชุฏุฑูุจ ุงูููุฒุน ุญูุซ ูุง ูุชู ุชุฒุงูู ุงูุชุฏุฑุฌุงุช ูู ูู ุฎุทูุฉ. ูุจุงูุชุงููุ ูููู ูู ุนูููุฉ ุจุชุญุฏูุซ ูุณุฎุชู ุงูุฎุงุตุฉ ูู ุฃูุฒุงู ุงููููุฐุฌุ ูุจุนุฏ ุนุฏุฏ ูุนูู ูู ุงูุฎุทูุงุชุ ูุชู ุชุฒุงูู ูุฐู ุงูุฃูุฒุงู ุนู ุทุฑูู ุญุณุงุจ ุงููุชูุณุท ุนุจุฑ ุฌููุน ุงูุนูููุงุช. ูุญุณู ูุฐุง ูู ููุงุกุฉ ุงูุงุชุตุงู ููููู ุฃู ูุคุฏู ุฅูู ุชุณุฑูุน ุงูุชุฏุฑูุจ ุจุดูู ูุจูุฑุ ุฎุงุตุฉ ุนูุฏูุง ููุชูุฑ ุงูููุจููุชุฑ ุฅูู ุงุชุตุงู ุฃุณุฑุน ูุซู NVLink.

ุนูู ุนูุณ ุชุฌููุน ุงูุชุฏุฑุฌุงุช (ุญูุซ ูุชุทูุจ ุชุญุณูู ููุงุกุฉ ุงูุงุชุตุงู ุฒูุงุฏุฉ ุญุฌู ุงูุฏูุนุฉ ุงููุนุงู)ุ ูุง ูุชุทูุจ Local SGD ุชุบููุฑ ุญุฌู ุงูุฏูุนุฉ ุฃู ูุนุฏู ุงูุชุนูู / ุงูุฌุฏูู. ููุน ุฐููุ ุฅุฐุง ูุฒู ุงูุฃูุฑุ ูููู ุงูุฌูุน ุจูู Local SGD ูุชุฌููุน ุงูุชุฏุฑุฌุงุช ุฃูุถูุง.

ูู ูุฐุง ุงูุจุฑูุงูุฌ ุงูุชุนููููุ ุณุชุชุนูู ููููุฉ ุฅุนุฏุงุฏ Local SGD ๐ค Accelerate ุจุณุฑุนุฉ. ููุงุฑูุฉ ุจุงูุฅุนุฏุงุฏ ุงูููุงุณู ูู Accelerateุ ูุชุทูุจ ูุฐุง ุณุทุฑูู ููุท ูู ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ ุงูุฅุถุงููุฉ.

ุณูุณุชุฎุฏู ูุฐุง ุงููุซุงู ุญููุฉ ุชุฏุฑูุจ PyTorch ูุจุณุทุฉ ููุบุงูุฉ ุชููู ุจุชุฌููุน ุงูุชุฏุฑุฌุงุช ูู ุฏูุนุชูู:

```python
device = "cuda"
model.to(device)

gradient_accumulation_steps = 2

for index, batch in enumerate(training_dataloader):
    inputs, targets = batch
    inputs = inputs.to(device)
    targets = targets.to(device)
    outputs = model(inputs)
    loss = loss_function(outputs, targets)
    loss = loss / gradient_accumulation_steps
    loss.backward()
    if (index + 1) % gradient_accumulation_steps == 0:
        optimizer.step()
        scheduler.step()
        optimizer.zero_grad()
```

## ุชุญูููู ุฅูู ๐ค Accelerate

ุฃููุงูุ ุณูุชู ุชุญููู ุงูููุฏ ุงูููุถุญ ุณุงุจููุง ูุงุณุชุฎุฏุงู ๐ค Accelerate ุจุฏูู ูุณุงุนุฏ LocalSGD ุฃู ุชุฌููุน ุงูุชุฏุฑุฌุงุช:

```diff
+ from accelerate import Accelerator
+ accelerator = Accelerator()

+ model, optimizer, training_dataloader, scheduler = accelerator.prepare(
+     model, optimizer, training_dataloader, scheduler
+ )

  for index, batch in enumerate(training_dataloader):
      inputs, targets = batch
-     inputs = inputs.to(device)
-     targets = targets.to(device)
      outputs = model(inputs)
      loss = loss_function(outputs, targets)
      loss = loss / gradient_accumulation_steps
+     accelerator.backward(loss)
      if (index+1) % gradient_accumulation_steps == 0:
          optimizer.step()
          scheduler.step()
```

## ุงูุณูุงุญ ูู ๐ค Accelerate ุจุงูุชุนุงูู ูุน ูุฒุงููุฉ ุงููููุฐุฌ

ูู ูุง ุชุจูู ุงูุขู ูู ุงูุณูุงุญ ูู ๐ค Accelerate ุจุงูุชุนุงูู ูุน ูุฒุงููุฉ ูุนููุงุช ุงููููุฐุฌ **ูุชุฌููุน ุงูุชุฏุฑุฌุงุช** ููุงุจุฉ ุนูุง. ููุชุจุณูุท ุงูุฃููุฑุ ุฏุนูุง ููุชุฑุถ ุฃููุง ุจุญุงุฌุฉ ุฅูู ุงููุฒุงููุฉ ูู 8 ุฎุทูุงุช. ูุชู ุชุญููู ุฐูู ุนู ุทุฑูู ุฅุถุงูุฉ ุนุจุงุฑุฉ `with LocalSGD` ูุงุณุชุฏุนุงุก ูุงุญุฏ `local_sgd.step()` ุจุนุฏ ูู ุฎุทูุฉ ูู ุฎุทูุงุช ุงููุญุณู:

```diff
+local_sgd_steps=8

+with LocalSGD(accelerator=accelerator, model=model, local_sgd_steps=8, enabled=True) as local_sgd:
    for batch in training_dataloader:
        with accelerator.accumulate(model):
            inputs, targets = batch
            outputs = model(inputs)
            loss = loss_function(outputs, targets)
            accelerator.backward(loss)
            optimizer.step()
            scheduler.step()
            optimizer.zero_grad()
+           local_sgd.step()
```

ุชุญุช ุงูุบุทุงุกุ ูููู ููุฏ Local SGD ุจุชุนุทูู ูุฒุงููุฉ ุงูุชุฏุฑุฌุงุช ุงูุชููุงุฆูุฉ (ูููู ูุง ูุฒุงู ุงูุชุฌููุน ูุนูู ููุง ูู ูุชููุน!). ุจุฏูุงู ูู ุฐููุ ูุฅูู ูููู ุจูุนุฏูุฉ ูุนููุงุช ุงููููุฐุฌ ูู `local_sgd_steps` ุฎุทูุงุช (ููู ููุงูุฉ ุญููุฉ ุงูุชุฏุฑูุจ ุฃูุถูุง).

## ุงููููุฏ

ูุนูู ุงูุชูููุฐ ุงูุญุงูู ููุท ูุน ุงูุชุฏุฑูุจ ูุชุนุฏุฏ GPU (ุฃู CPU) ุงูุฃุณุงุณู ุจุฏููุ ุนูู ุณุจูู ุงููุซุงูุ [DeepSpeed.](https://github.com/microsoft/DeepSpeed).

## ุงููุฑุงุฌุน

ุนูู ุงูุฑุบู ูู ุฃููุง ูุง ูุนุฑู ุงูุฃุตูู ุงูุญููููุฉ ููุฐู ุงูุทุฑููุฉ ุงูุจุณูุทุฉุ ุฅูุง ุฃู ููุฑุฉ Local SGD ูุฏููุฉ ุฌุฏูุง ูุชุฑุฌุน ุนูู ุงูุฃูู ุฅูู:

Zhang, J., De Sa, C., Mitliagkas, I., & Rรฉ, C. (2016). [Parallel SGD: When does averaging help?. arXiv preprint
arXiv:1606.07365.](https://arxiv.org/abs/1606.07365)

ูุญู ููุณุจ ูุตุทูุญ Local SGD ุฅูู ุงููุฑูุฉ ุงูุชุงููุฉ (ูููู ูุฏ ุชููู ููุงู ูุฑุงุฌุน ุณุงุจูุฉ ูุง ูุนุฑููุง).

Stich, Sebastian Urban. ["Local SGD Converges Fast and Communicates Little." ICLR 2019-International Conference on
Learning Representations. No. CONF. 2019.](https://arxiv.org/abs/1805.09767)