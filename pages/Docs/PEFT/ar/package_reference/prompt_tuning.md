# ضبط المطالبة

يضيف [ضبط المطالبة](https://hf.co/papers/2104.08691) مطالبات خاصة بالمهمة إلى الإدخال، ويتم تحديث معلمات المطالبة هذه بشكل مستقل عن معلمات النموذج المُدرب مسبقًا والتي يتم تجميدها.

المستخلص من الورقة هو:

*في هذا العمل، نستكشف "ضبط المطالبة"، وهي آلية بسيطة وفعالة لتعلم "مطالبات ناعمة" لتهيئة النماذج اللغوية المجمدة لأداء مهام محددة لأسفل البئر. على عكس مطالبات النص المتقطعة التي يستخدمها GPT-3، يتم تعلم المطالبات الناعمة من خلال الانتشار الخلفي ويمكن ضبطها لدمج الإشارة من أي عدد من الأمثلة المسماة. يتفوق نهجنا المُتعلم من النهاية إلى النهاية على تعلم "اللقطة الواحدة" لـ GPT-3 بهامش كبير. والأكثر لفتًا للنظر، من خلال عمليات الحجب على حجم النموذج باستخدام T5، نُظهر أن ضبط المطالبة يصبح أكثر تنافسية مع النطاق: مع زيادة عدد معلمات النماذج عن مليارات، تُغلق طريقة "الفجوة" وتطابق الأداء القوي لضبط النموذج (حيث يتم ضبط جميع أوزان النموذج). هذا الاكتشاف مهم بشكل خاص لأن النماذج الكبيرة مكلفة للمشاركة والخدمة، وتتمثل القدرة على إعادة استخدام نموذج مجمد واحد لمهام متعددة لأسفل البئر في تخفيف هذا العبء. يمكن اعتبار طريقة عملنا تبسيطًا لـ "ضبط البادئة" الذي اقترحه مؤخرًا Li and Liang (2021)، ونقدم مقارنة لهذا ولنُهج مماثلة أخرى. وأخيرًا، نُظهر أن تهيئة نموذج مجمد بمطالبات ناعمة تمنح فوائد في الروبوتية لنقل المجال، مقارنة بضبط النموذج الكامل*.

## PromptTuningConfig

[[autodoc]] tuners.prompt_tuning.config.PromptTuningConfig

## PromptEmbedding

[[autodoc]] tuners.prompt_tuning.model.PromptEmbedding