# P-tuning 

تضيف طريقة P-tuning [رابط](https://hf.co/papers/2103.10385) غرسات موجهة قابلة للتدريب إلى الإدخال الذي يقوم موجه الترميز بتحسينه لإيجاد موجه أفضل، مما يلغي الحاجة إلى تصميم الموجهات يدويًا. يمكن إضافة رموز الموجه في أي مكان في تسلسل الإدخال، ويقدم P-tuning أيضًا رموز مرساة لتحسين الأداء. 

ملخص الورقة هو: 

*بينما تفشل طرق GPTs مع الضبط الدقيق التقليدي في تحقيق نتائج قوية في فهم اللغة الطبيعية (NLU)، فإننا نُظهر أن طرق GPTs يمكن أن تكون أفضل من أو مشابهة لـ BERTs المماثلة في الحجم في مهام NLU باستخدام طريقة جديدة تسمى P-tuning - والتي تستخدم غرسات موجه مستمر قابل للتدريب. وفي معيار استكشاف المعرفة (LAMA)، تستعيد أفضل طريقة GPT 64٪ (P@1) من المعرفة العالمية دون توفير أي نص إضافي أثناء وقت الاختبار، مما يحسن بشكل كبير أفضل النتائج السابقة بأكثر من 20 نقطة مئوية. وفي معيار SuperGlue، تحقق طرق GPT أداءً مشابهًا وأحيانًا أفضل من BERTs المماثلة في الحجم في التعلم الخاضع للإشراف. والأهم من ذلك، أننا وجدنا أن P-tuning يحسن أيضًا أداء BERTs في كل من الإعدادات الخاضعة للإشراف والقليلة، مع تقليل الحاجة إلى هندسة الموجهات إلى حد كبير. ونتيجة لذلك، تفوق طريقة P-tuning على الطرق الأخرى في معيار SuperGlue القليل*.

## PromptEncoderConfig

[[autodoc]] tuners.p_tuning.config.PromptEncoderConfig

## PromptEncoder

[[autodoc]] tuners.p_tuning.model.PromptEncoder