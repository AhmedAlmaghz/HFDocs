# ضبط تعدد المهام 

[ضبط تعدد المهام للملفات](https://huggingface.co/papers/2303.02861) يفصل الملفات الناعمة لكل مهمة إلى ملف تعلم قابل للنقل بدلاً من ملف منفصل لكل مهمة. يمكن تكييف ملف التعلم الفردي لكل مهمة من خلال تحديثات الترتيب المنخفض الضربي.

المستخلص من الورقة هو:

*ظهر ضبط الملف، الذي يتم فيه تكييف نموذج أساسي مُدرب مسبقًا مع كل مهمة عن طريق الشرط على متجهات ملفات التعلم، كنهج واعد لتكييف نماذج اللغة الكبيرة بكفاءة مع مهام تدفق متعددة. ومع ذلك، عادةً ما تتعلم الطرق الحالية متجهات ملفات ناعمة من الصفر، ولم يتضح كيفية استغلال المعرفة الشاملة للمهمة بمتجهات الملفات في إعداد تعلم المهام المتعددة. نقترح ضبط ملف المهام المتعددة (MPT)، والذي يتعلم أولاً ملفًا قابلًا للنقل عن طريق تقطير المعرفة من ملفات المصدر المحددة للمهمة المتعددة. بعد ذلك، نتعلم تحديثات الترتيب المنخفض الضربي لهذا الملف المشترك لتكييفه بكفاءة مع كل مهمة هدف لأسفل. تُظهر التجارب واسعة النطاق على 23 مجموعة بيانات خاصة بمعالجة اللغات الطبيعية أن النهج الذي نقترحه يتفوق على طرق الحوسبة الفائقة، بما في ذلك خط الأساس للتدريب الدقيق الكامل في بعض الحالات، على الرغم من ضبط 0.035% فقط من المعلمات المحددة للمهمة*.

## MultitaskPromptTuningConfig

[[autodoc]] tuners.multitask_prompt_tuning.config.MultitaskPromptTuningConfig

## MultitaskPromptEmbedding

[[autodoc]] tuners.multitask_prompt_tuning.model.MultitaskPromptEmbedding