# Llama-Adapter

[Llama-Adapter](https://hf.co/papers/2303.16199) هي طريقة PEFT مصممة خصيصًا لتحويل Llama إلى نموذج يتبع التعليمات. يتم تثبيت نموذج Llama ولا يتم تعلم سوى مجموعة من موجهات التكيف التي يتم وضعها قبل رموز التعليمات المدخلة. نظرًا لأن الوحدات المبدئية بشكل عشوائي والمُدخلة في النموذج يمكن أن تتسبب في فقدان النموذج لبعض معارفه الموجودة، يستخدم Llama-Adapter اهتمامًا مبدئيًا صفريًا مع بوابة صفريّة لإضافة موجهات التعليمات تدريجيًا إلى النموذج.

الملخص من الورقة البحثية هو:

*نحن نقدم LLaMA-Adapter، وهي طريقة تكيّف خفيفة الوزن لتكييف LLaMA بكفاءة إلى نموذج يتبع التعليمات. باستخدام 52 ألف عرض تعليم ذاتي، لا يقدم LLaMA-Adapter سوى 1.2 مليون معلمة قابلة للتعلم بناءً على نموذج LLaMA 7B المجمد، وتكلف أقل من ساعة للضبط الدقيق على 8 وحدات معالجة رسومات A100. على وجه التحديد، نحن نتبنى مجموعة من موجهات التكيف القابلة للتعلم، ونسبقها لرموز الرموز المميزة للنص المدخل في طبقات المحول الأعلى. بعد ذلك، يتم اقتراح آلية اهتمام مبدئية صفريّة مع بوابة صفريّة، والتي تقوم بحقن إشارات التعليمات الجديدة في LLaMA بشكل تكيفي، مع الحفاظ على معرفته المسبقة التدريب بشكل فعال. مع التدريب الفعال، ينشئ LLaMA-Adapter استجابات عالية الجودة، قابلة للمقارنة مع Alpaca مع 7B معلمات مضبوطة بشكل كامل. علاوة على ذلك، يمكن ببساطة توسيع نطاق نهجنا إلى الإدخال متعدد الوسائط، على سبيل المثال، الصور، لـ LLaMA المشروطة بالصورة، والتي تحقق قدرة استدلال متفوقة على ScienceQA. نحن نطلق كودنا على https://github.com/ZrrSkywalker/LLaMA-Adapter*.

## AdaptionPromptConfig

[[autodoc]] tuners.adaption_prompt.config.AdaptionPromptConfig

## AdaptionPromptModel

[[autodoc]] tuners.adaption_prompt.model.AdaptionPromptModel