# تكوينات وموديلات PEFT

إن الحجم الهائل للنماذج الكبيرة مسبقة التدريب في يومنا هذا - والتي عادة ما تحتوي على مليارات من المعلمات - يمثل تحديًا تدريبيًا كبيرًا لأنه يتطلب المزيد من مساحة التخزين والمزيد من الطاقة الحاسوبية لإجراء جميع تلك الحسابات. ستحتاج إلى الوصول إلى وحدات معالجة الرسوميات (GPU) أو وحدات معالجة المصفوفات (TPU) القوية لتدريب هذه النماذج الكبيرة مسبقة التدريب، وهو ما يعد مكلفًا، وغير متاح على نطاق واسع للجميع، وغير صديق للبيئة، وغير عملي إلى حد ما. وتعالج طرق PEFT العديد من هذه التحديات. هناك عدة أنواع من طرق PEFT (التلميح الناعم، وتحليل المصفوفات، والمحولات)، ولكنها جميعًا تركز على نفس الشيء، وهو تقليل عدد المعلمات القابلة للتدريب. وهذا يجعل تدريب وتخزين النماذج الكبيرة على أجهزة المستهلك أكثر سهولة.

تم تصميم مكتبة PEFT لمساعدتك في تدريب النماذج الكبيرة بسرعة على وحدات معالجة الرسوميات (GPU) المجانية أو منخفضة التكلفة، وفي هذا البرنامج التعليمي، ستتعلم كيفية إعداد تكوين لتطبيق طريقة PEFT على نموذج أساسي مُدرَّب مسبقًا. بمجرد إعداد تكوين PEFT، يمكنك استخدام أي إطار عمل تدريبي تفضله (فئة ~transformers.Trainer في Transformer، أو Accelerate، أو حلقة تدريب PyTorch مخصصة).

## تكوينات PEFT

تعرف أكثر على المعلمات التي يمكنك تكوينها لكل طريقة PEFT في صفحة مرجع واجهة برمجة التطبيقات الخاصة بها.

يخزن التكوين معلمات مهمة تحدد كيفية تطبيق طريقة PEFT معينة.

على سبيل المثال، الق نظرة على التالي [LoraConfig] (https://huggingface.co/ybelkada/opt-350m-lora/blob/main/adapter_config.json) لتطبيق LoRA و [PromptEncoderConfig] (https://huggingface.co/smangrul/roberta-large-peft-p-tuning/blob/main/adapter_config.json) لتطبيق p-tuning (ملفات التكوين هذه هي بالفعل JSON-serialized). عند تحميل محول PEFT، من الجيد التحقق مما إذا كان لديه ملف adapter_config.json المرتبط به والذي يكون مطلوبًا.

<hfoptions id="config">

<hfoption id="LoraConfig">

```json
{
"base_model_name_or_path": "facebook/opt-350m"، #base model to apply LoRA to
"bias": "none"،
"fan_in_fan_out": false،
"inference_mode": true،
"init_lora_weights": true،
"layers_pattern": null،
"layers_to_transform": null،
"lora_alpha": 32،
"lora_dropout": 0.05،
"modules_to_save": null،
"peft_type": "LORA"، #PEFT method type
"r": 16،
"revision": null،
"target_modules": [
"q_proj"، #model modules to apply LoRA to (query and value projection layers)
"v_proj"
]،
"task_type": "CAUSAL_LM" #type of task to train model on
}
```

يمكنك إنشاء تكوينك الخاص للتدريب عن طريق تهيئة [LoraConfig].

```py
from peft import LoraConfig, TaskType

lora_config = LoraConfig(
r=16،
target_modules=["q_proj"، "v_proj"]،
task_type=TaskType.CAUSAL_LM،
lora_alpha=32،
loraََُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُُ