لم يتم ترجمة الأجزاء المحددة في النص الأصلي بناء على طلبك.

# Polytropon

[Polytropon](https://hf.co/papers/2202.13914) هو نموذج متعدد المهام يحتوي على عدد من وحدات LoRA المختلفة في "مخزونه". ويتعلم النموذج المزيج الصحيح من وحدات التخزين من المخزون باستخدام دالة توجيه لاختيار أفضل مجموعة فرعية من الوحدات النمطية لمهمة معينة. كما يدعم PEFT [Multi-Head Adapter Routing (MHR)](https://hf.co/papers/2211.03831) لـ Polytropon الذي يعتمد على دالة التوجيه ويحسنها من خلال الجمع بين رؤوس المحول بشكل أكثر تفصيلاً. يتم فصل رؤوس المحول إلى كتل غير متجاورة ويتم تعلم دالة توجيه مختلفة لكل منها، مما يسمح بمزيد من التعبير.

<hfoptions id="paper">
<hfoption id="Combining Modular Skills in Multitask Learning">

ملخص الورقة هو:

> يشجع التصميم النمطي النماذج العصبية على فصل وإعادة دمج الجوانب المختلفة للمعرفة للتعميم بشكل أكثر منهجية على المهام الجديدة. في هذا العمل، نفترض أن كل مهمة مرتبطة بمجموعة فرعية من المهارات الكامنة والمنفصلة من مخزون (صغير محتمل). بدورها، تتوافق المهارات مع معلمات نموذج فعالة من حيث التكلفة (مبعثرة / منخفضة الرتبة). من خلال التعلم المشترك لهذه المعلمات ومصفوفة تخصيص المهام والمهارات، يتم إنشاء الشبكة لكل مهمة كمعدل لمعلمات المهارات النشطة. ولتفضيل التقسيمات غير التافهة للمهارات عبر المهام، نجري تجارب باستخدام سلسلة من الانحيازات الاستقرائية، مثل عملية Indian Buffet السابقة ومعدل تعلم ثنائي السرعة. نقيّم نموذج المهارات الكامنة لدينا في إطار إعدادين رئيسيين: 1) التعلم التعزيزي متعدد المهام لمتابعة التعليمات المستندة إلى BabyAI على 8 مستويات من المنصة؛ و 2) التكيف القليل للنماذج المولدة للنص المسبقة التدريب على CrossFit، وهو معيار مرجعي يتكون من 160 مهمة NLP. نجد أن التصميم النمطي للشبكة يزيد بشكل كبير من كفاءة العينات في التعلم التعزيزي والتعميم القليل في التعلم الخاضع للإشراف، مقارنة بخطوط الأساس ذات المعلمات المشتركة بالكامل أو المحددة للمهمة أو المولدة شرطيًا حيث يتم تشابك المعرفة عبر المهام. بالإضافة إلى ذلك، نوضح كيف تساعد المهارات المنفصلة في قابلية التفسير، حيث توفر تسلسل هرمي صريح للمهام.

</hfoption>
<hfoption id="Multi-Head Adapter Routing for Cross-Task Generalization">

ملخص الورقة هو:

> يتكون الضبط الدقيق الفعال من حيث التكلفة (PEFT) للتعميم متعدد المهام من معايرة المحولات مسبقًا على مجموعة بيانات تدريب متعددة المهام قبل التكيف القليل مع مهام الاختبار. يتعلم Polytropon [Ponti et al.، 2023] (Poly) بشكل مشترك مخزونًا من المحولات ودالة توجيه تقوم باختيار مجموعة فرعية (متغيرة الحجم) من المحولات لكل مهمة أثناء كل من المعايرة المسبقة والتكيف القليل. في هذه الورقة، نستكشف دور التوجيه الذي يلعبه المحول في نجاحه ونصمم متغيرات جديدة بناءً على النتائج التي توصلنا إليها. أولاً، نعتمد على الحدس بأن التوجيه الدقيق يوفر تعبيرًا أكثر دقة. وبالتالي، نقترح MHR (Multi-Head Routing)، والذي يجمع بين مجموعات فرعية من معلمات المحول ويتفوق على Poly بميزانية معلمات قابلة للمقارنة؛ من خلال ضبط دالة التوجيه فقط وليس المحولات (MHR-z)، نحقق أداءً تنافسيًا بكفاءة معلمات قصوى. ثانيًا، نجد أن أداء Poly/MHR هو نتيجة لتحسين المهام المتعددة بشكل أفضل، بدلاً من التحيزات الاستقرائية النمطية التي تسهل إعادة دمج المحول والتكيف المحلي، كما كان مفترضًا سابقًا. في الواقع، نجد أن MHR يظهر محاذاة تدرج أعلى بين المهام أكثر من أي طريقة أخرى. بما أن هذا يعني أن التوجيه مهم فقط أثناء المعايرة متعددة المهام، فإننا نقترح MHR-mu، والذي يتخلص من التوجيه ويضبط معدل المحولات مسبقة التدريب أثناء التكيف القليل. وهذا يجعل MHR-mu طريقة فعالة لضبط محول واحد.

</hfoption>
</hfoptions>

## PolyConfig

[[autodoc]] tuners.poly.config.PolyConfig

## PolyModel

[[autodoc]] tuners.poly.model.PolyModel