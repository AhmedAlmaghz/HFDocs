# ุงุณุชูุดุงู ุงูุฃุฎุทุงุก ูุฅุตูุงุญูุง

ุฅุฐุง ูุงุฌูุชู ุฃู ูุดููุฉ ุนูุฏ ุงุณุชุฎุฏุงู PEFTุ ูุฑุฌู ุงูุชุญูู ูู ูุงุฆูุฉ ุงููุดููุงุช ุงูุดุงุฆุนุฉ ูุญููููุง ุงูุชุงููุฉ.

## ุนุฏู ุนูู ุงูุฃูุซูุฉ

ุบุงูุจุงู ูุง ุชุนุชูุฏ ุงูุฃูุซูุฉ ุนูู ุฃุญุฏุซ ุฅุตุฏุงุฑุงุช ุงูุญุฒูุ ูุฐุง ูุฑุฌู ุงูุชุฃูุฏ ูู ุชุญุฏูุซูุง. ูุนูู ูุฌู ุงูุฎุตูุตุ ุชุญูู ูู ุฅุตุฏุงุฑุงุช ุงูุญุฒู ุงูุชุงููุฉ:

- `peft`
- `transformers`
- `accelerate`
- `torch`

ุจุดูู ุนุงูุ ููููู ุชุญุฏูุซ ุฅุตุฏุงุฑ ุงูุญุฒูุฉ ุจุชุดุบูู ูุฐุง ุงูุฃูุฑ ุฏุงุฎู ุจูุฆุฉ Python ุงูุฎุงุตุฉ ุจู:

```bash
python -m pip install -U <package_name>
```

ูููู ุฃู ูููู ุชุซุจูุช PEFT ูู ุงููุตุฏุฑ ูููุฏูุง ูููุงูุจุฉ ุฃุญุฏุซ ุงูุชุทูุฑุงุช:

```bash
python -m pip install git+https://github.com/huggingface/peft
```

## ุฎุทุฃ ุงููููุฉ: ูุญุงููุฉ ุฅูุบุงุก ุชุญุฌูู ุชุฏุฑุฌุงุช FP16

ูู ุงููุญุชูู ุฃู ูููู ูุฐุง ุงูุฎุทุฃ ูุฏ ุญุฏุซ ูุฃู ุงููููุฐุฌ ุชู ุชุญูููู ุจุงุณุชุฎุฏุงู `torch_dtype=torch.float16` ุซู ุชู ุงุณุชุฎุฏุงูู ูู ุณูุงู ุงูุฏูุฉ ุงููุชูููุฉ ุงูุชููุงุฆูุฉ (AMP)ุ ุนูู ุณุจูู ุงููุซุงูุ ุนู ุทุฑูู ุชุนููู `fp16=True` ูู ูุฆุฉ [`~transformers.Trainer`] ูู ุญุฒูุฉ ๐ค Transformers. ูุงูุณุจุจ ูู ุฃูู ุนูุฏ ุงุณุชุฎุฏุงู AMPุ ูุง ููุจุบู ุฃุจุฏูุง ุงุณุชุฎุฏุงู ุงูุฏูุฉ ุงูุนุงุฆูุฉ fp16 ูู ุงูุฃูุฒุงู ุงููุงุจูุฉ ููุชุฏุฑูุจ. ูุฌุนู ูุฐุง ุงูุฃูุฑ ูุนูู ุฏูู ุชุญููู ุงููููุฐุฌ ุจุงููุงูู ูู fp32ุ ุฃุถู ูุง ููู ุฅูู ููุฏู:

```python
peft_model = get_peft_model(...)

# add this:
for param in model.parameters():
    if param.requires_grad:
        param.data = param.data.float()

# proceed as usual
trainer = Trainer(model=peft_model, fp16=True, ...)
trainer.train()
```

ุจุฏูุงู ูู ุฐููุ ููููู ุงุณุชุฎุฏุงู ูุธููุฉ [`~utils.cast_mixed_precision_params`] ูุชุญููู ุงูุฃูุฒุงู ุจุดูู ุตุญูุญ:

```python
from peft import cast_mixed_precision_params

peft_model = get_peft_model(...)
cast_mixed_precision_params(peft_model, dtype=torch.float16)

# ุชุงุจุน ูุงููุนุชุงุฏ
trainer = Trainer(model=peft_model, fp16=True, ...)
trainer.train()
```

<Tip>

ุจุฏุกูุง ูู ุฅุตุฏุงุฑ PEFT v0.11.0ุ ูููู PEFT ุชููุงุฆููุง ุจุชุฑููุฉ ููุน ุจูุงูุงุช ุฃูุฒุงู ุงููุญูู ูู `torch.float16` ู`torch.bfloat16` ุฅูู `torch.float32` ุนูุฏ ุงูุงูุชุถุงุก. ูููุน ูุฐุง ุงูุณูููุ ููููู ุชูุฑูุฑ `autocast_adapter_dtype=False` ุฅูู [`~get_peft_model` ]ุ ุฅูู [`~PeftModel.from_pretrained` ]ุ ูุฅูู [`~PeftModel.load_adapter`].

</Tip>

## ูุชุงุฆุฌ ุณูุฆุฉ ูู ูููุฐุฌ PEFT ูุญูู

ูุฏ ูููู ููุงู ุนุฏุฉ ุฃุณุจุงุจ ููุญุตูู ุนูู ูุชูุฌุฉ ุณูุฆุฉ ูู ูููุฐุฌ PEFT ูุญููุ ููู ูุฏุฑุฌุฉ ุฃุฏูุงู. ุฅุฐุง ููุช ูุง ุชุฒุงู ุบูุฑ ูุงุฏุฑ ุนูู ุงุณุชูุดุงู ุงููุดููุฉ ูุฅุตูุงุญูุงุ ุชุญูู ููุง ุฅุฐุง ูุงู ุฃู ุดุฎุต ุขุฎุฑ ูุฏ ูุงุฌู ูุดููุฉ ููุงุซูุฉ ุนูู [GitHub](https://github.com/huggingface/peft/issues)ุ ูุฅุฐุง ูู ุชุชููู ูู ุงูุนุซูุฑ ุนูู ุฃู ูููุงุ ููู ุจูุชุญ ูุดููุฉ ุฌุฏูุฏุฉ.

ุนูุฏ ูุชุญ ูุดููุฉุ ุณูููู ูู ุงููููุฏ ุฌุฏูุง ุฅุฐุง ูุฏูุช ูุซุงููุง ุจุฑูุฌููุง ุจุณูุทูุง ูุชูุงุซุฑ ุงููุดููุฉ. ุฃูุถูุงุ ูุฑุฌู ุงูุฅุจูุงุบ ุนูุง ุฅุฐุง ูุงู ุงููููุฐุฌ ุงููุญูู ูุนูู ุจููุณ ูุณุชูู ุงููููุฐุฌ ูุจู ุงูุถุจุท ุงูุฏูููุ ุฃู ุฅุฐุง ูุงู ูุนูู ุจูุณุชูู ุนุดูุงุฆูุ ุฃู ุฅุฐุง ูุงู ุฃุณูุฃ ููููุงู ูู ุงููุชููุน. ุชุณุงุนุฏูุง ูุฐู ุงููุนูููุงุช ุนูู ุชุญุฏูุฏ ุงููุดููุฉ ุจุดูู ุฃุณุฑุน.

### ุงูุงูุญุฑุงูุงุช ุงูุนุดูุงุฆูุฉ

ุฅุฐุง ูุงูุช ูุชุงุฆุฌ ุงููููุฐุฌ ุบูุฑ ูุทุงุจูุฉ ุชูุงููุง ููุชุดุบูู ุงูุณุงุจูุ ููุฏ ุชููู ููุงู ูุดููุฉ ูู ุงูุนูุงุตุฑ ุงูุนุดูุงุฆูุฉ. ุนูู ุณุจูู ุงููุซุงู:

1. ูุฑุฌู ุงูุชุฃูุฏ ูู ุฃูู ูู ูุถุน `.eval()`ุ ููู ุฃูุฑ ูููุ ุนูู ุณุจูู ุงููุซุงูุ ุฅุฐุง ูุงู ุงููููุฐุฌ ูุณุชุฎุฏู ุงูุฅุณูุงุท

2. ุฅุฐุง ููุช ุชุณุชุฎุฏู [`~transformers.GenerationMixin.generate`] ุนูู ูููุฐุฌ ุงููุบุฉุ ููุฏ ูููู ููุงู ุนููุงุช ุนุดูุงุฆูุฉุ ูุฐุง ูุชุทูุจ ุงูุญุตูู ุนูู ููุณ ุงููุชูุฌุฉ ุชุนููู ุจุฐุฑุฉ ุนุดูุงุฆูุฉ

3. ุฅุฐุง ููุช ูุฏ ุงุณุชุฎุฏูุช ุงูุชูููู ูุฏูุฌุช ุงูุฃูุฒุงูุ ููู ุงููุชููุน ุญุฏูุซ ุงูุญุฑุงูุงุช ุทูููุฉ ุจุณุจุจ ุฃุฎุทุงุก ุงูุชูุฑูุจ

### ูููุฐุฌ ูุญูู ุจุดูู ุบูุฑ ุตุญูุญ

ูุฑุฌู ุงูุชุฃูุฏ ูู ุชุญููู ุงููููุฐุฌ ุจุดูู ุตุญูุญ. ุฃุญุฏ ุงูุฃุฎุทุงุก ุงูุดุงุฆุนุฉ ูู ูุญุงููุฉ ุชุญููู ูููุฐุฌ _trained_ ุจุงุณุชุฎุฏุงู [`get_peft_model`] ููู ุฃูุฑ ุบูุฑ ุตุญูุญ. ุจุฏูุงู ูู ุฐููุ ูุฌุจ ุฃู ุชุจุฏู ููุฏ ุงูุชุญููู ุนูู ุงููุญู ุงูุชุงูู:

```python
from peft import PeftModel, PeftConfig

base_model = ...  # ูุชุญููู ุงููููุฐุฌ ุงูุฃุณุงุณูุ ุงุณุชุฎุฏู ููุณ ุงูููุฏ ููุง ูุนูุช ุนูุฏ ุชุฏุฑูุจู
config = PeftConfig.from_pretrained(peft_model_id)
peft_model = PeftModel.from_pretrained(base_model, peft_model_id)
```

### ุทุจูุงุช ุชู ุชููุฆุชูุง ุจุดูู ุนุดูุงุฆู

ุจุงููุณุจุฉ ูุจุนุถ ุงูููุงูุ ูู ุงูููู ุชููุฆุฉ `modules_to_save` ูู ุงูุชููุฆุฉ ุจุดูู ุตุญูุญ ูุญุณุงุจ ุงูุทุจูุงุช ุงูุชู ุชู ุชููุฆุชูุง ุจุดูู ุนุดูุงุฆู.

ููุซุงู ุนูู ุฐููุ ูุฐุง ุฃูุฑ ุถุฑูุฑู ุฅุฐุง ููุช ุชุณุชุฎุฏู LoRA ูุถุจุท ูููุฐุฌ ุงููุบุฉ ุจุดูู ุฏููู ูุชุตููู ุงูุชุณูุณู ูุฃู ๐ค Transformers ุชุถูู ุฑุฃุณ ุชุตููู ุชู ุชููุฆุชู ุจุดูู ุนุดูุงุฆู ุฃุนูู ุงููููุฐุฌ. ุฅุฐุง ูู ุชุถู ูุฐู ุงูุทุจูุฉ ุฅูู `modules_to_save`ุ ููู ูุชู ุญูุธ ุฑุฃุณ ุงูุชุตููู. ูู ุงููุฑุฉ ุงูุชุงููุฉ ุงูุชู ุชููู ูููุง ุจุชุญููู ุงููููุฐุฌุ ุณุชุญุตู ุนูู ุฑุฃุณ ุชุตููู _different_ ุชู ุชููุฆุชู ุจุดูู ุนุดูุงุฆูุ ููุง ูุคุฏู ุฅูู ูุชุงุฆุฌ ูุฎุชููุฉ ุชูุงููุง.

ูุญุงูู PEFT ุชุฎููู `modules_to_save` ุจุดูู ุตุญูุญ ุฅุฐุง ูุฏูุช ุญุฌุฉ `task_type` ูู ุงูุชููุฆุฉ. ูุฌุจ ุฃู ูุนูู ูุฐุง ูุน ููุงุฐุฌ ุงููุญููุงุช ุงูุชู ุชุชุจุน ูุฎุทุท ุงูุชุณููุฉ ุงูููุงุณู. ูู ุงูุฌูุฏ ุฏุงุฆููุง ุงูุชุญูู ุงููุฒุฏูุฌ ุนูู ุงูุฑุบู ูู ุฃููุง ูุง ูุณุชุทูุน ุถูุงู ุงุชุจุงุน ุฌููุน ุงูููุงุฐุฌ ููุฎุทุท ุงูุชุณููุฉ.

ุนูุฏูุง ุชููู ุจุชุญููู ูููุฐุฌ ูุญููุงุช ูู ุทุจูุงุช ุชู ุชููุฆุชูุง ุจุดูู ุนุดูุงุฆูุ ูุฌุจ ุฃู ุชุดุงูุฏ ุชุญุฐูุฑูุง ุนูู ุงููุญู ุงูุชุงูู:

```
ูู ูุชู ุชููุฆุฉ ุจุนุถ ุฃูุฒุงู <MODEL> ูู ููุทุฉ ุชูุชูุด ุงููููุฐุฌ ูู <ID> ูุชู ุชููุฆุชูุง ุญุฏูุซูุง: [<LAYER_NAMES>].
ูุฌุจ ุนููู ุนูู ุงูุฃุฑุฌุญ ุชุฏุฑูุจ ูุฐุง ุงููููุฐุฌ ุนูู ูููุฉ ูุฃุณูู ูุชุชููู ูู ุงุณุชุฎุฏุงูู ููุชูุจุคุงุช ูุงูุงุณุชุฏูุงู.
```

ูุฌุจ ุฅุถุงูุฉ ุงูุทุจูุงุช ุงููุฐููุฑุฉ ุฅูู `modules_to_save` ูู ุงูุชููุฆุฉ ูุชุฌูุจ ุงููุดููุฉ ุงูููุถุญุฉ.

### ุชูุณูุน ุงูููุฑุฏุงุช

ุจุงููุณุจุฉ ููุนุฏูุฏ ูู ููุงู ุถุจุท ุงููุบุฉ ุงูุฏูููุ ูู ุงูุถุฑูุฑู ุชูุณูุน ููุฑุฏุงุช ุงููููุฐุฌ ุญูุซ ูุชู ุชูุฏูู ุฑููุฒ ุฌุฏูุฏุฉ. ูุชุทูุจ ุฐูู ุชูุณูุน ุทุจูุฉ ุงูุชุถููู ูุญุณุงุจ ุงูุฑููุฒ ุงูุฌุฏูุฏุฉุ ููุฐูู ุชุฎุฒูู ุทุจูุฉ ุงูุชุถููู ุจุงูุฅุถุงูุฉ ุฅูู ุฃูุฒุงู ุงููุญูู ุนูุฏ ุญูุธ ุงููุญูู.

ุงุญูุธ ุทุจูุฉ ุงูุชุถููู ุนู ุทุฑูู ุฅุถุงูุชูุง ุฅูู `target_modules` ูู ุงูุชููุฆุฉ. ูุฌุจ ุฃู ูุชุจุน ุงุณู ุทุจูุฉ ุงูุชุถููู ูุฎุทุท ุงูุชุณููุฉ ุงูููุงุณู ูู Transformers. ุนูู ุณุจูู ุงููุซุงูุ ูููู ุฃู ุชุจุฏู ุชููุฆุฉ Mistral ุนูู ุงููุญู ุงูุชุงูู:

```python
config = LoraConfig(..., target_modules=["embed_tokens"ุ "lm_head"ุ "q_proj"ุ "v_proj"])
```

ุจูุฌุฑุฏ ุฅุถุงูุชู ุฅูู `target_modules`ุ ูููู PEFT ุชููุงุฆููุง ุจุชุฎุฒูู ุทุจูุฉ ุงูุชุถููู ุนูุฏ ุญูุธ ุงููุญูู ุฅุฐุง ูุงู ูููููุฐุฌ [`~transformers.PreTrainedModel.get_input_embeddings`] ู [`~transformers.PreTrainedModel.get_output_embeddings`]. ูุฐุง ูู ุงูุญุงู ุจุดูู ุนุงู ูููุงุฐุฌ Transformers.

ุฅุฐุง ูู ุชุชุจุน ุทุจูุฉ ุชุถููู ุงููููุฐุฌ ูุฎุทุท ุงูุชุณููุฉ ุงูุฎุงุต ุจู Transformersุ ูููููู ุญูุธูุง ุนู ุทุฑูู ุชูุฑูุฑ `save_embedding_layers=True` ูุฏูููุง ุนูุฏ ุญูุธ ุงููุญูู:

```python
model = get_peft_model(...)
# ุชุฏุฑูุจ ุงููููุฐุฌ
model.save_pretrained("my_adapter"ุ save_embedding_layers=True)
```

ููุนุฑุถุ ูู ุจุชุญููู ุงููููุฐุฌ ุงูุฃุณุงุณู ุฃููุงู ููู ุจุชุบููุฑ ุญุฌูู ุจููุณ ุงูุทุฑููุฉ ุงูุชู ููุช ุจูุง ูุจู ุชุฏุฑูุจ ุงููููุฐุฌ. ุจุนุฏ ุฃู ููุช ุจุชุบููุฑ ุญุฌู ุงููููุฐุฌ ุงูุฃุณุงุณูุ ููููู ุชุญููู ููุทุฉ ุชูุชูุด PEFT.

ููุญุตูู ุนูู ูุซุงู ูุงููุ ูุฑุฌู ุงูุงุทูุงุน ุนูู [ูุฐุง ุงูุฏูุชุฑ](https://github.com/huggingface/peft/blob/main/examples/causal_language_modeling/peft_lora_clm_with_additional_tokens.ipynb).

### ุงูุชุญูู ูู ุญุงูุฉ ุงูุทุจูุฉ ูุงููููุฐุฌ

ูู ุจุนุถ ุงูุฃุญูุงูุ ูุฏ ููุชูู ูููุฐุฌ PEFT ูู ุญุงูุฉ ุณูุฆุฉุ ุฎุงุตุฉ ุนูุฏ ุงูุชุนุงูู ูุน ูุญููุงุช ูุชุนุฏุฏุฉ. ูุฏ ูููู ููุงู ุจุนุถ ุงูุงุฑุชุจุงู ุญูู ุงููุญููุงุช ุงูููุฌูุฏุฉุ ูุฃููุง ูุดุทุ ูุฃููุง ุชู ุฏูุฌูุ ููุง ุฅูู ุฐูู. ูููุณุงุนุฏุฉ ูู ุงูุชุญููู ูู ูุฐู ุงููุดููุฉุ ูู ุจุงุณุชุฏุนุงุก ุทุฑู [`~peft.PeftModel.get_layer_status`] ู [`~peft.PeftModel.get_model_status`].

ุชููุฑ ุทุฑููุฉ [`~peft.PeftModel.get_layer_status`] ูุธุฑุฉ ุนุงูุฉ ููุตูุฉ ุนู ุงููุญููุงุช ุงููุดุทุฉ ูุงููุฏูุฌุฉ ูุงููุชุงุญุฉ ููู ุทุจูุฉ ูุณุชูุฏูุฉ.

```python
>>> from transformers import AutoModel
>>> from peft import get_peft_model, LoraConfig

>>> model_id = "google/flan-t5-small"
>>> model = AutoModel.from_pretrained(model_id)
>>> model = get_peft_model(model, LoraConfig())

>>> model.get_layer_status()
[TunerLayerStatus(name='model.encoder.block.0.layer.0.SelfAttention.q',
                  module_type='lora.Linear',
                  enabled=True,
                  active_adapters=['default'],
                  merged_adapters=[],
                  requires_grad={'default': True},
                  available_adapters=['default']),
 TunerLayerStatus(name='model.encoder.block.0.layer.0.SelfAttention.v',
                  module_type='lora.Linear',
                  enabled=True,
                  active_adapters=['default'],
                  merged_adapters=[],
                  requires_grad={'default': True},
                  available_adapters=['default']),
...]

>>> model.get_model_status()
TunerModelStatus(
    base_model_type='T5Model',
    adapter_model_type='LoraModel',
    peft_types={'default': 'LORA'},
    trainable_params=344064,
    total_params=60855680,
    num_adapter_layers=48,
    enabled=True,
    active_adapters=['default'],
    merged_adapters=[],
    requires_grad={'default': True},
    available_adapters=['default'],
)
```

ูู ุฅุฎุฑุงุฌ ุญุงูุฉ ุงููููุฐุฌุ ูุฌุจ ุงูุงูุชุจุงู ุฅูู ุงูุฅุฏุฎุงูุงุช ุงูุชู ุชููู "irregular". ููุฐุง ูุนูู ุฃู PEFT ุงูุชุดู ุญุงูุฉ ุบูุฑ ูุชุณูุฉ ูู ุงููููุฐุฌ. ุนูู ุณุจูู ุงููุซุงูุ ุฅุฐุง ูุงู `merged_adapters="irregular"`ุ ููุฐุง ูุนูู ุฃูู ุจุงููุณุจุฉ ููุญูู ูุงุญุฏ ุนูู ุงูุฃููุ ุชู ุฏูุฌู ูู ุจุนุถ ูุญุฏุงุช ุงูุทุจูุฉ ุงููุณุชูุฏูุฉ ูููู ููุณ ูู ุบูุฑูุง. ูู ุงููุญุชูู ุฃู ุชููู ูุชุงุฆุฌ ุงูุงุณุชุฏูุงู ุบูุฑ ุตุญูุญุฉ ูุชูุฌุฉ ูุฐูู.

ุฃูุถู ุทุฑููุฉ ูุญู ูุฐู ุงููุดููุฉ ูู ุฅุนุงุฏุฉ ุชุญููู ููุทุฉ ุชูุชูุด ุงููููุฐุฌ ููุญูู (ุงุช) ุจุงููุงูู. ุชุฃูุฏ ูู ุฃูู ูุง ุชููู ุจุฃู ุนูููุงุช ุบูุฑ ุตุญูุญุฉ ุนูู ุงููููุฐุฌุ ุนูู ุณุจูู ุงููุซุงูุ ุฏูุฌ ุงููุญููุงุช ูุฏูููุง ูู ุจุนุถ ุงููุญุฏุงุช ูููู ููุณ ูู ูุญุฏุงุช ุฃุฎุฑู.

ูู ุจุชุญููู ุญุงูุฉ ุงูุทุจูุฉ ุฅูู ุฅุทุงุฑ ุจูุงูุงุช Pandas ูููุญุต ุงููุฑุฆู ุงูุฃุณูู.

```python
from dataclasses import asdict
import pandas as pd

df = pd.DataFrame(asdict(layer) for layer in model.get_layer_status())
```

ูู ุงููููู ุงูุญุตูู ุนูู ูุฐู ุงููุนูููุงุช ูููุงุฐุฌ ุบูุฑ PEFT ุฅุฐุง ูุงูุช ุชุณุชุฎุฏู ุทุจูุงุช PEFT ุชุญุช ุงูุบุทุงุกุ ูููู ุจุนุถ ุงููุนูููุงุช ูุซู `base_model_type` ุฃู `peft_types` ูุง ูููู ุชุญุฏูุฏูุง ูู ูุฐู ุงูุญุงูุฉ. ููุซุงู ุนูู ุฐููุ ููููู ุงุณุชุฏุนุงุก ูุฐุง ุนูู ูููุฐุฌ [diffusers](https://huggingface.co/docs/diffusers/index) ูุซู ูุฐุง:

```python
>>> import torch
>>> from diffusers import StableDiffusionPipeline
>>> from peft import get_model_status, get_layer_status

>>> path = "runwayml/stable-diffusion-v1-5"
>>> lora_id = "takuma104/lora-test-text-encoder-lora-target"
>>> pipe = StableDiffusionPipeline.from_pretrained(path, torch_dtype=torch.float16)
>>> pipe.load_lora_weights(lora_id, adapter_name="adapter-1")
>>> pipe.load_lora_weights(lora_id, adapter_name="adapter-2")
>>> pipe.set_lora_device(["adapter-2"], "cuda")
>>> get_layer_status(pipe.text_encoder)
[TunerLayerStatus(name='text_model.encoder.layers.0.self_attn.k_proj',
                  module_type='lora.Linear',
                  enabled=True,
                  active_adapters=['adapter-2'],
                  merged_adapters=[],
                  requires_grad={'adapter-1': False, 'adapter-2': True},
                  available_adapters=['adapter-1', 'adapter-2'],
                  devices={'adapter-1': ['cpu'], 'adapter-2': ['cuda']}),
 TunerLayerStatus(name='text_model.encoder.layers.0.self_attn.v_proj',
                  module_type='lora.Linear',
                  enabled=True,
                  active_adapters=['adapter-2'],
                  merged_adapters=[],
                  requires_grad={'adapter-1': False, 'adapter-2': True},
                  devices={'adapter-1': ['cpu'], 'adapter-2': ['cuda']}),
...]

>>> get_model_status(pipe.unet)
TunerModelStatus(
    base_model_type='other',
    adapter_model_type='None',
    peft_types={},
    trainable_params=797184,
    total_params=861115332,
    num_adapter_layers=128,
    enabled=True,
    active_adapters=['adapter-2'],
    merged_adapters=[],
    requires_grad={'adapter-1': False, 'adapter-2': True},
    available_adapters=['adapter-1', 'adapter-2'],
    devices={'adapter-1': ['cpu'], 'adapter-2': ['cuda']},
)
```
## ุฅููุงููุฉ ุฅุนุงุฏุฉ ุงูุฅูุชุงุฌ

### ุงูููุงุฐุฌ ุงูุชู ุชุณุชุฎุฏู ูุนูุงุฑ ุงูุฏูุนุฉ

ุนูุฏ ุชุญููู ูููุฐุฌ PEFT ูุฏุฑุจ ุญูุซ ูุณุชุฎุฏู ุงููููุฐุฌ ุงูุฃุณุงุณู ูุนูุงุฑ ุงูุฏูุนุฉ (ุนูู ุณุจูู ุงููุซุงูุ `torch.nn.BatchNorm1d` ุฃู `torch.nn.BatchNorm2d`)ุ ูุฏ ุชุฌุฏ ุฃูู ูุง ุชุณุชุทูุน ุฅุนุงุฏุฉ ุฅูุชุงุฌ ููุณ ุงููุฎุฑุฌุงุช ุจุงูุถุจุท. ููุฑุฌุน ุฐูู ุฅูู ุฃู ุทุจูุงุช ูุนูุงุฑ ุงูุฏูุนุฉ ุชุญุชูุธ ุจุฅุญุตุงุฆูุงุช ุงูุชุดุบูู ุฃุซูุงุก ุงูุชุฏุฑูุจุ ูููู ูุฐู ุงูุฅุญุตุงุฆูุงุช ููุณุช ุฌุฒุกูุง ูู ููุทุฉ ุชูุชูุด PEFT. ูุฐููุ ุนูุฏ ุชุญููู ูููุฐุฌ PEFTุ ูุชู ุงุณุชุฎุฏุงู ุงูุฅุญุตุงุฆูุงุช ุงูุชุดุบูููุฉ ูููููุฐุฌ ุงูุฃุณุงุณู (ุฃู ูู ูุจู ุงูุชุฏุฑูุจ ูุน PEFT).

ุงุนุชูุงุฏูุง ุนูู ุญุงูุชู ุงูุงุณุชุฎุฏุงููุฉุ ูุฏ ูุง ูููู ูุฐุง ุงูุฃูุฑ ููููุง. ุฅุฐุง ููุช ุจุญุงุฌุฉ ุฅูู ุฃู ุชููู ุงููุฎุฑุฌุงุช ูุงุจูุฉ ูุฅุนุงุฏุฉ ุงูุฅูุชุงุฌ ุจูุณุจุฉ 100ูชุ ูููููู ุชุญููู ุฐูู ุนู ุทุฑูู ุฅุถุงูุฉ ุทุจูุงุช ูุนูุงุฑ ุงูุฏูุนุฉ ุฅูู `modules_to_save`. ููููุง ููู ูุซุงู ุนูู ุฐูู ุจุงุณุชุฎุฏุงู resnet ูLoRA. ูุงุญุธ ุฃููุง ูููุง ุจุชุนููู `modules_to_save=["classifier"ุ "normalization"]`. ูุญุชุงุฌ ุฅูู ูุณูุท "ุงููุตูู" ูุฃู ูููุชูุง ูู ุชุตููู ุงูุตูุฑุ ููุถูู ูุณูุท "ุงูุชุทุจูุน" ูุถูุงู ุญูุธ ุทุจูุงุช ูุนูุงุฑ ุงูุฏูุนุฉ ูู ููุทุฉ ุชูุชูุด PEFT.

```python
from transformers import AutoModelForImageClassification
from peft import LoraConfig, get_peft_model

model_id = "microsoft/resnet-18"
base_model = AutoModelForImageClassification.from_pretrained(self.model_id)
config = LoraConfig(
    target_modules=["convolution"],
    modules_to_save=["classifier", "normalization"],
),
```

ุงุนุชูุงุฏูุง ุนูู ููุน ุงููููุฐุฌ ุงูุฐู ุชุณุชุฎุฏููุ ูุฏ ูููู ูุทุจูุงุช ูุนูุงุฑ ุงูุฏูุนุฉ ุฃุณูุงุก ูุฎุชููุฉ ุนู "ุงูุชุทุจูุน"ุ ูุฐุง ูุฑุฌู ุงูุชุฃูุฏ ูู ุฃู ุงูุงุณู ูุชุทุงุจู ูุน ุจููุฉ ูููุฐุฌู.