# ุฌููุฉ ุณุฑูุนุฉ

ูููุฑ PEFT ุทุฑููุง ูุนุงูุฉ ูู ุญูุซ ุงูุชูููุฉ ูุถุจุท ุฏูุฉ ุงูููุงุฐุฌ ุงููุณุจูุฉ ุงูุถุฎูุฉ. ุงููููุฐุฌ ุงูุชูููุฏู ูู ุถุจุท ุฏูุฉ ุฌููุน ูุนููุงุช ุงููููุฐุฌ ููู ูููุฉ ูู ููุงู ุงูุชุฏูู ุงูุณูููุ ูููู ูุฐุง ุฃุตุจุญ ูููููุง ููุบุงูุฉ ูุบูุฑ ุนููู ุจุณุจุจ ุงูุนุฏุฏ ุงููุงุฆู ูู ุงููุนููุงุช ูู ุงูููุงุฐุฌ ุงูููู. ุจุฏูุงู ูู ุฐููุ ูู ุงูุฃูุซุฑ ููุงุกุฉ ุชุฏุฑูุจ ุนุฏุฏ ุฃูู ูู ูุนููุงุช ุงูุฅุดุงุฑุฉ ุฃู ุงุณุชุฎุฏุงู ุทุฑููุฉ ุฅุนุงุฏุฉ ุงููุนูููุฉ ูุซู ุงูุชููู ููุฎูุถ ุงูุฑุชุจุฉ (LoRA) ูุชูููู ุนุฏุฏ ุงููุนููุงุช ุงููุงุจูุฉ ููุชุฏุฑูุจ.

ุณุชุนุฑุถ ูู ูุฐู ุงูุฌููุฉ ุงูุณุฑูุนุฉ ุงูููุฒุงุช ุงูุฑุฆูุณูุฉ ูู PEFT ูููููุฉ ุชุฏุฑูุจู ุฃู ุชุดุบูู ุงูุงุณุชุฏูุงู ุนูู ุงูููุงุฐุฌ ุงููุจูุฑุฉ ุงูุชู ุนุงุฏุฉ ูุง ูุชุนุฐุฑ ุงููุตูู ุฅูููุง ุนูู ุงูุฃุฌูุฒุฉ ุงูุงุณุชููุงููุฉ.

## ุชุฏุฑูุจ

ูุชู ุชุนุฑูู ูู ุทุฑููุฉ PEFT ุจูุงุณุทุฉ ูุฆุฉ [`PeftConfig`] ุงูุชู ุชุฎุฒู ุฌููุน ุงููุนููุงุช ุงููููุฉ ูุจูุงุก [`PeftModel`]. ุนูู ุณุจูู ุงููุซุงูุ ูุชุฏุฑูุจ ูุน LoRAุ ูู ุจุชุญููู ูุฅูุดุงุก ูุฆุฉ [`LoraConfig`] ูุญุฏุฏ ุงููุนููุงุช ุงูุชุงููุฉ:

- `task_type`: ุงููููุฉ ุงูุชู ุณูุชู ุงูุชุฏุฑูุจ ุนูููุง (ููุฐุฌุฉ ุงููุบุฉ ูู ุงูุชุณูุณู ุฅูู ุงูุชุณูุณู ูู ูุฐู ุงูุญุงูุฉ)
- `inference_mode`: ูุง ุฅุฐุง ููุช ุชุณุชุฎุฏู ุงููููุฐุฌ ููุงุณุชุฏูุงู ุฃู ูุง
- `r`: ุจุนุฏ ุงููุตูููุงุช ููุฎูุถุฉ ุงูุฑุชุจุฉ
- `lora_alpha`: ุนุงูู ุงูููุงุณ ูููุตูููุงุช ููุฎูุถุฉ ุงูุฑุชุจุฉ
- `lora_dropout`: ุงุญุชูุงู ุฅุณูุงุท ุทุจูุงุช LoRA

```python
from peft import LoraConfig, TaskType

peft_config = LoraConfig(task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1)
```

<Tip>
ุฑุงุฌุน ูุฑุฌุน [`LoraConfig`] ููุฒูุฏ ูู ุงูุชูุงุตูู ุญูู ุงููุนููุงุช ุงูุฃุฎุฑู ุงูุชู ููููู ุถุจุทูุงุ ูุซู ุงููุญุฏุงุช ุงููุณุชูุฏูุฉ ุฃู ููุน ุงูุงูุญูุงุฒ.
</Tip>

ุจูุฌุฑุฏ ุฅุนุฏุงุฏ [`LoraConfig`]ุ ูู ุจุฅูุดุงุก [`PeftModel`] ุจุงุณุชุฎุฏุงู ุฏุงูุฉ [`get_peft_model`]. ูุฃุฎุฐ ูููุฐุฌูุง ุฃุณุงุณููุง - ููููู ุชุญูููู ูู ููุชุจุฉ ุงููุญููุงุช - ู [`LoraConfig`] ุงูุฐู ูุญุชูู ุนูู ุงููุนููุงุช ุงูุฎุงุตุฉ ุจููููุฉ ุชูููู ูููุฐุฌ ููุชุฏุฑูุจ ูุน LoRA.

ูู ุจุชุญููู ุงููููุฐุฌ ุงูุฃุณุงุณู ุงูุฐู ุชุฑูุฏ ุถุจุท ุฏูุชู.

```python
from transformers import AutoModelForSeq2SeqLM

model = AutoModelForSeq2SeqLM.from_pretrained("bigscience/mt0-large")
```

ูู ุจุชุบููู ุงููููุฐุฌ ุงูุฃุณุงุณู ู `peft_config` ูุน ุฏุงูุฉ [`get_peft_model`] ูุฅูุดุงุก [`PeftModel`]. ููุญุตูู ุนูู ููุฑุฉ ุนู ุนุฏุฏ ุงููุนููุงุช ุงููุงุจูุฉ ููุชุฏุฑูุจ ูู ูููุฐุฌูุ ุงุณุชุฎุฏู ุทุฑููุฉ [`print_trainable_parameters`].

```python
from peft import get_peft_model

model = get_peft_model(model, peft_config)
model.print_trainable_parameters()
"output: trainable params: 2359296 || all params: 1231940608 || trainable%: 0.19151053100118282"
```

ูู ุจูู 1.2 ูููุงุฑ ูุนููุฉ ูู [bigscience/mt0-large](https://huggingface.co/bigscience/mt0-large)ุ ูุฅูู ุชุฏุฑุจ ููุท 0.19ูช ูููู!

ูุฐุง ูู ุดูุก ๐! ุงูุขู ููููู ุชุฏุฑูุจ ุงููููุฐุฌ ุจุงุณุชุฎุฏุงู ูุญููุงุช [`~transformers.Trainer`] ุฃู ุชุณุฑูุน ุฃู ุฃู ุญููุฉ ุชุฏุฑูุจ PyTorch ูุฎุตุตุฉ.

ุนูู ุณุจูู ุงููุซุงูุ ูุชุฏุฑูุจ ุจุงุณุชุฎุฏุงู ูุฆุฉ [`~transformers.Trainer`]ุ ูู ุจุฅุนุฏุงุฏ ูุฆุฉ [`~transformers.TrainingArguments`] ุจูุนููุงุช ุชุฏุฑูุจ ูุฎุชููุฉ.

```py
training_args = TrainingArguments(
    output_dir="your-name/bigscience/mt0-large-lora",
    learning_rate=1e-3,
    per_device_train_batch_size=32,
    per_device_eval_batch_size=32,
    num_train_epochs=2,
    weight_decay=0.01,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
)
```

ูุฑุฑ ุงููููุฐุฌุ ูุญุฌุฌ ุงูุชุฏุฑูุจุ ููุฌููุนุฉ ุงูุจูุงูุงุชุ ููุนุงูุฌ ุงูุชุญูููุ ูุฃู ูููู ุถุฑูุฑู ุขุฎุฑ ุฅูู [`~transformers.Trainer`]ุ ูุงุณุชุฏุนุงุก [`~transformers.Trainer.train`] ูุจุฏุก ุงูุชุฏุฑูุจ.

```py
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["test"],
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics,
)

trainer.train()
```

### ุญูุธ ุงููููุฐุฌ

ุจุนุฏ ุงูุชูุงุก ุงููููุฐุฌ ูู ุงูุชุฏุฑูุจุ ููููู ุญูุธ ูููุฐุฌู ูู ุฏููู ุจุงุณุชุฎุฏุงู ูุธููุฉ [`~transformers.PreTrainedModel.save_pretrained`].

```py
model.save_pretrained("output_dir")
```

ููููู ุฃูุถูุง ุญูุธ ูููุฐุฌู ุนูู Hub (ุชุฃูุฏ ูู ุชุณุฌูู ุงูุฏุฎูู ุฅูู ุญุณุงุจ Hugging Face ุงูุฎุงุต ุจู ุฃููุงู) ุจุงุณุชุฎุฏุงู ูุธููุฉ [`~transformers.PreTrainedModel.push_to_hub`].

```python
from huggingface_hub import notebook_login

notebook_login()
model.push_to_hub("your-name/bigscience/mt0-large-lora")
```

ุชููู ููุชุง ุงูุทุฑููุชูู ุจุญูุธ ุฃูุฒุงู PEFT ุงูุฅุถุงููุฉ ุงูุชู ุชู ุชุฏุฑูุจูุง ููุทุ ููุง ูุนูู ุฃูู ูู ุงูููุก ุฌุฏูุง ุชุฎุฒูููุง ูููููุง ูุชุญููููุง. ุนูู ุณุจูู ุงููุซุงูุ ูุญุชูู ูุฐุง ุงููููุฐุฌ [facebook/opt-350m](https://huggingface.co/ybelkada/opt-350m-lora) ุงููุฏุฑุจ ุจุงุณุชุฎุฏุงู LoRA ุนูู ููููู ููุท: `adapter_config.json` ู`adapter_model.safetensors`. ููู `adapter_model.safetensors` ูู ููุท 6.3MB!

<div class="flex flex-col justify-center">
<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/peft/PEFT-hub-screenshot.png"/>
<figcaption class="text-center">ุฃูุฒุงู ุงููุญูู ููููุฐุฌ opt-350m ุงููุฎุฒูุฉ ุนูู Hub ูู ููุท ~6MB ููุงุฑูุฉ ุจุงูุญุฌู ุงููุงูู ูุฃูุฒุงู ุงููููุฐุฌุ ูุงูุชู ูููู ุฃู ุชููู ~700MB.</figcaption>
</div>

## ุงูุงุณุชุฏูุงู

<Tip>
ุงูู ูุธุฑุฉ ุนูู ูุฑุฌุน [AutoPeftModel](package_reference/auto_class) ููุญุตูู ุนูู ูุงุฆูุฉ ูุงููุฉ ูู ูุฆุงุช `AutoPeftModel` ุงููุชุงุญุฉ.
</Tip>

ููููู ุชุญููู ุฃู ูููุฐุฌ ูุฏุฑุจ ุนูู PEFT ููุงุณุชุฏูุงู ุจุณูููุฉ ุจุงุณุชุฎุฏุงู ูุฆุฉ [`AutoPeftModel`] ูุทุฑููุฉ [`~transformers.PreTrainedModel.from_pretrained`]:

```py
from peft import AutoPeftModelForCausalLM
from transformers import AutoTokenizer
import torch

model = AutoPeftModelForCausalLM.from_pretrained("ybelkada/opt-350m-lora")
tokenizer = AutoTokenizer.from_pretrained("facebook/opt-350m")

model = model.to("cuda")
model.eval()
inputs = tokenizer("ุณุฎู ุงููุฑู ุฅูู 350 ุฏุฑุฌุฉ ูุถุน ุนุฌููุฉ ุงูููููุฒ"ุ return_tensors="pt")

outputs = model.generate(input_ids=inputs["input_ids"].to("cuda"), max_new_tokens=50)
print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0])

"ุณุฎู ุงููุฑู ุฅูู 350 ุฏุฑุฌุฉ ูุถุน ุนุฌููุฉ ุงูููููุฒ ูู ูุณุท ุงููุฑู. ูู ูุนุงุก ูุจูุฑุ ุงุฎูุทู ุงูุฏููู ูุงูุจูููุฌ ุจุงูุฏุฑ ูุตูุฏุง ุงูุฎุจุฒ ูุงูููุญ ูุงููุฑูุฉ. ูู ูุนุงุก ูููุตูุ ุงุฎููู ุตูุงุฑ ุงูุจูุถ ูุงูุณูุฑ ูุงููุงููููุง."
```

ุจุงููุณุจุฉ ููููุงู ุงูุฃุฎุฑู ุงูุชู ูุง ูุชู ุฏุนููุง ุจุดูู ุตุฑูุญ ุจุงุณุชุฎุฏุงู ูุฆุฉ `AutoPeftModelFor` - ูุซู ุงูุชุนุฑู ุงูุชููุงุฆู ุนูู ุงูููุงู - ููููู ุงุณุชุฎุฏุงู ูุฆุฉ [`AutoPeftModel`] ุงูุฃุณุงุณูุฉ ูุชุญููู ูููุฐุฌ ูููููุฉ.

```py
from peft import AutoPeftModel

model = AutoPeftModel.from_pretrained("smangrul/openai-whisper-large-v2-LORA-colab")
```

## ุงูุฎุทูุงุช ุงูุชุงููุฉ

ุงูุขู ุจุนุฏ ุฃู ุฑุฃูุช ููููุฉ ุชุฏุฑูุจ ูููุฐุฌ ุจุงุณุชุฎุฏุงู ุฅุญุฏู ุทุฑู PEFTุ ูุดุฌุนู ุนูู ุชุฌุฑุจุฉ ุจุนุถ ุงูุทุฑู ุงูุฃุฎุฑู ูุซู ุถุจุท ุฏูุฉ ุงูุฅุดุงุฑุฉ. ุงูุฎุทูุงุช ููุงุซูุฉ ูุชูู ุงูููุถุญุฉ ูู ุงูุฌููุฉ ุงูุณุฑูุนุฉ:

1. ูู ุจุฅุนุฏุงุฏ [`PeftConfig`] ูุทุฑููุฉ PEFT
2. ุงุณุชุฎุฏู ุทุฑููุฉ [`get_peft_model`] ูุฅูุดุงุก [`PeftModel`] ูู ุงูุชูููู ูุงููููุฐุฌ ุงูุฃุณุงุณู

ุจุนุฏ ุฐููุ ููููู ุชุฏุฑูุจู ุจุงูุทุฑููุฉ ุงูุชู ุชุฑูุฏูุง! ูุชุญููู ูููุฐุฌ PEFT ููุงุณุชุฏูุงูุ ููููู ุงุณุชุฎุฏุงู ูุฆุฉ [`AutoPeftModel`].

ูุง ุชุชุฑุฏุฏ ูู ุฅููุงุก ูุธุฑุฉ ุนูู ุฃุฏูุฉ ุงูููุงู ุฅุฐุง ููุช ููุชููุง ุจุชุฏุฑูุจ ูููุฐุฌ ุจุงุณุชุฎุฏุงู ุทุฑููุฉ PEFT ุฃุฎุฑู ููููุฉ ูุญุฏุฏุฉ ูุซู ุงูุชุฌุฒุฆุฉ ุงูุฏูุงููุฉ ุฃู ุงูุชุนุฑู ุงูุชููุงุฆู ุนูู ุงูููุงู ูุชุนุฏุฏ ุงููุบุงุช ุฃู DreamBooth ุฃู ุชุตููู ุงูุฑููุฒุ ูุบูุฑ ุฐูู.