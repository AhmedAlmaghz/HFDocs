# معايير الضبط الدقيق لشبكات اللغة العصبية

## معلمات خاصة بالمهمة

قد تختلف معلمات الطول المستخدمة لمدربين مختلفين. بعضها يتطلب سياقًا أكثر من غيرها.

- `block_size`: هذا هو الطول الأقصى للتسلسل أو طول كتلة واحدة من النص. يؤدي الضبط إلى -1 إلى تحديد حجم الكتلة تلقائيًا. الافتراضي هو -1.

- `model_max_length`: قم بتعيين الطول الأقصى للنمذجة لمعالجة الدفعة الواحدة، والتي يمكن أن تؤثر على كل من الأداء واستخدام الذاكرة. الافتراضي هو 1024

- `max_prompt_length`: حدد الطول الأقصى للفوارغ المستخدمة في التدريب، خاصة فيما يتعلق بالمهام التي تتطلب إدخالًا سياقيًا أوليًا. يستخدم فقط لمدرب `orpo` و`dpo`.

- `max_completion_length`: طول الإكمال الذي سيتم استخدامه، بالنسبة لـ orpo: نماذج الترميز فك الترميز فقط. بالنسبة لـ dpo، فهو طول نص الإكمال.

**ملاحظة**:

- لا يمكن أن يكون حجم الكتلة أكبر من `model_max_length`!

- لا يمكن أن يكون `max_prompt_length` أكبر من `model_max_length`!

- لا يمكن أن يكون `max_prompt_length` أكبر من `block_size`!

- لا يمكن أن يكون `max_completion_length` أكبر من `model_max_length`!

- لا يمكن أن يكون `max_completion_length` أكبر من `block_size`!

**ملاحظة**: عدم اتباع هذه القيود سيؤدي إلى خطأ / خسائر نان.

### المدرب العام

```
--add_eos_token, --add-eos-token
قم بالتبديل بين إضافة رمز نهاية الجملة (EOS) تلقائيًا في نهاية النصوص، والذي قد يكون حاسمًا لأنواع معينة
من النماذج مثل نماذج اللغة. يستخدم فقط لمدرب "افتراضي"
--block_size BLOCK_SIZE، --block-size BLOCK_SIZE
تحديد حجم الكتلة لمعالجة التسلسلات. هذا هو الطول الأقصى للتسلسل أو طول كتلة واحدة من النص. الضبط إلى
-1 يحدد حجم الكتلة تلقائيًا. الافتراضي هو -1.
--model_max_length MODEL_MAX_LENGTH، --model-max-length MODEL_MAX_LENGTH
قم بتعيين الطول الأقصى للنمذجة لمعالجة الدفعة الواحدة، والتي يمكن أن تؤثر على كل من الأداء واستخدام الذاكرة.
الافتراضي هو 1024
```

### مدرب SFT

```
--block_size BLOCK_SIZE، --block-size BLOCK_SIZE
تحديد حجم الكتلة لمعالجة التسلسلات. هذا هو الطول الأقصى للتسلسل أو طول كتلة واحدة من النص. الضبط إلى
-1 يحدد حجم الكتلة تلقائيًا. الافتراضي هو -1.
--model_max_length MODEL_MAX_LENGTH، --model-max-length MODEL_MAX_LENGTH
قم بتعيين الطول الأقصى للنمذجة لمعالجة الدفعة الواحدة، والتي يمكن أن تؤثر على كل من الأداء واستخدام الذاكرة.
الافتراضي هو 1024
```

### مدرب المكافأة

```
--block_size BLOCK_SIZE، --block-size BLOCK_SIZE
تحديد حجم الكتلة لمعالجة التسلسلات. هذا هو الطول الأقصى للتسلسل أو طول كتلة واحدة من النص. الضبط إلى
-1 يحدد حجم الكتلة تلقائيًا. الافتراضي هو -1.
--model_max_length MODEL_MAX_LENGTH، --model-max-length MODEL_MAX_LENGTH
قم بتعيين الطول الأقصى للنمذجة لمعالجة الدفعة الواحدة، والتي يمكن أن تؤثر على كل من الأداء واستخدام الذاكرة.
الافتراضي هو 1024
```

### مدرب DPO

```
--dpo-beta DPO_BETA، --dpo-beta DPO_BETA
بيتا لمدرب DPO

--model-ref MODEL_REF
نموذج مرجعي لاستخدامه في DPO عند عدم استخدام PEFT
--block_size BLOCK_SIZE، --block-size BLOCK_SIZE
تحديد حجم الكتلة لمعالجة التسلسلات. هذا هو الطول الأقصى للتسلسل أو طول كتلة واحدة من النص. الضبط إلى
-1 يحدد حجم الكتلة تلقائيًا. الافتراضي هو -1.
--model_max_length MODEL_MAX_LENGTH، --model-max-length MODEL_MAX_LENGTH
قم بتعيين الطول الأقصى للنمذجة لمعالجة الدفعة الواحدة، والتي يمكن أن تؤثر على كل من الأداء واستخدام الذاكرة.
الافتراضي هو 1024
--max_prompt_length MAX_PROMPT_LENGTH، --max-prompt-length MAX_PROMPT_LENGTH
تحديد الطول الأقصى للفوارغ المستخدمة في التدريب، خاصة فيما يتعلق بالمهام التي تتطلب إدخالًا سياقيًا أوليًا.
يستخدم فقط لمدرب "orpo".
--max_completion_length MAX_COMPLETION_LENGTH، --max-completion-length MAX_COMPLETION_LENGTH
طول الإكمال الذي سيتم استخدامه، بالنسبة لـ orpo: نماذج الترميز فك الترميز فقط
```

### مدرب ORPO

```
--block_size BLOCK_SIZE، --block-size BLOCK_SIZE
تحديد حجم الكتلة لمعالجة التسلسلات. هذا هو الطول الأقصى للتسلسل أو طول كتلة واحدة من النص. الضبط إلى
-1 يحدد حجم الكتلة تلقائيًا. الافتراضي هو -1.
--model_max_length MODEL_MAX_LENGTH، --model-max-length MODEL_MAX_LENGTH
قم بتعيين الطول الأقصى للنمذجة لمعالجة الدفعة الواحدة، والتي يمكن أن تؤثر على كل من الأداء واستخدام الذاكرة.
الافتراضي هو 1024
--max_prompt_length MAX_PROMPT_LENGTH، --max-prompt-length MAX_PROMPT_LENGTH
تحديد الطول الأقصى للفوارغ المستخدمة في التدريب، خاصة فيما يتعلق بالمهام التي تتطلب إدخالًا سياقيًا أوليًا.
يستخدم فقط لمدرب "orpo".
--max_completion_length MAX_COMPLETION_LENGTH، --max-completion-length MAX_COMPLETION_LENGTH
طول الإكمال الذي سيتم استخدامه، بالنسبة لـ orpo: نماذج الترميز فك الترميز فقط
```

## المعلمات العامة

```
--batch-size BATCH_SIZE، --train-batch-size BATCH_SIZE
حجم الدفعة التدريبية التي سيتم استخدامها
--seed SEED           البذور العشوائية لإمكانية التكرار
--epochs EPOCHS       عدد دورات التدريب
--gradient_accumulation GRADIENT_ACCUMULATION، --gradient-accumulation GRADIENT_ACCUMULATION
خطوات تراكم التدرج
--disable_gradient_checkpointing، --disable-gradient-checkpointing، --disable-gc
تعطيل نقطة تفتيش التدرج
--lr LR               معدل التعلم
--log {none,wandb,tensorboard}
استخدم تتبع التجربة
--warmup_ratio WARMUP_RATIO، --warmup-ratio WARMUP_RATIO
حدد نسبة التدريب المخصصة لتسخين معدل التعلم، والذي يمكن أن يعزز استقرار النموذج والأداء
في بداية التدريب. الافتراضي هو 0.1
--optimizer OPTIMIZER
اختر خوارزمية المحسن لتدريب النموذج. يمكن أن تؤثر المحسنات المختلفة على سرعة التدريب وأداء النموذج.
يتم استخدام "adamw_torch" بشكل افتراضي.
--scheduler SCHEDULER
حدد جدولة معدل التعلم لتعديل معدل التعلم بناءً على عدد دورات التدريب. يقلل "الخطي"
معدل التعلم الخطي من معدل التعلم الأولي المحدد. الافتراضي هو "خطي". جرب "التناسب الكوسيني" لجدول التناسب الكوسيني.
--weight_decay WEIGHT_DECAY، --weight-decay WEIGHT_DECAY
تحديد معدل اضمحلال الوزن للتنظيم، والذي يساعد في منع الإفراط في التكييف عن طريق معاقبة الأوزان الأكبر. الافتراضي هو
0.0
--max_grad_norm MAX_GRAD_NORM، --max-grad-norm MAX_GRAD_NORM
قم بتعيين الحد الأقصى للقاعدة لتدرج القص، والذي يعد أمرًا بالغ الأهمية لمنع الانفجارات التدرجية أثناء
الانتشار الخلفي. الافتراضي هو 1.0.
--peft، --use-peft    تمكين LoRA-PEFT
--lora_r LORA_R، --lora-r LORA_R
قم بتعيين معلمة "r" للتكيف منخفض الرتبة (LoRA). الافتراضي هو 16.
--lora_alpha LORA_ALPHA، --lora-alpha LORA_ALPHA
تحديد معلمة "ألفا" لـ LoRA. الافتراضي هو 32.
--lora_dropout LORA_DROPOUT، --lora-dropout LORA_DROPOUT
قم بتعيين معدل التسرب داخل طبقات LoRA للمساعدة في منع الإفراط في التكيف أثناء التكيف. الافتراضي هو 0.05.
--logging_steps LOGGING_STEPS، --logging-steps LOGGING_STEPS
تحديد مدى تكرار تسجيل تقدم التدريب من حيث الخطوات. يؤدي الضبط إلى "-1" إلى تحديد خطوات التسجيل تلقائيًا.
--eval_strategy {epoch، steps، no}، --eval-strategy {epoch، steps، no}
اختر مدى تكرار تقييم أداء النموذج، مع "epoch" كافتراضي، مما يعني في نهاية كل دورة تدريب
--save_total_limit SAVE_TOTAL_LIMIT، --save-total-limit SAVE_TOTAL_LIMIT
قم بتقييد العدد الإجمالي لنقاط تفتيش النموذج المحفوظة لإدارة استخدام القرص بفعالية. الافتراضي هو حفظ
فقط أحدث نقطة تفتيش
--auto_find_batch_size، --auto-find-batch-size
حدد تلقائيًا حجم الدفعة الأمثل بناءً على قدرات النظام لتعظيم الكفاءة.
--mixed_precision {fp16، bf16، None}، --mixed-precision {fp16، bf16، None}
اختر وضع الدقة للتدريب لتحسين الأداء واستخدام الذاكرة. الخيارات هي "fp16" أو "bf16" أو None للدقة الافتراضية.
الافتراضي هو None.
--quantization {int4، int8، None}، --quantization {int4، int8، None}
اختر مستوى التقريب لخفض حجم النموذج وزيادة سرعة الاستدلال المحتملة. تشمل الخيارات "int4" أو "int8"
أو لا شيء. يتطلب التمكين --peft
--trainer {default، dpo، sft، orpo، reward}
نوع المدرب الذي سيتم استخدامه
--target_modules TARGET_MODULES، --target-modules TARGET_MODULES
تحديد وحدات محددة داخل بنية النموذج لاستهدافها بالتكيفات أو التحسينات، مثل LoRA. قائمة مفصولة بفواصل
أسماء الوحدات. الافتراضي هو "all-linear".
--merge_adapter، --merge-adapter
استخدم هذا العلم لدمج محول PEFT مع النموذج
--use_flash_attention_2، --use-flash-attention-2، --use-fa2
استخدم الاهتمام بالوميض 2
--chat_template {tokenizer، chatml، zephyr، None}، --chat-template {tokenizer، chatml، zephyr، None}
تطبيق قالب محدد للتفاعلات القائمة على الدردشة، مع خيارات بما في ذلك "tokenizer" أو "chatml" أو "zephyr" أو None.
يمكن لهذا الإعداد تشكيل سلوك النموذج المحادثي.
--padding {left، right، None}، --padding {left، right، None}
تحديد اتجاه الحشو للتسلسلات، وهو أمر بالغ الأهمية للنماذج الحساسة لمحاذاة الإدخال. تشمل الخيارات "left"
"يمين" أو لا شيء
```