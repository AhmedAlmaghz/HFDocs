# الاستدلال الأمثل مع ONNX Runtime
Optimum هي حزمة برامج مساعدة لبناء وتشغيل الاستدلال مع وقت التشغيل المعجل مثل ONNX Runtime.
يمكن استخدام Optimum لتحميل النماذج المحسنة من [Hugging Face Hub](hf.co/models) وإنشاء خطوط أنابيب
لتشغيل الاستدلال المعجل دون إعادة كتابة واجهات برمجة التطبيقات الخاصة بك.

## التبديل من المحولات إلى الأمثل
فئات نموذج `optimum.onnxruntime.ORTModelForXXX` متوافقة مع واجهة برمجة تطبيقات نماذج Hugging Face Transformers. وهذا
يعني أنه يمكنك فقط استبدال فئة `AutoModelForXXX` الخاصة بك بالفئة المقابلة `ORTModelForXXX` في `optimum.onnxruntime`.

لا تحتاج إلى تكييف رمزك لجعله يعمل مع فئات `ORTModelForXXX`:

```diff
from transformers import AutoTokenizer, pipeline
-from transformers import AutoModelForQuestionAnswering
+from optimum.onnxruntime import ORTModelForQuestionAnswering

-model = AutoModelForQuestionAnswering.from_pretrained("deepset/roberta-base-squad2") # PyTorch checkpoint
+model = ORTModelForQuestionAnswering.from_pretrained("optimum/roberta-base-squad2") # ONNX checkpoint
tokenizer = AutoTokenizer.from_pretrained("deepset/roberta-base-squad2")

onnx_qa = pipeline("question-answering",model=model,tokenizer=tokenizer)

question = "What's my name?"
context = "My name is Philipp and I live in Nuremberg."
pred = onnx_qa(question, context)
```

### تحميل نموذج Transformers عادي
لأن النموذج الذي تريد العمل معه قد لا يكون محولًا بالفعل إلى ONNX، يتضمن [`~optimum.onnxruntime.ORTModel`]
طريقة لتحويل نماذج Transformers العادية إلى تنسيق ONNX. ما عليك سوى تمرير `export=True` إلى
طريقة [`~optimum.onnxruntime.ORTModel.from_pretrained`]`~optimum.onnxruntime.ORTModel.from_pretrained`، وسيتم تحميل نموذجك وتحويله إلى ONNX أثناء التنقل:

```python
>>> from optimum.onnxruntime import ORTModelForSequenceClassification

>>> # قم بتحميل النموذج من المركز وتصديره إلى تنسيق ONNX
>>> model = ORTModelForSequenceClassification.from_pretrained(
...     "distilbert-base-uncased-finetuned-sst-2-english", export=True
... )
```

### دفع نماذج ONNX إلى Hugging Face Hub
من الممكن أيضًا، كما هو الحال مع [`~transformers.PreTrainedModel`]s العادية، دفع `ORTModelForXXX` إلى
[Hugging Face Model Hub](https://hf.co/models):

```python
>>> from optimum.onnxruntime import ORTModelForSequenceClassification

>>> # قم بتحميل النموذج من المركز وتصديره إلى تنسيق ONNX
>>> model = ORTModelForSequenceClassification.from_pretrained(
...     "distilbert-base-uncased-finetuned-sst-2-english", export=True
... )

>>> # حفظ النموذج المحول
>>> model.save_pretrained("a_local_path_for_convert_onnx_model")

# ادفع نموذج onnx إلى HF Hub
>>> model.push_to_hub(  # doctest: +SKIP
...   "a_local_path_for_convert_onnx_model", repository_id="my-onnx-repo", use_auth_token=True
... )
```

## نماذج التسلسل إلى التسلسل
يمكن أيضًا استخدام نماذج التسلسل إلى التسلسل (Seq2Seq) عند تشغيل الاستدلال باستخدام ONNX Runtime. عندما يتم تصدير نماذج Seq2Seq
إلى تنسيق ONNX، يتم تقسيمها إلى ثلاثة أجزاء يتم دمجها لاحقًا أثناء الاستدلال:

- الجزء المشفر للنموذج
- الجزء فك تشفير النموذج + رأس النمذجة اللغوية
- نفس الجزء فك تشفير النموذج + رأس النمذجة اللغوية ولكن مع إدخال واستخدام القيم الرئيسية / القيم المحسوبة مسبقًا كإدخالات ومخرجات. يجعل هذا الاستدلال أسرع.

فيما يلي مثال على كيفية تحميل نموذج T5 إلى تنسيق ONNX وتشغيل الاستدلال لمهمة الترجمة:

```python
>>> from transformers import AutoTokenizer, pipeline
>>> from optimum.onnxruntime import ORTModelForSeq2SeqLM

# قم بتحميل النموذج من المركز وتصديره إلى تنسيق ONNX
>>> model_name = "t5-small"
>>> model = ORTModelForSeq2SeqLM.from_pretrained(model_name, export=True)
>>> tokenizer = AutoTokenizer.from_pretrained(model_name)

# إنشاء خط أنابيب
>>> onnx_translation = pipeline("translation_en_to_fr"، model=model، tokenizer=tokenizer)
>>> text = "He never went out without a book under his arm, and he often came back with two."
>>> result = onnx_translation(text)
>>> # [{'translation_text': "Il n'est jamais sorti sans un livre sous son bras, et il est souvent revenu avec deux."}]
```

## الانتشار المستقر
يمكن أيضًا استخدام نماذج Stable Diffusion عند تشغيل الاستدلال باستخدام ONNX Runtime. عندما يتم تصدير نماذج Stable Diffusion
إلى تنسيق ONNX، يتم تقسيمها إلى أربعة مكونات يتم دمجها لاحقًا أثناء الاستدلال:

- مشفر النص
- U-NET
- فك تشفير VAE
- فك تشفير VAE

تأكد من تثبيت 🤗 Diffusers.

لتثبيت `diffusers`:

```bash
pip install diffusers
```

### نص إلى صورة
فيما يلي مثال على كيفية تحميل نموذج ONNX Stable Diffusion وتشغيل الاستدلال باستخدام ONNX Runtime:

```python
from optimum.onnxruntime import ORTStableDiffusionPipeline

model_id = "runwayml/stable-diffusion-v1-5"
pipeline = ORTStableDiffusionPipeline.from_pretrained(model_id, revision="onnx")
prompt = "sailing ship in storm by Leonardo da Vinci"
image = pipeline(prompt).images[0]
```

لتحميل نموذج PyTorch الخاص بك وتحويله إلى ONNX أثناء التنقل، يمكنك تعيين `export=True`.

```python
pipeline = ORTStableDiffusionPipeline.from_pretrained(model_id, export=True)

# لا تنس حفظ نموذج ONNX
save_directory = "a_local_path"
pipeline.save_pretrained(save_directory)
```

<div class="flex justify-center">
<img src="https://huggingface.co/datasets/optimum/documentation-images/resolve/main/onnxruntime/stable_diffusion_v1_5_ort_sail_boat.png">
</div>

### صورة إلى صورة

```python
import requests
import torch
from PIL import Image
from io import BytesIO
from optimum.onnxruntime import ORTStableDiffusionImg2ImgPipeline

model_id = "runwayml/stable-diffusion-v1-5"
pipeline = ORTStableDiffusionImg2ImgPipeline.from_pretrained(model_id, revision="onnx")

url = "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg"

response = requests.get(url)
init_image = Image.open(BytesIO(response.content)).convert("RGB")
init_image = init_image.resize((768, 512))

prompt = "A fantasy landscape, trending on artstation"

image = pipeline(prompt=prompt, image=init_image, strength=0.75, guidance_scale=7.5).images[0]
image.save("fantasy_landscape.png")
```

### إصلاح

```python
import PIL
import requests
import torch
from io import BytesIO
from optimum.onnxruntime import ORTStableDiffusionInpaintPipeline

model_id = "runwayml/stable-diffusion-inpainting"
pipeline = ORTStableDiffusionInpaintPipeline.from_pretrained(model_id, revision="onnx")

def download_image(url):
response = requests.get(url)
return PIL.Image.open(BytesIO(response.content)).convert("RGB")

img_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
mask_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"

init_image = download_image(img_url).resize((512, 512))
mask_image = download_image(mask_url).resize((512, 512))

prompt = "Face of a yellow cat, high resolution, sitting on a park bench"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image).images[0]
```

## الانتشار المستقر XL
قبل استخدام `ORTStableDiffusionXLPipeline`، تأكد من تثبيت `diffusers` و`invisible_watermark`. يمكنك تثبيت المكتبات على النحو التالي:

```bash
pip install diffusers
pip install invisible-watermark>=0.2.0
```

### نص إلى صورة
فيما يلي مثال على كيفية تحميل نموذج SDXL ONNX من [stabilityai/stable-diffusion-xl-base-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0) وتشغيل الاستدلال باستخدام ONNX Runtime:

```python
from optimum.onnxruntime import ORTStableDiffusionXLPipeline

model_id = "stabilityai/stable-diffusion-xl-base-1.0"
base = ORTStableDiffusionXLPipeline.from_pretrained(model_id)
prompt = "sailing ship in storm by Leonardo da Vinci"
image = base(prompt).images[0]

# لا تنس حفظ نموذج ONNX
save_directory = "sd_xl_base"
base.save_pretrained(save_directory)
```

### صورة إلى صورة
فيما يلي مثال على كيفية تحميل نموذج PyTorch SDXL، وتحويله إلى ONNX أثناء التنقل، وتشغيل الاستدلال باستخدام ONNX Runtime لـ *image-to-image*:

```python
from optimum.onnxruntime import ORTStableDiffusionXLImg2ImgPipeline
from diffusers.utils import load_image

model_id = "stabilityai/stable-diffusion-xl-refiner-1.0"
pipeline = ORTStableDiffusionXLImg2ImgPipeline.from_pretrained(model_id, export=True)

url = "https://huggingface.co/datasets/optimum/documentation-images/resolve/main/intel/openvino/sd_xl/castle_friedrich.png"
image = load_image(url).convert("RGB")
prompt = "medieval castle by Caspar David Friedrich"
image = pipeline(prompt, image=image).images[0]
image.save("medieval_castle.png")
```

### تحسين إخراج الصورة
يمكن تحسين الصورة باستخدام نموذج مثل [stabilityai/stable-diffusion-xl-refiner-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0). في هذه الحالة، تحتاج فقط إلى إخراج المخفونات من النموذج الأساسي.

```python
from optimum.onnxruntime import ORTStableDiffusionXLImg2ImgPipeline

model_id = "stabilityai/stable-diffusion-xl-refiner-1.0"
refiner = ORTStableDiffusionXLImg2ImgPipeline.from_pretrained(model_id, export=True)

image = base(prompt=prompt, output_type="latent").images[0]
image = refiner(prompt=prompt, image=image[None, :]).images[0]
image.save("sailing_ship.png")
```

## نماذج الاتساق الكامنة

### نص إلى صورة
فيما يلي مثال على كيفية تحميل نماذج اتساق الكامنة (LCMs) من [SimianLuo/LCM_Dreamshaper_v7](https://huggingface.co/SimianLuo/LCM_Dreamshaper_v7) وتشغيل الاستدلال باستخدام ONNX Runtime:

```python
from optimum.onnxruntime import ORTLatentConsistencyModelPipeline

model_id = "SimianLuo/LCM_Dreamshaper_v7"
pipeline = ORTLatentConsistencyModelPipeline.from_pretrained(model_id, export=True)
prompt = "sailing ship in storm by Leonardo da Vinci"
images = pipeline(prompt، num_inference_steps=4، guidance_scale=8.0).images
```