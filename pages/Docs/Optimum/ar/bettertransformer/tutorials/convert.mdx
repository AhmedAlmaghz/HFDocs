# ููููุฉ ุงุณุชุฎุฏุงู `optimum` ู`BetterTransformer`ุ

## ุชุซุจูุช ุงูุชุจุนูุงุช

ููููู ุจุณูููุฉ ุงุณุชุฎุฏุงู ุชูุงูู `BetterTransformer` ูุน ๐ค Optimumุ ูู ุฃููุงู ุจุชุซุจูุช ุงูุชุจุนูุงุช ููุง ููู:

```bash
pip install transformers accelerate optimum
```

ุชุฃูุฏ ุฃูุถูุง ูู ุชุซุจูุช ุฃุญุฏุซ ุฅุตุฏุงุฑ ูู PyTorch ุจุงุชุจุงุน ุงูุฅุฑุดุงุฏุงุช ุนูู [ุงููููุน ุงูุฑุณูู ูู PyTorch](https://pytorch.org/get-started/locally/). ูุงุญุธ ุฃู ูุงุฌูุฉ ุจุฑูุฌุฉ ุชุทุจููุงุช `BetterTransformer` ูุชูุงููุฉ ููุท ูุน `torch>=1.13`ุ ูุฐูู ุชุฃูุฏ ูู ุชุซุจูุช ูุฐุง ุงูุฅุตุฏุงุฑ ุนูู ุจูุฆุชู ูุจู ุงูุจุฏุก.

ุฅุฐุง ููุช ุชุฑูุฏ ุงูุงุณุชูุงุฏุฉ ูู ุฏุงูุฉ `scaled_dot_product_attention` (ููููุงุฐุฌ ุงููุณุชูุฏุฉ ุฅูู ูู ุงูุชุดููุฑ)ุ ุชุฃูุฏ ูู ุงุณุชุฎุฏุงู `torch>=2.0` ุนูู ุงูุฃูู.

## ุงูุฎุทูุฉ 1: ูู ุจุชุญููู ูููุฐุฌู

ูู ุฃููุงู ุจุชุญููู ูููุฐุฌ Hugging Face ุจุงุณุชุฎุฏุงู ๐ค Transformers. ุชุฃูุฏ ูู ุชูุฒูู ุฃุญุฏ ุงูููุงุฐุฌ ุงููุฏุนููุฉ ูู ูุจู ูุงุฌูุฉ ุจุฑูุฌุฉ ุชุทุจููุงุช `BetterTransformer`:

```python
>>> from transformers import AutoModel

>>> model_id = "roberta-base"
>>> model = AutoModel.from_pretrained(model_id)
```

<Tip>
ูู ุจุนุถ ุงูุฃุญูุงูุ ููููู ุชุญููู ูููุฐุฌู ูุจุงุดุฑุฉ ุนูู ุฃุฌูุฒุฉ GPU ุจุงุณุชุฎุฏุงู ููุชุจุฉ `accelerate`ุ ูุฐูู ููููู ุชุฌุฑุจุฉ ุงูุฃูุฑ ุงูุชุงูู ุจุดูู ุงุฎุชูุงุฑู:
</Tip>

```python
>>> from transformers import AutoModel

>>> model_id = "roberta-base"
>>> model = AutoModel.from_pretrained(model_id, device_map="auto")
```

## ุงูุฎุทูุฉ 2: ูู ุจุชุนููู ูููุฐุฌู ุนูู ุงูุฌูุงุฒ ุงูููุถู ูุฏูู

ุฅุฐุง ูู ุชุณุชุฎุฏู `device_map="auto"` ูุชุญููู ูููุฐุฌู (ุฃู ุฅุฐุง ูู ููู ูููุฐุฌู ูุฏุนู `device_map="auto"`)ุ ูููููู ุชุนููู ูููุฐุฌู ูุฏูููุง ุนูู GPU:

```python
>>> model = model.to(0) # ุฃู model.to("cuda:0")
```

## ุงูุฎุทูุฉ 3: ูู ุจุชุญููู ูููุฐุฌู ุฅูู BetterTransformer!

ุงูุขู ุญุงู ุงูููุช ูุชุญููู ูููุฐุฌู ุจุงุณุชุฎุฏุงู ูุงุฌูุฉ ุจุฑูุฌุฉ ุชุทุจููุงุช `BetterTransformer`! ููููู ุชุดุบูู ุงูุฃูุงูุฑ ุฃุฏูุงู:

```python
>>> from optimum.bettertransformer import BetterTransformer

>>> model = BetterTransformer.transform(model)
```

ุจุดูู ุงูุชุฑุงุถูุ ุณูููู `BetterTransformer.transform` ุจูุชุงุจุฉ ูููุฐุฌูุ ููุง ูุนูู ุฃูู ูู ููููู ุงุณุชุฎุฏุงู ูููุฐุฌู ุงูุฃุตูู ุงูุฃุตูู ุจุนุฏ ุงูุขู. ุฅุฐุง ููุช ุชุฑูุฏ ุงูุงุญุชูุงุธ ุจู ูุฃู ุณุจุจุ ููู ููุท ุจุฅุถุงูุฉ ุนูุงูุฉ `keep_original_model=True`!

```python
>>> from optimum.bettertransformer import BetterTransformer

>>> model_bt = BetterTransformer.transform(model, keep_original_model=True)
```

ุฅุฐุง ูู ููู ูููุฐุฌู ูุฏุนู ูุงุฌูุฉ ุจุฑูุฌุฉ ุชุทุจููุงุช `BetterTransformer`ุ ูุณูุชู ุนุฑุถ ุฐูู ูู ุชุชุจุน ุงูุฎุทุฃ. ูุงุญุธ ุฃูุถูุง ุฃู ุงูููุงุฐุฌ ุงููุณุชูุฏุฉ ุฅูู ูู ุงูุชุดููุฑ (OPT ู BLOOMุ ุฅูุฎ) ุบูุฑ ูุฏุนููุฉ ุญุงูููุง ูููููุง ูุฏุฑุฌุฉ ูู ุฎุงุฑุทุฉ ุทุฑูู PyTorch ูููุณุชูุจู.

## ุชูุงูู ุงูุฃูุงุจูุจ

[ุฃูุจูุจ ุงููุญููุงุช](https://huggingface.co/docs/transformers/main_classes/pipelines) ูุชูุงูู ุฃูุถูุง ูุน ูุฐุง ุงูุชูุงูู ูููููู ุงุณุชุฎุฏุงู `BetterTransformer` ููุณุฑุน ูุฃูุงุจูุจู. ุชูุถุญ ููุชุทูุงุช ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ ุฃุฏูุงู ููููุฉ ุงูููุงู ุจุฐูู:

```python
>>> from optimum.pipelines import pipeline

>>> pipe = pipeline("fill-mask", "distilbert-base-uncased", accelerator="bettertransformer")
>>> pipe("I am a student at [MASK] University.")
```

ุฅุฐุง ููุช ุชุฑูุฏ ุชุดุบูู ุฃูุจูุจ ุนูู ุฌูุงุฒ GPUุ ููู ุจุชุดุบูู:

```python
>>> from optimum.pipelines import pipeline

>>> pipe = pipeline("fill-mask", "distilbert-base-uncased", accelerator="bettertransformer", device=0)
>>> ...
```

ููููู ุฃูุถูุง ุงุณุชุฎุฏุงู `transformers.pipeline` ูุงููุนุชุงุฏ ููุฑุฑ ุงููููุฐุฌ ุงููุญูู ูุจุงุดุฑุฉู:

```python
>>> from transformers import pipeline

>>> pipe = pipeline("fill-mask", model=model_bt, tokenizer=tokenizer, device=0)
>>> ...
```

ูุฑุฌู ุงูุฑุฌูุน ุฅูู [ุงููุซุงุฆู ุงูุฑุณููุฉ ูู `pipeline`](https://huggingface.co/docs/transformers/main_classes/pipelines) ููุฒูุฏ ูู ุงูุงุณุชุฎุฏุงู. ุฅุฐุง ูุงุฌูุชู ุฃู ูุดููุฉุ ูุง ุชุชุฑุฏุฏ ูู ูุชุญ ูุดููุฉ ุนูู GitHub!

## ุชูุงูู ุงูุชุฏุฑูุจ

ุงูุขู ููููู ุงูุงุณุชูุงุฏุฉ ูู ูุงุฌูุฉ ุจุฑูุฌุฉ ุชุทุจููุงุช `BetterTransformer` ูุจุฑุงูุฌ ุงูุชุฏุฑูุจ ุงูุฎุงุตุฉ ุจู. ุชุฃูุฏ ููุท ูู ุฅุนุงุฏุฉ ุชุญููู ูููุฐุฌู ุฅูู ุฅุตุฏุงุฑู ุงูุฃุตูู ุนู ุทุฑูู ุงุณุชุฏุนุงุก `BetterTransformer.reverse` ูุจู ุญูุธ ูููุฐุฌู.

ุชูุถุญ ููุชุทูุงุช ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ ุฃุฏูุงู ููููุฉ ุงูููุงู ุจุฐูู:

```python
from optimum.bettertransformer import BetterTransformer
from transformers import AutoModelForCausalLM

with torch.device("cuda"):
    model = AutoModelForCausalLM.from_pretrained("gpt2-large", torch_dtype=torch.float16)

model = BetterTransformer.transform(model)

# ูู ุจุงูุงุณุชุฏูุงู ุฃู ุงูุชุฏุฑูุจ ููุง

# ุฅุฐุง ููุช ุชููู ุจุงูุชุฏุฑูุจ ูุชุฑูุฏ ุญูุธ ุงููููุฐุฌ
model = BetterTransformer.reverse(model)
model.save_pretrained("fine_tuned_model")
model.push_to_hub("fine_tuned_model")
```