# إضافة دعم لبنية غير مدعومة

إذا كنت ترغب في تصدير نموذج لا تدعمه المكتبة حاليًا، فإليك الخطوات الرئيسية التي يجب اتباعها:

1. تنفيذ تكوين ONNX مخصص.
2. قم بتسجيل تكوين ONNX في [`~optimum.exporters.TasksManager`].
3. قم بتصدير النموذج إلى ONNX.
4. التحقق من صحة الإخراج للنموذج الأصلي والمصدّر.

في هذا القسم، سنلقي نظرة على كيفية تنفيذ BERT لإظهار ما ينطوي عليه كل خطوة.

## تنفيذ تكوين ONNX مخصص

لنبدأ مع كائن تكوين ONNX. نقدم [تسلسل هرمي للصفوف](/exporters/onnx/package_reference/configuration) من ثلاثة مستويات، ولإضافة الدعم لنموذج ما، سيكون التوارث من صف الفئة المتوسطة هو الطريقة الصحيحة في معظم الأحيان. قد تحتاج إلى تنفيذ فئة متوسطة بنفسك إذا كنت تضيف بنية لمعالجة طريقة أو حالة لم يسبق رؤيتها.

<Tip>

طريقة جيدة لتنفيذ تكوين ONNX مخصص هي النظر في تنفيذات التكوين الموجودة في
ملف `optimum/exporters/onnx/model_configs.py`.

أيضًا، إذا كانت البنية التي تحاول إضافتها (مماثلة جدًا) لبنية مدعومة بالفعل
(على سبيل المثال، إضافة دعم لـ ALBERT عندما يكون BERT مدعومًا بالفعل)، فقد يعمل التوارث البسيط من هذه الفئة.

</Tip>

عند التوارث من فئة متوسطة، ابحث عن الفئة التي تتعامل مع نفس طريقة / فئة النماذج التي تحاول دعمها.

### مثال: إضافة الدعم لـ BERT

نظرًا لأن BERT هو نموذج ترميز يعتمد على النص، فإنه يرث تكوينه من فئة المستوى المتوسط [`~optimum.exporters.onnx.config.TextEncoderOnnxConfig`].

في `optimum/exporters/onnx/model_configs.py`:

```python
# تقع هذه الفئة بالفعل في optimum/exporters/onnx/config.py
class TextEncoderOnnxConfig(OnnxConfig):
# يصف كيفية إنشاء إدخالات وهمية.
DUMMY_INPUT_GENERATOR_CLASSES = (DummyTextInputGenerator,)

class BertOnnxConfig(TextEncoderOnnxConfig):
# يحدد كيفية تطبيع BertConfig، وهو مطلوب للوصول إلى السمات الشائعة
# أثناء توليد الإدخال الوهمي.
NORMALIZED_CONFIG_CLASS = NormalizedTextConfig
# يحدد التسامح المطلق عند التحقق من صحة نموذج ONNX المصدر
# مقابل النموذج المرجعي.
ATOL_FOR_VALIDATION = 1e-4

@property
def inputs(self) -> Dict[str, Dict[int, str]]:
if self.task == "multiple-choice":
dynamic_axis = {0: "batch_size", 1: "num_choices", 2: "sequence_length"}
else:
dynamic_axis = {0: "batch_size", 1: "sequence_length"}
return {
"input_ids": dynamic_axis,
"attention_mask": dynamic_axis,
"token_type_ids": dynamic_axis,
}
```

أولاً، دعنا نشرح ما `TextEncoderOnnxConfig` هو كل شيء. في حين أن معظم الميزات يتم تنفيذها بالفعل في `OnnxConfig`،
هذه الفئة لا علاقة لها بالطريقة، وهذا يعني أنها لا تعرف نوع الإدخالات التي يجب أن تتعامل معها. تتم معالجة طريقة إنشاء الإدخال
عبر `DUMMY_INPUT_GENERATOR_CLASSES` السمة، والتي هي عبارة عن مجموعة من [`~optimum.utils.input_generators.DummyInputGenerator`]s.
هنا نقوم بإنشاء تكوين واعي بالطريقة يرث من `OnnxConfig` عن طريق تحديد
`DUMMY_INPUT_GENERATOR_CLASSES = (DummyTextInputGenerator,)`.

ثم يأتي فئة محددة للنموذج، `BertOnnxConfig`. يتم تحديد سمة فئة اثنين هنا:

- `NORMALIZED_CONFIG_CLASS`: يجب أن يكون هذا [`~optimum.utils.normalized_config.NormalizedConfig`]، فهو يسمح
مولد الإدخال للوصول إلى سمات تكوين النموذج بطريقة عامة.
- `ATOL_FOR_VALIDATION`: يتم استخدامه للتحقق من صحة النموذج المصدر مقابل الأصلي، وهذا هو
التسامح المطلق المقبول لاختلاف قيم الإخراج.

يجب أن يقوم كائن التكوين بتنفيذ خاصية [`~optimum.exporters.onnx.OnnxConfig.inputs`] وإرجاع خريطة، حيث يتوافق كل مفتاح مع اسم إدخال، ويشير كل قيمة إلى المحاور الديناميكية في هذا الإدخال.

بالنسبة لـ BERT، يمكننا أن نرى أن هناك ثلاثة مدخلات مطلوبة: `input_ids`، `attention_mask` و`token_type_ids`.
هذه الإدخالات لها نفس الشكل `(batch_size، sequence_length)` (باستثناء مهمة `multiple-choice`)، ولهذا السبب نرى نفس المحاور المستخدمة في التكوين.

بمجرد تنفيذ تكوين ONNX، يمكنك إنشاء مثيل منه عن طريق توفير تكوين النموذج الأساسي كما يلي:

```python
>>> from transformers import AutoConfig
>>> from optimum.exporters.onnx.model_configs import BertOnnxConfig
>>> config = AutoConfig.from_pretrained("bert-base-uncased")
>>> onnx_config = BertOnnxConfig(config)
```

يحتوي الكائن الناتج على العديد من الخصائص المفيدة. على سبيل المثال، يمكنك عرض مجموعة مشغلي ONNX التي سيتم استخدامها أثناء التصدير:

```python
>>> print(onnx_config.DEFAULT_ONNX_OPSET)
11
```

يمكنك أيضًا عرض الإخراج المرتبط بالنموذج كما يلي:

```python
>>> print(onnx_config.outputs)
OrderedDict([('last_hidden_state', {0: 'batch_size', 1: 'sequence_length'})])
```

لاحظ أن خاصية الإخراج تتبع نفس بنية الإدخالات؛ فهو يعيد `OrderedDict` من الإخراج المسمى وأشكالهم. ترتبط بنية الإخراج
باختيار المهمة التي يتم تهيئة التكوين بها. بشكل افتراضي، يتم تهيئة تكوين ONNX بالمهمة `default` التي تتوافق مع تصدير
نموذج محمل باستخدام فئة `AutoModel`. إذا كنت تريد تصدير نموذج لمهمة أخرى، فقم فقط بتوفير مهمة مختلفة للحجة `task` عند تهيئة تكوين ONNX. على سبيل المثال، إذا كنا نرغب في تصدير BERT برأس تصنيف تسلسل، فيمكننا استخدام ما يلي:

```python
>>> from transformers import AutoConfig

>>> config = AutoConfig.from_pretrained("bert-base-uncased")
>>> onnx_config_for_seq_clf = BertOnnxConfig(config, task="text-classification")
>>> print(onnx_config_for_seq_clf.outputs)
OrderedDict([('logits', {0: 'batch_size'})])
```

<Tip>

تحقق من [`BartOnnxConfig`] لمثال متقدم.

</Tip>

## تسجيل تكوين ONNX في TasksManager

[`~optimum.exporters.tasks.TasksManager`] هي نقطة الدخول الرئيسية لتحميل نموذج معين باسم ومهمة،
وللحصول على التكوين الصحيح لزوج (بنية، خلفية). عند إضافة الدعم للتصدير إلى ONNX،
سيؤدي تسجيل التكوين في `TasksManager` إلى جعل التصدير متاحًا في أداة سطر الأوامر.

للقيام بذلك، أضف إدخالاً في سمة `_SUPPORTED_MODEL_TYPE`:

- إذا كان النموذج مدعومًا بالفعل لخلفيات أخرى غير ONNX، فسيتم إدخاله بالفعل، لذلك ستحتاج فقط إلى
أضف مفتاح "onnx" الذي يحدد اسم فئة التكوين.
- وإلا، فسيتعين عليك إضافة الإدخال بالكامل.

بالنسبة لـ BERT، يبدو الأمر كما يلي:

```python
"bert": supported_tasks_mapping(
"default",
"fill-mask",
"text-generation",
"text-classification",
"multiple-choice",
"token-classification",
"question-answering",
onnx="BertOnnxConfig",
)
```

## تصدير النموذج

بمجرد تنفيذ تكوين ONNX، تتمثل الخطوة التالية في تصدير النموذج.
يمكننا هنا استخدام وظيفة `export()` التي توفرها حزمة `optimum.exporters.onnx`.
تتوقع هذه الوظيفة تكوين ONNX، إلى جانب النموذج الأساسي، ومسار حفظ الملف المصدر:

```python
>>> from pathlib import Path
>>> from optimum.exporters import TasksManager
>>> from optimum.exporters.onnx import export
>>> from transformers import AutoModel

>>> base_model = AutoModel.from_pretrained("bert-base-uncased")

>>> onnx_path = Path("model.onnx")
>>> onnx_config_constructor = TasksManager.get_exporter_config_constructor("onnx"، base_model)
>>> onnx_config = onnx_config_constructor(base_model.config)

>>> onnx_inputs، onnx_outputs = export(base_model, onnx_config, onnx_path, onnx_config.DEFAULT_ONNX_OPSET)
```

`onnx_inputs` و`onnx_outputs` التي تعيدها وظيفة `export()` هي قوائم بالمفاتيح المحددة في خصائص [`~optimum.exporters.onnx.OnnxConfig.inputs`]
و [`~optimum.exporters.onnx.OnnxConfig.inputs`] من التكوين. بمجرد تصدير النموذج، يمكنك اختبار ما إذا كان النموذج جيد التشكيل كما يلي:

```python
>>> import onnx

>>> onnx_model = onnx.load("model.onnx")
>>> onnx.checker.check_model(onnx_model)
```

<Tip>

إذا كان نموذجك أكبر من 2 جيجابايت، فستلاحظ أنه يتم إنشاء العديد من الملفات الإضافية أثناء التصدير. هذا
متوقع لأن ONNX يستخدم [بروتوكول المخازن المؤقتة](https://developers.google.com/protocol-buffers/) لتخزين النموذج
ولديها حد حجم يبلغ 2 جيجابايت. راجع [وثائق ONNX](https://github.com/onnx/onnx/blob/master/docs/ExternalData.md)
للحصول على تعليمات حول كيفية تحميل النماذج ذات البيانات الخارجية.

</Tip>

## التحقق من صحة إخراج النموذج

الخطوة الأخيرة هي التحقق من صحة الإخراج من النموذج الأساسي والمصدر
تتفق ضمن بعض التسامح المطلق.
يمكننا هنا استخدام وظيفة `validate_model_outputs()` التي توفرها حزمة `optimum.exporters.onnx`:

```python
>>> from optimum.exporters.onnx import validate_model_outputs

>>> validate_model_outputs(
... onnx_config, base_model, onnx_path, onnx_outputs, onnx_config.ATOL_FOR_VALIDATION
... )
```

## المساهمة في التكوين الجديد في 🤗 Optimum

الآن بعد تنفيذ دعم البنية والتحقق من صحتها، هناك أمران متبقيان:

1. أضف بنية نموذجك إلى الاختبارات في `tests/exporters/test_onnx_export.py`
2. إنشاء طلب سحب على [`مستودع Optimum`](https://github.com/huggingface/optimum)

شكرًا لمساهمتك!